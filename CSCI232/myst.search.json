{"version":"1","records":[{"hierarchy":{"lvl1":"CSCI 232"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"CSCI 232"},"content":"This book focuses on Intermediate Data Structures and Algorithms.\n\nJames Goudy\n\n© 2024\n\nAlgorithms\n\nCSCI 232 Data Structures and Algorithms\n\nTerms and Concepts\n\nRadix - Number Bases\n\nSerializable\n\nIterator\n\nBinary Search Tree - Intro\n\nApplications That Use Binary Trees\n\nBinary Tree Comparisons\n\nTree Traversal\n\nDemonstrate BST using iterative looping and recursion\n\nBinary Search Tree\n\nAVL Tree\n\nRed Black Tree\n\nBST AVL Red Black Tree Comparisons\n\nSplay Trees\n\nHash Table\n\nUnderstanding Hash Tables and Hash Functions*\n\nModulus Hash Function\n\nHash Tables - Chaining\n\nHash Table - Open Addressing\n\nJava code for double hashing in a hash table:\n\nSkip List\n\nGraphs\n\nA Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms\n\nUnderstanding Breadth-First Search (BFS)\n\nUnderstanding Depth-First Search (DFS)\n\nSeven Bridges of Königsberg\n\nDepth-First Search (DFS)\n\nBreadth First\n\nDFS - Stored Paths\n\nDSF - Maze Solving\n\nDijkstra’s Algorithm\n\nHuffman Code\n\nSerialization\n\nJAVA Techniques\n\nExamples of Java’s HashMap, TreeMap, and LinkedHashMap\n\nHashSet, LinkedHashSet, and TreeSet Comparision\n\nProgramming To The Interface, Not The Implementation\"\n\nEnd","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"AVL Tree"},"type":"lvl1","url":"/xbst-avltree","position":0},{"hierarchy":{"lvl1":"AVL Tree"},"content":"AVL Tree Overview\n\nAn AVL (Adelson-Velsky and Landis) Tree is a type of self-balancing binary search tree. It is named after its inventors, Georgy Adelson-Velsky and Evgenii Landis, who introduced it in 1962.\n\nIn a typical binary search tree, the key in each node is larger than all keys in its left subtree and smaller than all keys in its right subtree. While a standard binary search tree can degrade to a linked list in the worst case, an AVL tree enforces additional balance properties that prevent extreme imbalance.","type":"content","url":"/xbst-avltree","position":1},{"hierarchy":{"lvl1":"AVL Tree","lvl2":"Key Properties and Balance Rules"},"type":"lvl2","url":"/xbst-avltree#key-properties-and-balance-rules","position":2},{"hierarchy":{"lvl1":"AVL Tree","lvl2":"Key Properties and Balance Rules"},"content":"Balance Factor:\nFor each node, the AVL tree tracks a balance factor defined as:\n\nbalance(node)=height(node.left)−height(node.right)\\text{balance}(node) = \\text{height}(node.left) - \\text{height}(node.right)\n\nIn an AVL tree, the balance factor for any node must always be -1, 0, or 1.\n\nHeight Constraint:\nThe height of the left and right subtrees of any node differ by at most 1. If the height difference exceeds 1, the tree performs rotations to restore balance.\n\nRotations:\nThe four possible rotation cases occur after an insertion or deletion that breaks the balance:\n\nLeft-Left (LL) rotation: Performed when a node is inserted into the left subtree of the left child. Fixed by a single right rotation.\n\nRight-Right (RR) rotation: Performed when a node is inserted into the right subtree of the right child. Fixed by a single left rotation.\n\nLeft-Right (LR) rotation: Performed when a node is inserted into the right subtree of the left child. Fixed by a left rotation on the left child, then a right rotation on the node.\n\nRight-Left (RL) rotation: Performed when a node is inserted into the left subtree of the right child. Fixed by a right rotation on the right child, then a left rotation on the node.","type":"content","url":"/xbst-avltree#key-properties-and-balance-rules","position":3},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Single Rotations","lvl2":"Key Properties and Balance Rules"},"type":"lvl3","url":"/xbst-avltree#single-rotations","position":4},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Single Rotations","lvl2":"Key Properties and Balance Rules"},"content":"Right Rotation (for an unbalanced node leaning left):    y                            x\n   / \\                          / \\\n  x   T3       ---->          T1   y\n / \\                              / \\\nT1  T2                           T2  T3\n\nLeft Rotation (for an unbalanced node leaning right):  y                                x\n / \\                              / \\\nT1  x          ---->            y   T3\n   / \\                          / \\\n  T2  T3                       T1  T2","type":"content","url":"/xbst-avltree#single-rotations","position":5},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Double Rotations","lvl2":"Key Properties and Balance Rules"},"type":"lvl3","url":"/xbst-avltree#double-rotations","position":6},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Double Rotations","lvl2":"Key Properties and Balance Rules"},"content":"When the subtree is not in a strictly left-left or right-right configuration but rather “zig-zag,” two rotations are performed in sequence. For instance, Left-Right rotation is effectively a left rotation on the left child, followed by a right rotation on the original node.","type":"content","url":"/xbst-avltree#double-rotations","position":7},{"hierarchy":{"lvl1":"AVL Tree","lvl2":"Java Implementation of an AVL Tree"},"type":"lvl2","url":"/xbst-avltree#java-implementation-of-an-avl-tree","position":8},{"hierarchy":{"lvl1":"AVL Tree","lvl2":"Java Implementation of an AVL Tree"},"content":"Below is a simple Java class that implements:\n\nInsertion\n\nDeletion\n\nSearch\n\nTraversals: In-order, Pre-order, Post-order\n\nA pretty print method to display the tree structurepublic class AVLTree<T extends Comparable<T>> {\n\n    private class Node {\n        T key;\n        Node left, right;\n        int height;\n\n        Node(T key) {\n            this.key = key;\n            height = 1;\n        }\n    }\n\n    private Node root;\n\n    // ------------------------\n    // Utility Functions\n    // ------------------------\n\n    // Return the height of a node, or 0 if null\n    private int height(Node node) {\n        return (node == null) ? 0 : node.height;\n    }\n\n    // Calculate the balance factor of a node\n    private int getBalance(Node node) {\n        if (node == null) {\n            return 0;\n        }\n        return height(node.left) - height(node.right);\n    }\n\n    // Update the node's height based on children's heights\n    private void updateHeight(Node node) {\n        node.height = 1 + Math.max(height(node.left), height(node.right));\n    }\n\n    // ------------------------\n    // Rotations\n    // ------------------------\n\n    // Right rotate subtree rooted with y\n    private Node rotateRight(Node y) {\n        Node x = y.left;\n        Node T2 = x.right;\n\n        // Perform rotation\n        x.right = y;\n        y.left = T2;\n\n        // Update heights\n        updateHeight(y);\n        updateHeight(x);\n\n        // x becomes new root\n        return x;\n    }\n\n    // Left rotate subtree rooted with x\n    private Node rotateLeft(Node x) {\n        Node y = x.right;\n        Node T2 = y.left;\n\n        // Perform rotation\n        y.left = x;\n        x.right = T2;\n\n        // Update heights\n        updateHeight(x);\n        updateHeight(y);\n\n        // y becomes new root\n        return y;\n    }\n\n    // ------------------------\n    // Insertion\n    // ------------------------\n    public void insert(T key) {\n        root = insertRec(root, key);\n    }\n\n    private Node insertRec(Node node, T key) {\n        // 1. Perform the normal BST insertion\n        if (node == null) {\n            return new Node(key);\n        }\n\n        int cmp = key.compareTo(node.key);\n        if (cmp < 0) {\n            node.left = insertRec(node.left, key);\n        } else if (cmp > 0) {\n            node.right = insertRec(node.right, key);\n        } else {\n            // Duplicate keys not allowed or handle as desired\n            return node;\n        }\n\n        // 2. Update the height of the ancestor node\n        updateHeight(node);\n\n        // 3. Get the balance factor\n        int balance = getBalance(node);\n\n        // 4. If the node becomes unbalanced, then check the four cases\n\n        // Left Left Case\n        if (balance > 1 && key.compareTo(node.left.key) < 0) {\n            return rotateRight(node);\n        }\n\n        // Right Right Case\n        if (balance < -1 && key.compareTo(node.right.key) > 0) {\n            return rotateLeft(node);\n        }\n\n        // Left Right Case\n        if (balance > 1 && key.compareTo(node.left.key) > 0) {\n            node.left = rotateLeft(node.left);\n            return rotateRight(node);\n        }\n\n        // Right Left Case\n        if (balance < -1 && key.compareTo(node.right.key) < 0) {\n            node.right = rotateRight(node.right);\n            return rotateLeft(node);\n        }\n\n        // return the (unchanged) node pointer\n        return node;\n    }\n\n    // ------------------------\n    // Deletion\n    // ------------------------\n    public void delete(T key) {\n        root = deleteRec(root, key);\n    }\n\n    private Node deleteRec(Node node, T key) {\n        // 1. Perform standard BST delete\n        if (node == null) {\n            return node;\n        }\n\n        int cmp = key.compareTo(node.key);\n        if (cmp < 0) {\n            node.left = deleteRec(node.left, key);\n        } else if (cmp > 0) {\n            node.right = deleteRec(node.right, key);\n        } else {\n            // Node with only one child or no child\n            if (node.left == null || node.right == null) {\n                Node temp = (node.left != null) ? node.left : node.right;\n                // No child\n                if (temp == null) {\n                    node = null;\n                } else {\n                    // One child\n                    node = temp;\n                }\n            } else {\n                // Node with two children: get the inorder successor\n                Node successor = getMinValueNode(node.right);\n                // Copy successor's data to this node\n                node.key = successor.key;\n                // Delete the successor\n                node.right = deleteRec(node.right, successor.key);\n            }\n        }\n\n        // If the tree had only one node\n        if (node == null) {\n            return node;\n        }\n\n        // 2. Update height of the current node\n        updateHeight(node);\n\n        // 3. Get balance factor\n        int balance = getBalance(node);\n\n        // 4. Rebalance if needed\n\n        // Left Left Case\n        if (balance > 1 && getBalance(node.left) >= 0) {\n            return rotateRight(node);\n        }\n\n        // Left Right Case\n        if (balance > 1 && getBalance(node.left) < 0) {\n            node.left = rotateLeft(node.left);\n            return rotateRight(node);\n        }\n\n        // Right Right Case\n        if (balance < -1 && getBalance(node.right) <= 0) {\n            return rotateLeft(node);\n        }\n\n        // Right Left Case\n        if (balance < -1 && getBalance(node.right) > 0) {\n            node.right = rotateRight(node.right);\n            return rotateLeft(node);\n        }\n\n        return node;\n    }\n\n    // Helper function to find the node with the minimum key value\n    private Node getMinValueNode(Node node) {\n        Node current = node;\n        while (current.left != null) {\n            current = current.left;\n        }\n        return current;\n    }\n\n    // ------------------------\n    // Search\n    // ------------------------\n    public boolean search(T key) {\n        return searchRec(root, key);\n    }\n\n    private boolean searchRec(Node node, T key) {\n        if (node == null) {\n            return false;\n        }\n        int cmp = key.compareTo(node.key);\n        if (cmp < 0) {\n            return searchRec(node.left, key);\n        } else if (cmp > 0) {\n            return searchRec(node.right, key);\n        } else {\n            // cmp == 0, key found\n            return true;\n        }\n    }\n\n    // ------------------------\n    // Traversals\n    // ------------------------\n    public void inOrder() {\n        System.out.print(\"InOrder: \");\n        inOrderRec(root);\n        System.out.println();\n    }\n\n    private void inOrderRec(Node node) {\n        if (node == null) {\n            return;\n        }\n        inOrderRec(node.left);\n        System.out.print(node.key + \" \");\n        inOrderRec(node.right);\n    }\n\n    public void preOrder() {\n        System.out.print(\"PreOrder: \");\n        preOrderRec(root);\n        System.out.println();\n    }\n\n    private void preOrderRec(Node node) {\n        if (node == null) {\n            return;\n        }\n        System.out.print(node.key + \" \");\n        preOrderRec(node.left);\n        preOrderRec(node.right);\n    }\n\n    public void postOrder() {\n        System.out.print(\"PostOrder: \");\n        postOrderRec(root);\n        System.out.println();\n    }\n\n    private void postOrderRec(Node node) {\n        if (node == null) {\n            return;\n        }\n        postOrderRec(node.left);\n        postOrderRec(node.right);\n        System.out.print(node.key + \" \");\n    }\n\n    // ------------------------\n    // Pretty Print (Tree Display)\n    // ------------------------\n    public void printTree() {\n        printTreeRec(root, \"\", true);\n    }\n\n    /*\n     * Traverses the tree in a rotated manner and prints branches to visualize\n     * the structure. The approach is to go right, then print current, then go left.\n     */\n    private void printTreeRec(Node node, String indent, boolean isRight) {\n        if (node == null) {\n            return;\n        }\n        // Print right subtree\n        printTreeRec(node.right, indent + (isRight ? \"     \" : \" |   \"), false);\n\n        // Print current node\n        System.out.print(indent);\n        if (isRight) {\n            System.out.print(\"└───\");\n        } else {\n            System.out.print(\"┌───\");\n        }\n        System.out.println(node.key);\n\n        // Print left subtree\n        printTreeRec(node.left, indent + (isRight ? \" |   \" : \"     \"), true);\n    }\n\n    // ------------------------\n    // Main (for demonstration)\n    // ------------------------\n    public static void main(String[] args) {\n        AVLTree<Integer> tree = new AVLTree<>();\n        int[] values = { 10, 20, 30, 40, 50, 25 };\n        for (int val : values) {\n            tree.insert(val);\n        }\n\n        tree.printTree();\n        tree.inOrder();\n        tree.preOrder();\n        tree.postOrder();\n\n        System.out.println(\"Search 25: \" + tree.search(25));\n        System.out.println(\"Search 15: \" + tree.search(15));\n\n        System.out.println(\"\\nDelete 20\");\n        tree.delete(20);\n        tree.printTree();\n    }\n}","type":"content","url":"/xbst-avltree#java-implementation-of-an-avl-tree","position":9},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Explanation of the Key Methods","lvl2":"Java Implementation of an AVL Tree"},"type":"lvl3","url":"/xbst-avltree#explanation-of-the-key-methods","position":10},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Explanation of the Key Methods","lvl2":"Java Implementation of an AVL Tree"},"content":"Node Class\nEach node stores:\n\nThe key (generic type T).\n\nReferences to the left and right children.\n\nAn integer height to aid in maintaining balance.\n\nHeight and Balance Factor\n\nheight(node): returns the height of the node (with null as height 0).\n\ngetBalance(node): computes the difference in heights of the left and right subtrees.\n\nInsertion\n\nInsert the new key as in a regular BST.\n\nUpdate the height of the ancestor nodes.\n\nCheck the balance factor.\n\nPerform appropriate rotations if unbalanced.\n\nDeletion\n\nPerform the usual BST deletion (case of no child, one child, or two children).\n\nUpdate the height and balance for nodes on the path back up.\n\nFix any imbalance with the correct rotations.\n\nSearch\nStandard BST search logic:\n\nCompare, traverse left or right, or return true if the key is found.\n\nTraversals\n\nIn-order: left, node, right\n\nPre-order: node, left, right\n\nPost-order: left, right, node\n\nPretty Print\nA simple, recursive approach that prints the tree horizontally, showing child branches with ASCII symbols.\n\nTime Complexity\n\nInsertion, Deletion, and Search each take O(log n) time on average because the AVL tree remains balanced (height is O(log⁡n)\\mathcal{O}(\\log n)).\n\nWith this, you have a complete Java class demonstrating the core features of an AVL tree, along with helpful utility methods and a main routine for testing.","type":"content","url":"/xbst-avltree#explanation-of-the-key-methods","position":11},{"hierarchy":{"lvl1":"AVL Tree","lvl2":"Supplemental Note"},"type":"lvl2","url":"/xbst-avltree#supplemental-note","position":12},{"hierarchy":{"lvl1":"AVL Tree","lvl2":"Supplemental Note"},"content":"Let’s break down the line of code in detail:public class AVLTree<T extends Comparable<T>>\n\nThis declaration defines a generic class named AVLTree which has a single type parameter, T. The part that might look complex at first glance is:T extends Comparable<T>","type":"content","url":"/xbst-avltree#supplemental-note","position":13},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"What does T extends Comparable<T> mean?","lvl2":"Supplemental Note"},"type":"lvl3","url":"/xbst-avltree#what-does-t-extends-comparable-t-mean","position":14},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"What does T extends Comparable<T> mean?","lvl2":"Supplemental Note"},"content":"Generic Type Parameter\nWhen you write class AVLTree<T>, T is a generic type parameter. This allows the class AVLTree to work with any type without being tied to a specific class or interface.\n\nType Bound (extends Comparable<T>)\nBy saying T extends Comparable<T>, we’re adding a constraint on what T can be:\n\nIt must be a type that implements the Comparable<T> interface.\n\nIn other words, T must be able to compare itself to another object of the same type T.\n\nIn Java, extends in a generic type context can mean either “extends (a superclass)” or “implements (an interface).” Since Comparable is an interface, this part actually means “implements Comparable<T>.”\n\nWhy do we need Comparable<T> in an AVL Tree?\nAn AVL tree is a self-balancing binary search tree. For a binary search tree, we need to compare elements to decide:\n\nWhere to insert a new node (go left if the new value is smaller, go right if it’s larger).\n\nHow to traverse or search in the tree.\n\nBecause we need to compare elements, the type T used in this tree must be comparable. That’s why the code requires T extends Comparable<T>—so that each node’s value can be compared to another node’s value.","type":"content","url":"/xbst-avltree#what-does-t-extends-comparable-t-mean","position":15},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"What does the Comparable interface do?","lvl2":"Supplemental Note"},"type":"lvl3","url":"/xbst-avltree#what-does-the-comparable-interface-do","position":16},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"What does the Comparable interface do?","lvl2":"Supplemental Note"},"content":"Comparable<T> is a built-in Java interface (from the java.lang package) that has a single method:public interface Comparable<T> {\n    int compareTo(T o);\n}\n\nAny class that implements Comparable<T> is expected to provide its own definition of the compareTo(T o) method. The compareTo method returns:\n\nA negative integer if the current object is “less than” the argument.\n\nZero if they are “equal.”\n\nA positive integer if the current object is “greater than” the argument.\n\nThis enables sorting and ordering. In a data structure like an AVL tree, you rely on the compareTo method to decide how to place or find items.","type":"content","url":"/xbst-avltree#what-does-the-comparable-interface-do","position":17},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Example","lvl2":"Supplemental Note"},"type":"lvl3","url":"/xbst-avltree#example","position":18},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Example","lvl2":"Supplemental Note"},"content":"For instance, Java’s built-in String class implements Comparable<String>:public final class String implements Comparable<String>, CharSequence, ...\n{\n    // Implementation details\n\n    @Override\n    public int compareTo(String anotherString) {\n        // returns negative, 0, or positive\n        // based on lexicographical comparison\n    }\n}\n\nSo if you create an AVLTree<String>, you know that you can compare String objects to decide their order in the tree.\n\nSimilarly, Java’s built-in numeric types like Integer implement Comparable<Integer>, so AVLTree<Integer> would also work.","type":"content","url":"/xbst-avltree#example","position":19},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Summary of T extends Comparable<T>","lvl2":"Supplemental Note"},"type":"lvl3","url":"/xbst-avltree#summary-of-t-extends-comparable-t","position":20},{"hierarchy":{"lvl1":"AVL Tree","lvl3":"Summary of T extends Comparable<T>","lvl2":"Supplemental Note"},"content":"It constrains the generic parameter T to types that implement Comparable of themselves.\n\nIt ensures that any instance of AVLTree<T> can compare its elements (T objects) with each other.\n\nIt’s essential for data structures or algorithms that rely on comparing objects (e.g., sorting, searching, or balancing a tree).\n\nBy using T extends Comparable<T>, the AVLTree class is guaranteed that T has a compareTo method, making it possible to implement comparison-based logic correctly and safely within the tree’s operations.","type":"content","url":"/xbst-avltree#summary-of-t-extends-comparable-t","position":21},{"hierarchy":{"lvl1":"AVL Tree","lvl2":"Alternative"},"type":"lvl2","url":"/xbst-avltree#alternative","position":22},{"hierarchy":{"lvl1":"AVL Tree","lvl2":"Alternative"},"content":"// AVLTreeDemo.java\n// Compile: javac AVLTreeDemo.java\n// Run:     java AVLTreeDemo\n\n\n\nclass AVLTree {\n\n    // Node as a nested subclass (inner class).\n    private class Node {\n\n        int key;\n        String data;\n        int height;\n        Node left, right;\n\n        Node(int key, String data)\n        {\n            this.key = key;\n            this.data = data;\n            this.height = 1; // leaf height = 1\n        }\n    }\n\n    private Node root;\n\n    // -----------------------\n    // Public API\n    // -----------------------\n    public void insert(int key, String data)\n    {\n        /*\n         Rotation rules (AVL rebalancing after INSERT):\n           Let balance = height(left) - height(right)\n\n           If balance > 1 (left heavy):\n             - Left-Left (LL): key inserted into left subtree of left child\n                 => rotateRight(node)\n             - Left-Right (LR): key inserted into right subtree of left child\n                 => rotateLeft(node.left) then rotateRight(node)\n\n           If balance < -1 (right heavy):\n             - Right-Right (RR): key inserted into right subtree of right child\n                 => rotateLeft(node)\n             - Right-Left (RL): key inserted into left subtree of right child\n                 => rotateRight(node.right) then rotateLeft(node)\n         */\n        root = insert(root, key, data);\n    }\n\n    public void delete(int key)\n    {\n    /*\n     Rotation rules (AVL rebalancing after DELETE):\n       Deletion can reduce subtree heights, so after \n       removing a key, walk back up:\n       - Update height\n       - Compute balance = height(left) - height(right)\n       - If unbalanced, use the child's balance to pick the case:\n\n       If balance > 1 (left heavy):\n         - If balance(left) >= 0  => LL case => rotateRight(node)\n         - If balance(left) <  0  => LR case => rotateLeft(node.left), \n            rotateRight(node)\n\n       If balance < -1 (right heavy):\n         - If balance(right) <= 0 => RR case => rotateLeft(node)\n         - If balance(right) >  0 => RL case => rotateRight(node.right), \n            rotateLeft(node)\n     */\n        root = delete(root, key);\n    }\n\n    public String find(int key)\n    {\n        Node n = find(root, key);\n        return (n == null) ? null : n.data;\n    }\n\n    public void preOrder()\n    {\n        preOrder(root);\n        System.out.println();\n    }\n\n    public void inOrder()\n    {\n        inOrder(root);\n        System.out.println();\n    }\n\n    public void postOrder()\n    {\n        postOrder(root);\n        System.out.println();\n    }\n\n\n\n    // -----------------------\n    // Core AVL internals\n    // -----------------------\n    private Node insert(Node node, int key, String data)\n    {\n        if (node == null) {\n            return new Node(key, data);\n        }\n\n        if (key < node.key) {\n            node.left = insert(node.left, key, data);\n        } else if (key > node.key) {\n            node.right = insert(node.right, key, data);\n        } else {\n            // Duplicate key: update data (common practical policy).\n            node.data = data;\n            return node;\n        }\n\n        updateHeight(node);\n        int balance = getBalance(node);\n\n        // Left heavy\n        if (balance > 1) {\n            if (key < node.left.key) {\n                // LL\n                return rotateRight(node);\n            } else {\n                // LR\n                node.left = rotateLeft(node.left);\n                return rotateRight(node);\n            }\n        }\n\n        // Right heavy\n        if (balance < -1) {\n            if (key > node.right.key) {\n                // RR\n                return rotateLeft(node);\n            } else {\n                // RL\n                node.right = rotateRight(node.right);\n                return rotateLeft(node);\n            }\n        }\n\n        return node;\n    }\n\n    private Node delete(Node node, int key)\n    {\n        if (node == null) {\n            return null;\n        }\n\n        if (key < node.key) {\n            node.left = delete(node.left, key);\n        } else if (key > node.key) {\n            node.right = delete(node.right, key);\n        } else {\n            // Found node to delete.\n            if (node.left == null || node.right == null) {\n                Node child = (node.left != null) ? node.left : node.right;\n                node = child; // could become null if no children\n            } else {\n                // Two children: replace with inorder successor (min in right subtree)\n                Node succ = minValueNode(node.right);\n                node.key = succ.key;\n                node.data = succ.data;\n                node.right = delete(node.right, succ.key);\n            }\n        }\n\n        // If the tree had one node and we deleted it.\n        if (node == null) {\n            return null;\n        }\n\n        updateHeight(node);\n        int balance = getBalance(node);\n\n        // Left heavy\n        if (balance > 1) {\n            int leftBal = getBalance(node.left);\n            if (leftBal >= 0) {\n                // LL\n                return rotateRight(node);\n            } else {\n                // LR\n                node.left = rotateLeft(node.left);\n                return rotateRight(node);\n            }\n        }\n\n        // Right heavy\n        if (balance < -1) {\n            int rightBal = getBalance(node.right);\n            if (rightBal <= 0) {\n                // RR\n                return rotateLeft(node);\n            } else {\n                // RL\n                node.right = rotateRight(node.right);\n                return rotateLeft(node);\n            }\n        }\n\n        return node;\n    }\n\n    private Node find(Node node, int key)\n    {\n        while (node != null) {\n            if (key < node.key) {\n                node = node.left;\n            } else if (key > node.key) {\n                node = node.right;\n            } else {\n                return node;\n            }\n        }\n        return null;\n    }\n\n    private Node minValueNode(Node node)\n    {\n        Node cur = node;\n        while (cur.left != null) {\n            cur = cur.left;\n        }\n        return cur;\n    }\n\n    // -----------------------\n    // Rotations + helpers\n    // -----------------------\n    private int height(Node n)\n    {\n        return (n == null) ? 0 : n.height;\n    }\n\n    private void updateHeight(Node n)\n    {\n        n.height = 1 + Math.max(height(n.left), height(n.right));\n    }\n\n    private int getBalance(Node n)\n    {\n        return (n == null) ? 0 : height(n.left) - height(n.right);\n    }\n\n    // Right rotation:\n    //        y                 x\n    //       / \\               / \\\n    //      x   T3   =>       T1  y\n    //     / \\                   / \\\n    //    T1  T2                T2  T3\n    private Node rotateRight(Node y)\n    {\n        Node x = y.left;\n        Node t2 = x.right;\n\n        x.right = y;\n        y.left = t2;\n\n        updateHeight(y);\n        updateHeight(x);\n\n        return x;\n    }\n\n    // Left rotation:\n    //      x                    y\n    //     / \\                  / \\\n    //    T1  y      =>        x  T3\n    //       / \\              / \\\n    //      T2  T3           T1  T2\n    private Node rotateLeft(Node x)\n    {\n        Node y = x.right;\n        Node t2 = y.left;\n\n        y.left = x;\n        x.right = t2;\n\n        updateHeight(x);\n        updateHeight(y);\n\n        return y;\n    }\n\n    // -----------------------\n    // Traversals (prints key:data)\n    // -----------------------\n    private void preOrder(Node n)\n    {\n        if (n == null) {\n            return;\n        }\n        System.out.print(n.key + \":\" + n.data + \"  \");\n        preOrder(n.left);\n        preOrder(n.right);\n    }\n\n    private void inOrder(Node n)\n    {\n        if (n == null) {\n            return;\n        }\n        inOrder(n.left);\n        System.out.print(n.key + \":\" + n.data + \"  \");\n        inOrder(n.right);\n    }\n\n    private void postOrder(Node n)\n    {\n        if (n == null) {\n            return;\n        }\n        postOrder(n.left);\n        postOrder(n.right);\n        System.out.print(n.key + \":\" + n.data + \"  \");\n    }\n\n   \n    \n    //  version (top-down).\n    public void prettyPrint()\n    {\n        if (root == null) {\n            System.out.println(\"(empty)\");\n            return;\n        }\n\n        int h = height(root);\n        java.util.List<Node> level = new java.util.ArrayList<>();\n        level.add(root);\n\n        for (int depth = 1; depth <= h; depth++) {\n            int leading = (1 << (h - depth + 1)) - 2;  // spaces before first node\n            int between = (1 << (h - depth + 2)) - 2;  // spaces between nodes\n\n            // Print node keys line\n            printSpaces(leading);\n\n            java.util.List<Node> next = new java.util.ArrayList<>();\n            boolean anyNonNull = false;\n\n            for (int i = 0; i < level.size(); i++) {\n                Node n = level.get(i);\n\n                if (n == null) {\n                    System.out.print(\"  \"); // placeholder width\n                    next.add(null);\n                    next.add(null);\n                } else {\n                    String s = String.valueOf(n.key);\n                    // keep width roughly constant for small keys; pad to 2 chars\n                    if (s.length() == 1) {\n                        s = \" \" + s;\n                    }\n                    System.out.print(s);\n\n                    next.add(n.left);\n                    next.add(n.right);\n\n                    if (n.left != null || n.right != null) {\n                        anyNonNull = true;\n                    }\n                }\n\n                if (i < level.size() - 1) {\n                    printSpaces(between);\n                }\n            }\n            System.out.println();\n\n            // Print connector line (slashes) except last level\n            if (depth < h) {\n                int slashLeading = leading - 1;\n                int slashBetween = between - 2;\n\n                if (slashLeading < 0) {\n                    slashLeading = 0;\n                }\n                if (slashBetween < 0) {\n                    slashBetween = 0;\n                }\n\n                printSpaces(slashLeading);\n\n                for (int i = 0; i < level.size(); i++) {\n                    Node n = level.get(i);\n\n                    if (n == null) {\n                        System.out.print(\"  \");\n                    } else {\n                        char left = (n.left != null) ? '/' : ' ';\n                        char right = (n.right != null) ? '\\\\' : ' ';\n                        System.out.print(left);\n                        System.out.print(right);\n                    }\n\n                    if (i < level.size() - 1) {\n                        printSpaces(slashBetween);\n                    }\n                }\n                System.out.println();\n            }\n\n            level = next;\n\n            // If the next level is entirely null, stop early.\n            if (!anyNonNull && depth < h) {\n                // still printed current level; no need to print empty lower levels\n                break;\n            }\n        }\n    }\n\n    private void printSpaces(int count)\n    {\n        for (int i = 0; i < count; i++) {\n            System.out.print(' ');\n        }\n    }\n}\n\npublic class AVLTreeDemo {\n\n    public static void main(String[] args)\n    {\n        AVLTree tree = new AVLTree();\n\n        // Insert test data (key, data).\n        tree.insert(30, \"thirty\");\n        tree.insert(20, \"twenty\");\n        tree.insert(40, \"forty\");\n        tree.insert(10, \"ten\");\n        tree.insert(25, \"twenty-five\");\n        tree.insert(35, \"thirty-five\");\n        tree.insert(50, \"fifty\");\n        tree.insert(5, \"five\");\n        tree.insert(15, \"fifteen\");\n        tree.insert(27, \"twenty-seven\");\n\n        System.out.println(\"Pretty print after inserts:\");\n        tree.prettyPrint();\n\n        System.out.println(\"\\nInOrder (sorted by key):\");\n        tree.inOrder();\n\n        System.out.println(\"PreOrder:\");\n        tree.preOrder();\n\n        System.out.println(\"PostOrder:\");\n        tree.postOrder();\n\n        int lookFor = 25;\n        String found = tree.find(lookFor);\n        System.out.println(\"\\nFind \" + lookFor + \": \" + (found == null ? \"(not found)\" : found));\n\n        System.out.println(\"\\nDelete 20 (has two children in this dataset):\");\n        tree.delete(20);\n        tree.prettyPrint();\n\n        System.out.println(\"\\nDelete 5 (leaf):\");\n        tree.delete(5);\n        tree.prettyPrint();\n\n        System.out.println(\"\\nDelete 40 (has children):\");\n        tree.delete(40);\n        tree.prettyPrint();\n\n        System.out.println(\"\\nInOrder after deletions:\");\n        tree.inOrder();\n        \n\n        \n        System.out.println(\"\\n\\nEnd\\n\");\n    }\n}\n","type":"content","url":"/xbst-avltree#alternative","position":23},{"hierarchy":{"lvl1":"Applications That Use Binary Trees"},"type":"lvl1","url":"/xbst-applications","position":0},{"hierarchy":{"lvl1":"Applications That Use Binary Trees"},"content":"1. Database Systems:\n\nIndexing: B-trees and B+ trees are fundamental to database indexing, enabling fast retrieval of data based on specific keys. They optimize search and storage for large datasets, making queries lightning-fast.\n\nQuery Optimization: Binary trees assist in planning efficient query execution paths, minimizing read operations and boosting performance.\n\nTransaction Management: They play a role in managing concurrent transactions, ensuring data integrity and consistency.\n\n2. File Systems:\n\nDirectory Structure: Many file systems, including Unix-based ones, organize directories and files in a hierarchical structure using binary trees. This allows for efficient navigation and access to files based on their paths.\n\nFile Allocation: B-trees can be used to manage disk block allocation, optimizing storage and access to file contents.\n\n3. Networking:\n\nRouting Protocols: Routers often employ binary trees to store routing tables, enabling efficient path lookups for packet forwarding.\n\nNetwork Management: Binary trees can represent network topologies and assist in managing network resources effectively.\n\n4. Artificial Intelligence:\n\nDecision Trees: These tree-like models are used for classification and prediction tasks, learning patterns from data to make decisions.\n\nSearch Algorithms: Binary trees are essential for AI algorithms that explore large search spaces, like those used in game playing or problem-solving.\n\nMachine Learning: Some machine learning techniques, like decision trees and random forests, rely on binary trees for model construction and prediction.\n\n5. Compilers and Interpreters:\n\nSyntax Parsing: Binary trees are used to parse code syntax, representing the structure of expressions and statements for analysis and code generation.\n\nAbstract Syntax Trees (ASTs): These trees represent the abstract structure of code, used for optimizations and code generation.\n\n6. Data Compression:\n\nHuffman Coding: This compression technique relies on binary trees to assign variable-length codes to symbols based on their frequencies, reducing data size effectively.\n\n7. Computer Graphics:\n\nScene Management: Binary space partitioning (BSP) trees are used to efficiently divide 3D scenes into smaller regions for rendering, optimizing graphics performance.\n\nRay Tracing: Binary trees can accelerate ray intersection calculations, essential for realistic image rendering.\n\n8. Sorting and Searching:\n\nBinary Search Trees (BSTs): These trees enable efficient searching, insertion, and deletion of elements, making them valuable for various data organization tasks.\n\nHeaps: Used for implementing priority queues, which are essential for scheduling tasks, managing resources, and optimization algorithms.\n\n9. Expression Evaluation:\n\nExpression Trees: Represent mathematical expressions, enabling their evaluation and simplification.\n\n10. Game Development:\n\nGame Trees: Represent possible moves and game states, used in AI algorithms for strategy games like chess and checkers.","type":"content","url":"/xbst-applications","position":1},{"hierarchy":{"lvl1":"Binary Search Tree"},"type":"lvl1","url":"/xbst-binarysearchtree","position":0},{"hierarchy":{"lvl1":"Binary Search Tree"},"content":"","type":"content","url":"/xbst-binarysearchtree","position":1},{"hierarchy":{"lvl1":"Binary Search Tree","lvl2":"Background Information"},"type":"lvl2","url":"/xbst-binarysearchtree#background-information","position":2},{"hierarchy":{"lvl1":"Binary Search Tree","lvl2":"Background Information"},"content":"A binary search tree (BST) is a special type of binary tree data structure used to efficiently store and access sorted data. It’s like a regular tree, but with additional rules that keep everything neatly organized:\n\nKey features:\n\nOrdering: Each node in the tree has a value (key), and the key of a node is always greater than all the keys in its left subtree and less than all the keys in its right subtree. This creates a sorted order throughout the tree.\n\nEfficient searching: Because of this ordering, you can very quickly search for specific values in the tree. Imagine searching a phone book - you wouldn’t start at the very beginning or end, but somewhere in the middle based on the last name. Similarly, in a BST, you can efficiently move left or right depending on the value you’re searching for, narrowing down the possibilities with each comparison.\n\nDynamic insertions and deletions: You can easily add new values (insert) or remove existing ones (delete) from the tree while maintaining the sorted order. The process involves comparing the new value with existing nodes and finding its appropriate place based on the ordering rule.\n\nNo Duplicates: Typically, BSTs do not allow duplicate values, although variations exist that permit duplicates with specific rules (e.g., storing duplicates in the left or right subtree).\n\nBenefits of using BSTs:\n\nFast search: Searching for elements in a balanced BST takes logarithmic time on average, which is significantly faster than searching an unsorted list.\n\nOrdered access: You can easily traverse the tree in sorted order (e.g., for printing all elements in ascending order).\n\nEfficient insertions and deletions: These operations can also be done in logarithmic time in balanced BSTs.\n\nHowever, BSTs also have some drawbacks:\n\nPerformance depends on balance: The efficiency of BST operations relies heavily on the tree’s balance. An unbalanced tree can perform much worse than a balanced one.\n\nNot self-balancing: By default, BSTs are not self-balancing, meaning insertions and deletions can sometimes lead to imbalances. Special techniques are needed to maintain balance and ensure optimal performance.\n\nOverall, binary search trees are a powerful and versatile data structure for storing and managing sorted data efficiently. They offer fast search, insertion, and deletion operations, making them suitable for various applications like symbol tables, priority queues, and sorting algorithms.","type":"content","url":"/xbst-binarysearchtree#background-information","position":3},{"hierarchy":{"lvl1":"Binary Search Tree","lvl2":"Lecture Code"},"type":"lvl2","url":"/xbst-binarysearchtree#lecture-code","position":4},{"hierarchy":{"lvl1":"Binary Search Tree","lvl2":"Lecture Code"},"content":"/*\n * binary tree\n *\n */\npackage btreedemoone;\n\nimport java.util.Scanner;\nimport java.util.Stack;\n\nclass Node {\n\n    // key\n    public int key;\n\n    // data - that's a double\t\n    public int data;\n\n    // node characteristics\n    public Node leftChild;\n    public Node rightChild;\n\n    public Node(int key, int data) {\n        this.key = key;\n        this.data = data;\n    }\n\n    // display node\n    public void displayNode() {\n        System.out.print(\"{\" + key + \",\" + data + \"}\");\n    }\n\n}// end of node\n\nclass Tree {\n\n    private Node root;\n    static Scanner myScan = new Scanner(System.in);\n\n    public Tree() {\n        root = null;\n    }\n\n    public void insert(int key, int data) {\n        // newNode\n        Node newNode = new Node(key, data);\n        boolean run = true;\n\n        if (root == null) {\n            root = newNode;\n        } else {\n            Node current = root;\n            Node parent;\n\n            while (run) {\n                parent = current;\n\n                if (key < current.key) //go left\n                {\n                    current = current.leftChild;\n\n                    if (current == null) {\n                        parent.leftChild = newNode;\n                        run = false;\n                    }\n                } else // go right\n                {\n                    current = current.rightChild;\n\n                    if (current == null) {\n                        parent.rightChild = newNode;\n                        run = false;\n                    }\n                }\n            }\n\n        }\n\n    }// end of insert\n\n    public Node find(int key) {\n\n        Node current = root;\n\n        // check if empty\n        if (root == null) {\n            System.out.println(\"** Tree is empty **\");\n            return null;\n        }\n\n        while (current.key != key) {\n\n            if (key < current.key) // go left?\n            {\n                current = current.leftChild;\n            } else // go right\n            {\n                current = current.rightChild;\n            }\n\n            if (current == null) {\n                System.out.println(\"*** key not found ***\");\n                return null;\n            }\n        }\n\n        System.out.println(\"Key was FOUND\");\n        return current;\n    }\n\n    public boolean delete(int key) {\n        Node current = root;\n        Node parent = root;\n        boolean isLeftChild = true;\n\n        //check if empty\n        if (root == null) {\n            System.out.println(\"*** Tree is empty ***\");\n            return false;\n        }\n\n        // look for the key\n        while (current.key != key) {\n            parent = current;\n\n            if (key < current.key) // go left?\n            {\n                isLeftChild = true;\n                current = current.leftChild;\n            } else // go right\n            {\n                isLeftChild = false;\n                current = current.rightChild;\n            }\n\n            if (current == null) {\n                System.out.println(\"*** key not found ***\");\n                return false;\n            }\n\n        }// end while\n\n        // found we are on the node to delete\n        // if there is no children - simply delete the node\n        if (current.leftChild == null && current.rightChild == null) {\n            //check if node is the root (there is only one node in tree)\n            if (current == root) {\n                root = null;\n            } else if (isLeftChild) {\n                parent.leftChild = null;\n            } else {\n                parent.rightChild = null;\n            }\n        } // if no right child, rplace with left subtree\n        else if (current.rightChild == null) {\n            if (current == root) {\n                root = current.leftChild;\n            } else if (isLeftChild) {\n                parent.leftChild = current.leftChild;\n            } else {\n                parent.rightChild = current.leftChild;\n            }\n        } //if no left child, replace with right subtree\n        else if (current.leftChild == null) {\n            if (current == root) {\n                root = current.rightChild;\n            } else if (isLeftChild) {\n                parent.leftChild = current.rightChild;\n            } else {\n                parent.rightChild = current.rightChild;\n            }\n        } // if there are two children, replace with inorder successor\n        else {\n            //get successor of node to delete of current\n            Node successor = getSuccessor(current);\n\n            // connect parent of current to successor instead\n            if (current == root) {\n                root = successor;\n            } else if (isLeftChild) {\n                parent.leftChild = successor;\n            } else {\n                parent.rightChild = successor;\n            }\n\n            // connect successor to current's left child\n            successor.leftChild = current.leftChild;\n\n            // NOTE: successor cannot have a left child\n        }\n\n        return true;\n\n    }\n\n    // return node with the next highest value after the delete node\n    // goes to right child, then right child's lef descendent's\n    private Node getSuccessor(Node deleteNode) {\n        Node successorParent = deleteNode;\n        Node successor = deleteNode;\n        Node current = deleteNode.rightChild;\n\n        while (current != null) {\n            successorParent = successor;\n            successor = current;\n            current = current.leftChild;\n        }\n\n        // if successor not successful\n        if (successor != deleteNode.rightChild) {\n            successorParent.leftChild = successor.rightChild;\n            successor.rightChild = deleteNode.rightChild;\n        }\n\n        return successor;\n    }\n\n    public void traverse2() {\n\n        System.out.print(\"\\nPreorder Traversal: \");\n        preorder(root);\n\n        System.out.print(\"\\nInorder Traversal: \");\n        inorder(root);\n\n        System.out.print(\"\\nPostorder Traversal: \");\n        postorder(root);\n\n    }\n\n    private void preorder(Node nodeStart) {\n        if (nodeStart != null) {\n            System.out.print(nodeStart.key + \" \");\n            preorder(nodeStart.leftChild);\n            preorder(nodeStart.rightChild);\n        }\n    }\n\n    private void inorder(Node nodeStart) {\n        if (nodeStart != null) {\n            inorder(nodeStart.leftChild);\n            System.out.print(nodeStart.key + \" \");\n            inorder(nodeStart.rightChild);\n        }\n    }\n\n    private void postorder(Node nodeStart) {\n        if (nodeStart != null) {\n            postorder(nodeStart.leftChild);\n            postorder(nodeStart.rightChild);\n            System.out.print(nodeStart.key + \" \");\n        }\n    }\n\n    public void displayTree() {\n        Stack globalStack = new Stack();\n        globalStack.push(root);\n\n        int nBlanks = 32;\n\n        boolean isRowEmpty = false;\n\n        System.out.println(\n                \"\\n..........         Display Tree     ..........................\");\n\n        while (!isRowEmpty) {\n            Stack localStack = new Stack();\n            isRowEmpty = true;\n\n            for (int j = 0; j < nBlanks; j++) {\n                System.out.print(\" \");\n            }\n\n            while (globalStack.isEmpty() == false) {\n                Node temp = (Node) globalStack.pop();\n                if (temp != null) {\n                    System.out.print(temp.data);\n                    localStack.push(temp.leftChild);\n                    localStack.push(temp.rightChild);\n\n                    if (temp.leftChild != null || temp.rightChild != null) {\n                        isRowEmpty = false;\n                    }\n                } else {\n                    System.out.print(\"--\");\n                    localStack.push(null);\n                    localStack.push(null);\n                }\n\n                for (int j = 0; j < nBlanks * 2 - 2; j++) {\n                    System.out.print(' ');\n                }\n            }//while\n\n            System.out.println();\n            nBlanks /= 2;\n            while (localStack.isEmpty() == false) {\n                globalStack.push(localStack.pop());\n            }\n        }\n        // for separation\n        System.out.println(\"---------------------------\");\n    } // display tree\n\n}\n\npublic class BTreeDemoOne {\n\n    static Scanner myScan = new Scanner(System.in);\n\n    public static void main(String[] args) {\n\n        String quit = \"n\";\n\n        int findValue = 0;\n        int deleteValue = 0;\n        int insertValue = 0;\n        \n        boolean result = false;\n\n        Tree theTree = new Tree();\n\n        while (!quit.equals(\"y\")) {\n            theTree.insert(50, 50);\n            theTree.insert(25, 25);\n            theTree.insert(75, 75);\n            theTree.insert(12, 12);\n            theTree.insert(37, 37);\n            theTree.insert(43, 43);\n            theTree.insert(30, 30);\n            theTree.insert(33, 33);\n            theTree.insert(87, 87);\n            theTree.insert(93, 93);\n            theTree.insert(97, 97);\n            theTree.insert(70, 70);\n            theTree.insert(60, 60);\n\n            theTree.displayTree();\n\n            theTree.insert(85, 85);\n            theTree.insert(47, 47);\n            \n\n            theTree.displayTree();\n\n            try {\n                System.out.print(\"Enter an integer to insert \"\n                        + \"or letter to skip: \");\n                insertValue = Integer.parseInt(myScan.nextLine());\n                theTree.insert(insertValue, insertValue);\n                theTree.displayTree();\n                \n            } catch (Exception e) {\n            }\n            \n            \n            theTree.traverse2();\n            try {\n                \n                System.out.print(\"\\nEnter Value To Find or letter to skip: \");\n                findValue = Integer.parseInt(myScan.nextLine());\n                theTree.find(findValue);\n\n            \n                System.out.println(\"\\nEnter value to delete: \");\n                deleteValue = Integer.parseInt(myScan.nextLine());\n\n                if (theTree.delete(deleteValue)) {\n                    theTree.displayTree();\n                } else {\n                    System.out.println(\"NOT FOUND\");\n                }\n            } catch (Exception e) {\n            }\n\n            System.out.print(\"Would you like to quit y/n: \");\n            quit = myScan.nextLine().toLowerCase();\n\n        }\n\n        System.out.println(\"\\nbye\\n\");\n    }\n\n}\n\n\nBST as Class/*\n    Change the package to your specific package\n */\npackage ds_redblacktree_rev2_separateclass;\n\nimport java.util.LinkedList;\nimport java.util.Queue;\nimport java.util.Stack;\n\n/**\n *\n * @author jgoudy\n */\npublic class BinaryTreeSearch\n{\n\n    class Node\n    {\n\n        int key;\n        Node left;\n        Node right;\n        \n        \n\n        Node(int key)\n        {\n            this.key = key;\n            right = null;\n            left = null;\n        }\n    }\n\n    Node root;\n    public int trip = 0;\n\n    public void add(int key)\n    {\n        root = addRecursive(root, key);\n    }\n\n    private Node addRecursive(Node current, int key)\n    {\n\n        if (current == null)\n        {\n            return new Node(key);\n        }\n\n        if (key < current.key)\n        {\n            current.left = addRecursive(current.left, key);\n        } else if (key > current.key)\n        {\n            current.right = addRecursive(current.right, key);\n        }\n\n        return current;\n    }\n\n    public boolean isEmpty()\n    {\n        return root == null;\n    }\n\n    public int getSize()\n    {\n        return getSizeRecursive(root);\n    }\n\n    private int getSizeRecursive(Node current)\n    {\n        return current == null ? 0 : getSizeRecursive(current.left)\n                + 1 + getSizeRecursive(current.right);\n    }\n\n    public boolean containsNode(int key)\n    {\n        trip = 0;\n        return containsNodeRecursive(root, key);\n    }\n\n    private boolean containsNodeRecursive(Node current, int key)\n    {\n        if (current == null)\n        {\n            return false;\n        }\n        trip++;\n        if (key == current.key)\n        {\n            return true;\n        }\n\n        return key < current.key\n                ? containsNodeRecursive(current.left, key)\n                : containsNodeRecursive(current.right, key);\n    }\n\n    public void delete(int key)\n    {\n        root = deleteRecursive(root, key);\n    }\n\n    private Node deleteRecursive(Node current, int key)\n    {\n        if (current == null)\n        {\n            return null;\n        }\n\n        if (key == current.key)\n        {\n            // Case 1: no children\n            if (current.left == null && current.right == null)\n            {\n                return null;\n            }\n\n            // Case 2: only 1 child\n            if (current.right == null)\n            {\n                return current.left;\n            }\n\n            if (current.left == null)\n            {\n                return current.right;\n            }\n\n            // Case 3: 2 children\n            int smallestValue = findSmallestValue(current.right);\n            current.key = smallestValue;\n            current.right = deleteRecursive(current.right, smallestValue);\n            return current;\n        }\n        if (key < current.key)\n        {\n            current.left = deleteRecursive(current.left, key);\n            return current;\n        }\n\n        current.right = deleteRecursive(current.right, key);\n        return current;\n    }\n\n    public int findSmallestValue(Node root)\n    {\n        return root.left == null ? root.key : findSmallestValue(root.left);\n    }\n\n    public int findLargestValue(Node root)\n    {\n        return root.left == null ? root.key : findLargestValue(root.right);\n    }\n\n    public void traverseInOrder(Node node)\n    {\n        if (node != null)\n        {\n            traverseInOrder(node.left);\n            visit(node.key);\n            traverseInOrder(node.right);\n        }\n    }\n\n    public void traversePreOrder(Node node)\n    {\n        if (node != null)\n        {\n            visit(node.key);\n            traversePreOrder(node.left);\n            traversePreOrder(node.right);\n        }\n    }\n\n    public void traversePostOrder(Node node)\n    {\n        if (node != null)\n        {\n            traversePostOrder(node.left);\n            traversePostOrder(node.right);\n            visit(node.key);\n        }\n    }\n\n    public void traverseLevelOrder()\n    {\n        if (root == null)\n        {\n            return;\n        }\n\n        Queue<Node> nodes = new LinkedList<>();\n        nodes.add(root);\n\n        while (!nodes.isEmpty())\n        {\n\n            Node node = nodes.remove();\n\n            System.out.print(\" \" + node.key);\n\n            if (node.left != null)\n            {\n                nodes.add(node.left);\n            }\n\n            if (node.left != null)\n            {\n                nodes.add(node.right);\n            }\n        }\n    }\n\n    public void traverseInOrderWithoutRecursion()\n    {\n        Stack<Node> stack = new Stack<Node>();\n        Node current = root;\n        stack.push(root);\n        while (!stack.isEmpty())\n        {\n            while (current.left != null)\n            {\n                current = current.left;\n                stack.push(current);\n            }\n            current = stack.pop();\n            visit(current.key);\n            if (current.right != null)\n            {\n                current = current.right;\n                stack.push(current);\n            }\n        }\n    }\n\n    public void traversePreOrderWithoutRecursion()\n    {\n        Stack<Node> stack = new Stack<Node>();\n        Node current = root;\n        stack.push(root);\n        while (!stack.isEmpty())\n        {\n            current = stack.pop();\n            visit(current.key);\n\n            if (current.right != null)\n            {\n                stack.push(current.right);\n            }\n\n            if (current.left != null)\n            {\n                stack.push(current.left);\n            }\n        }\n    }\n\n    public void traversePostOrderWithoutRecursion()\n    {\n        Stack<Node> stack = new Stack<Node>();\n        Node prev = root;\n        Node current = root;\n        stack.push(root);\n\n        while (!stack.isEmpty())\n        {\n            current = stack.peek();\n            boolean hasChild = (current.left != null || current.right != null);\n            boolean isPrevLastChild = (prev == current.right\n                    || (prev == current.left && current.right == null));\n\n            if (!hasChild || isPrevLastChild)\n            {\n                current = stack.pop();\n                visit(current.key);\n                prev = current;\n            } else\n            {\n                if (current.right != null)\n                {\n                    stack.push(current.right);\n                }\n                if (current.left != null)\n                {\n                    stack.push(current.left);\n                }\n            }\n        }\n    }\n\n    private void visit(int key)\n    {\n        System.out.print(\" \" + key);\n    }\n\n}\n","type":"content","url":"/xbst-binarysearchtree#lecture-code","position":5},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons"},"type":"lvl1","url":"/xbst-comparisiontable","position":0},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons"},"content":"Here’s a comparative table of Binary Search Trees (BST), AVL Trees, and Red-Black Trees, highlighting their differences and similarities:\n\nFeature\n\nBinary Search Tree (BST)\n\nAVL Tree\n\nRed-Black Tree\n\nDefinition\n\nA hierarchical data structure where each node has at most two children, and the left child is smaller while the right child is greater.\n\nA self-balancing BST that maintains a strict height balance using rotations and balance factors.\n\nA self-balancing BST that enforces balance using a color property (red or black nodes) and specific rebalancing rules.\n\nBalance\n\nNot guaranteed to be balanced; can become skewed (degraded to linked list).\n\nStrictly balanced: the height difference between left and right subtrees is at most 1.\n\nLoosely balanced: ensures logarithmic height but allows more imbalance than AVL.\n\nHeight\n\nCan be as bad as O(n) in the worst case (skewed tree).\n\nAlways O(log n) due to strict balancing.\n\nAlways O(log n) but allows slightly more imbalance than AVL.\n\nRotations\n\nNo rotations are performed unless explicitly balanced.\n\nRotations occur frequently due to strict balance enforcement.\n\nRotations occur less frequently than AVL but are used to maintain red-black properties.\n\nInsertion Complexity\n\nO(n) in the worst case due to possible skewness.\n\nO(log n) due to rebalancing with rotations.\n\nO(log n) with fewer rotations compared to AVL.\n\nDeletion Complexity\n\nO(n) worst case.\n\nO(log n) with rebalancing after deletion.\n\nO(log n) with rebalancing but fewer rotations than AVL.\n\nSearch Complexity\n\nO(n) in the worst case (if unbalanced).\n\nO(log n) since tree remains strictly balanced.\n\nO(log n) due to maintained balance.\n\nMemory Overhead\n\nMinimal, just pointers to child nodes.\n\nHigher than BST due to storing balance factors at each node.\n\nMore than BST but less than AVL due to storing color bits.\n\nUse Cases\n\nSimple applications where balancing is not required.\n\nUsed in applications requiring fast lookups and strict balance (e.g., database indexing).\n\nCommon in memory allocators, operating systems, and complex data structures (e.g., Linux kernel, TreeMap in Java).\n\nPreferred When\n\nInsertions/deletions are rare, and tree balance is not a concern.\n\nLookups and searches need to be very fast, even at the cost of expensive insertions.\n\nA balance between insertion speed and search efficiency is required.","type":"content","url":"/xbst-comparisiontable","position":1},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"Summary:"},"type":"lvl2","url":"/xbst-comparisiontable#summary","position":2},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"Summary:"},"content":"BSTs are simple but can degrade into a linear structure, making operations inefficient.\n\nAVL Trees maintain a strict balance, ensuring fast lookups but with higher rotation costs.\n\nRed-Black Trees provide a good balance between insertion efficiency and search performance, making them widely used in practical applications like databases and OS kernels.\n\nChoosing between a Binary Search Tree (BST), AVL Tree, and Red-Black Tree depends on the specific requirements of the application. Below is a guideline on when to use each:","type":"content","url":"/xbst-comparisiontable#summary","position":3},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"1. Binary Search Tree (BST)"},"type":"lvl2","url":"/xbst-comparisiontable#id-1-binary-search-tree-bst","position":4},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"1. Binary Search Tree (BST)"},"content":"","type":"content","url":"/xbst-comparisiontable#id-1-binary-search-tree-bst","position":5},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Use when:","lvl2":"1. Binary Search Tree (BST)"},"type":"lvl3","url":"/xbst-comparisiontable#use-when","position":6},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Use when:","lvl2":"1. Binary Search Tree (BST)"},"content":"Data is inserted in a random manner, reducing the likelihood of a skewed tree.\n\nBalancing is not critical, and you prefer a simple implementation.\n\nRead and write operations are infrequent, so the risk of degeneration to O(n) performance is low.\n\nYou need a tree structure for educational or conceptual purposes rather than performance-oriented applications.","type":"content","url":"/xbst-comparisiontable#use-when","position":7},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Example Use Cases:","lvl2":"1. Binary Search Tree (BST)"},"type":"lvl3","url":"/xbst-comparisiontable#example-use-cases","position":8},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Example Use Cases:","lvl2":"1. Binary Search Tree (BST)"},"content":"Small datasets where tree height isn’t a major concern.\n\nSimple dictionary or symbol table implementations (if the data remains balanced).\n\nCompiler design (e.g., abstract syntax trees in compilers).\n\nBasic educational tools to demonstrate tree traversal and recursion.","type":"content","url":"/xbst-comparisiontable#example-use-cases","position":9},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"2. AVL Tree"},"type":"lvl2","url":"/xbst-comparisiontable#id-2-avl-tree","position":10},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"2. AVL Tree"},"content":"","type":"content","url":"/xbst-comparisiontable#id-2-avl-tree","position":11},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Use when:","lvl2":"2. AVL Tree"},"type":"lvl3","url":"/xbst-comparisiontable#use-when-1","position":12},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Use when:","lvl2":"2. AVL Tree"},"content":"Search operations are frequent and must be as fast as possible.\n\nStrict balancing is necessary to guarantee O(log n) time complexity for all operations.\n\nYou can afford extra space (due to balance factor storage) and a slightly higher insertion/deletion cost.\n\nFast lookups are more critical than insertions/deletions (e.g., read-heavy workloads).","type":"content","url":"/xbst-comparisiontable#use-when-1","position":13},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Example Use Cases:","lvl2":"2. AVL Tree"},"type":"lvl3","url":"/xbst-comparisiontable#example-use-cases-1","position":14},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Example Use Cases:","lvl2":"2. AVL Tree"},"content":"Databases that require many searches but relatively fewer inserts (e.g., in-memory key-value stores).\n\nApplications that require consistent log-time lookups (e.g., indexing large datasets).\n\nGeo-spatial applications where precise balancing affects query performance.\n\nMemory-constrained embedded systems where lookup efficiency is crucial.","type":"content","url":"/xbst-comparisiontable#example-use-cases-1","position":15},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"3. Red-Black Tree"},"type":"lvl2","url":"/xbst-comparisiontable#id-3-red-black-tree","position":16},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"3. Red-Black Tree"},"content":"","type":"content","url":"/xbst-comparisiontable#id-3-red-black-tree","position":17},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Use when:","lvl2":"3. Red-Black Tree"},"type":"lvl3","url":"/xbst-comparisiontable#use-when-2","position":18},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Use when:","lvl2":"3. Red-Black Tree"},"content":"Insertions and deletions occur frequently, and you need a balance between speed and efficiency.\n\nYou need a self-balancing tree but can tolerate a slightly less strict balance than AVL trees.\n\nPerformance is needed in general-purpose programming, where a slight imbalance can be acceptable for faster insertions.\n\nMemory overhead should be lower than AVL trees (RB trees store only one extra bit per node for color).","type":"content","url":"/xbst-comparisiontable#use-when-2","position":19},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Example Use Cases:","lvl2":"3. Red-Black Tree"},"type":"lvl3","url":"/xbst-comparisiontable#example-use-cases-2","position":20},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl3":"Example Use Cases:","lvl2":"3. Red-Black Tree"},"content":"Operating system kernels (e.g., Linux scheduler, memory management).\n\nDatabase indexing (e.g., Red-Black Trees are used in PostgreSQL for some indexing structures).\n\nBalanced associative containers in programming languages (e.g., TreeMap in Java, std::map in C++).\n\nNetworking applications, where frequent insertions and deletions happen (e.g., routing table lookups).","type":"content","url":"/xbst-comparisiontable#example-use-cases-2","position":21},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"Decision Summary:"},"type":"lvl2","url":"/xbst-comparisiontable#decision-summary","position":22},{"hierarchy":{"lvl1":"BST AVL Red Black Tree Comparisons","lvl2":"Decision Summary:"},"content":"Scenario\n\nBest Choice\n\nSimple implementation, small dataset, or learning purposes\n\nBST\n\nFast lookups with rare insertions/deletions (read-heavy workload)\n\nAVL Tree\n\nFrequent insertions/deletions with a balance of efficiency\n\nRed-Black Tree\n\nOS kernels, memory allocators, databases, or language libraries\n\nRed-Black Tree\n\nIf data insertion order is random and balanced naturally\n\nBST (unless performance degrades)\n\nIf data is likely to be inserted in sorted order (worst case for BSTs)\n\nAVL or Red-Black","type":"content","url":"/xbst-comparisiontable#decision-summary","position":23},{"hierarchy":{"lvl1":"Binary Tree Comparisons"},"type":"lvl1","url":"/xbst-comparisons","position":0},{"hierarchy":{"lvl1":"Binary Tree Comparisons"},"content":"","type":"content","url":"/xbst-comparisons","position":1},{"hierarchy":{"lvl1":"Binary Tree Comparisons","lvl2":"Comparison Chart"},"type":"lvl2","url":"/xbst-comparisons#comparison-chart","position":2},{"hierarchy":{"lvl1":"Binary Tree Comparisons","lvl2":"Comparison Chart"},"content":"Feature\n\nBinary Tree\n\nAVL Tree\n\nRed-Black Tree\n\nStructure\n\nNodes have 0 or 2 children\n\nSelf-balancing, height difference between subtrees <= 1\n\nSelf-balancing, specific color properties to maintain balance\n\nData Organization\n\nCan hold any type of data\n\nUsually holds comparable data for efficient search\n\nCan hold any type of data\n\nSearch Performance\n\nO(n) in worst case, O(log n) on average\n\nO(log n) guaranteed\n\nO(log n) guaranteed\n\nInsertion/Deletion Performance\n\nO(n) in worst case, O(log n) on average\n\nO(log n) guaranteed, more complex operations\n\nO(log n) guaranteed, simpler operations than AVL\n\nMemory Usage\n\nMinimum, only 2 pointers per node\n\nSlightly higher than binary tree, stores balance factor\n\nSlightly higher than binary tree, stores color information\n\nApplications\n\nSimple data structures, expression trees\n\nEfficient search and sorting, databases\n\nGeneral purpose, good balance between performance and complexity\n\nPros\n\nSimple to implement, efficient for small datasets\n\nFast search and guaranteed balance\n\nFaster insertions than AVL, simpler operations\n\nCons\n\nCan become unbalanced, leading to poor performance\n\nMore complex to implement than binary tree\n\nNot as strictly balanced as AVL trees, potentially impacting search performance in rare cases","type":"content","url":"/xbst-comparisons#comparison-chart","position":3},{"hierarchy":{"lvl1":"Binary Search Tree - Intro"},"type":"lvl1","url":"/xbst-intro","position":0},{"hierarchy":{"lvl1":"Binary Search Tree - Intro"},"content":"","type":"content","url":"/xbst-intro","position":1},{"hierarchy":{"lvl1":"Binary Search Tree - Intro","lvl2":"Background Information"},"type":"lvl2","url":"/xbst-intro#background-information","position":2},{"hierarchy":{"lvl1":"Binary Search Tree - Intro","lvl2":"Background Information"},"content":"A binary search tree (BST) is a special type of binary tree data structure used to efficiently store and access sorted data. It’s like a regular tree, but with additional rules that keep everything neatly organized:\n\nKey features:\n\nOrdering: Each node in the tree has a value (key), and the key of a node is always greater than all the keys in its left subtree and less than all the keys in its right subtree. This creates a sorted order throughout the tree.\n\nEfficient searching: Because of this ordering, you can very quickly search for specific values in the tree. Imagine searching a phone book - you wouldn’t start at the very beginning or end, but somewhere in the middle based on the last name. Similarly, in a BST, you can efficiently move left or right depending on the value you’re searching for, narrowing down the possibilities with each comparison.\n\nDynamic insertions and deletions: You can easily add new values (insert) or remove existing ones (delete) from the tree while maintaining the sorted order. The process involves comparing the new value with existing nodes and finding its appropriate place based on the ordering rule.\n\nBenefits of using BSTs:\n\nFast search: Searching for elements in a balanced BST takes logarithmic time on average, which is significantly faster than searching an unsorted list.\n\nOrdered access: You can easily traverse the tree in sorted order (e.g., for printing all elements in ascending order).\n\nEfficient insertions and deletions: These operations can also be done in logarithmic time in balanced BSTs.\n\nHowever, BSTs also have some drawbacks:\n\nPerformance depends on balance: The efficiency of BST operations relies heavily on the tree’s balance. An unbalanced tree can perform much worse than a balanced one.\n\nNot self-balancing: By default, BSTs are not self-balancing, meaning insertions and deletions can sometimes lead to imbalances. Special techniques are needed to maintain balance and ensure optimal performance.\n\nOverall, binary search trees are a powerful and versatile data structure for storing and managing sorted data efficiently. They offer fast search, insertion, and deletion operations, making them suitable for various applications like symbol tables, priority queues, and sorting algorithms.","type":"content","url":"/xbst-intro#background-information","position":3},{"hierarchy":{"lvl1":"Demonstrate BST using iterative looping and recursion"},"type":"lvl1","url":"/xbst-iterative-recursion-search","position":0},{"hierarchy":{"lvl1":"Demonstrate BST using iterative looping and recursion"},"content":"This Java program implements a Binary Search Tree (BST) that supports insertion, searching, and in-order traversal. It generates unique random numbers, inserts them into the BST, and allows the user to search for a specific number using both recursive and iterative approaches.\n\nThe Node class defines a BST node with an integer value and left and right child references. The BST class manages the BST operations, including inserting new values, searching for values recursively and iteratively, and performing an in-order traversal to display elements in sorted order.\n\nIn the main method (BST_Recursion_Loops), the program first generates an array of 50 unique random numbers using a HashSet, ensuring all values are distinct. These numbers are inserted into the BST, and an in-order traversal is performed to display the sorted tree contents. The program then prompts the user to enter a search key and performs both iterative and recursive searches to check for its presence, displaying whether the key was found or not.\n\nThis implementation highlights key BST operations and provides a practical demonstration of recursion, loops, and tree traversal techniques in Java.","type":"content","url":"/xbst-iterative-recursion-search","position":1},{"hierarchy":{"lvl1":"Demonstrate BST using iterative looping and recursion","lvl2":"HashSet"},"type":"lvl2","url":"/xbst-iterative-recursion-search#hashset","position":2},{"hierarchy":{"lvl1":"Demonstrate BST using iterative looping and recursion","lvl2":"HashSet"},"content":"A HashSet in Java is a part of the java.util package and implements\nthe Set interface. It is used to store a collection of unique elements,\nmeaning it does not allow duplicate values. It is backed by a HashMap,\nwhich makes its operations fast, typically running in O(1) time complexity\nfor basic operations like add, remove, and contains.\nKey Features of HashSetNo Duplicates –         It does not allow duplicate elements.\nUnordered Collection –  It does not maintain the order of elements.\nAllows Null Values –    It permits a single null value.\nFast Operations –       Add, remove, and search operations are \n                        generally O(1) due to hashing.\nNo Indexing –           Unlike lists,you cannot access elements by an index.","type":"content","url":"/xbst-iterative-recursion-search#hashset","position":3},{"hierarchy":{"lvl1":"Demonstrate BST using iterative looping and recursion","lvl2":"Demo Code"},"type":"lvl2","url":"/xbst-iterative-recursion-search#demo-code","position":4},{"hierarchy":{"lvl1":"Demonstrate BST using iterative looping and recursion","lvl2":"Demo Code"},"content":"/*\n\nDemonstrate iterative and recursive searching\nDeveloper: James Goudy\n */\npackage bst_recursion_loops;\n\nimport java.util.HashSet;\nimport java.util.Random;\nimport java.util.Scanner;\nimport org.w3c.dom.css.Counter;\n\n// Class for a Binary Search Tree Node\nclass Node {\n\n    int value;\n    Node left, right;\n\n    public Node(int item) {\n        value = item;\n        left = right = null;\n    }\n}\n\nclass BST {\n\n    int cntr = 1;\n    Node root;\n\n    // Constructor\n    public BST() {\n        root = null;\n    }\n\n    // Recursive Search Function\n    public boolean searchRecursive(Node root, int key) {\n        // Base case: root is null or key is found\n        if (root == null) {\n            return false;\n        }\n        if (root.value == key) {\n            return true;\n        }\n\n        // If the key is smaller, search in the left subtree\n        if (key < root.value) {\n            return searchRecursive(root.left, key);\n        } else {\n            // If the key is larger, search in the right subtree\n            return searchRecursive(root.right, key);\n        }\n    }\n\n    // Iterative Search Function\n    public boolean searchIterative(Node root, int key) {\n        while (root != null) {\n            if (root.value == key) {\n                return true;\n            } else if (key < root.value) {\n                root = root.left;  // Move to left subtree\n            } else {\n                root = root.right; // Move to right subtree\n            }\n        }\n        return false; // Key not found\n    }\n\n    // Insert function to add nodes to the BST\n    public void insert(int key) {\n        root = insertData(root, key);\n    }\n\n    private Node insertData(Node root, int key) {\n        if (root == null) {\n            root = new Node(key);\n            return root;\n        }\n\n        if (key < root.value) {\n            root.left = insertData(root.left, key);\n        } else if (key > root.value) {\n            root.right = insertData(root.right, key);\n        }\n\n        return root;\n    }\n\n    // Helper function to start recursive search from the root\n    public boolean searchRecursive(int key) {\n        return searchRecursive(root, key);\n    }\n\n    // Helper function to start iterative search from the root\n    public boolean searchIterative(int key) {\n        return searchIterative(root, key);\n    }\n\n    // Inorder Traversal to print the BST\n    public void inorder() {\n        cntr = 1;\n        inorderData(root);\n        System.out.println();\n    }\n\n    private void inorderData(Node root) {\n\n        if (root != null) {\n            cntr++;\n\n            if (cntr % 10 == 0 && cntr > 1) {\n                System.out.println(\"\");\n            }\n\n            \n\n            inorderData(root.left);\n            System.out.print(root.value + \" \");\n            inorderData(root.right);\n\n        }\n\n    }\n\n}\n\npublic class BST_Recursion_Loops {\n\n    public static int[] generateUniqueArray(int size) {\n\n        // create new HashSet\n        HashSet<Integer> uniqueNumbers = new HashSet<>();\n\n        Random rng = new Random();\n\n        // Fill the set with unique random numbers\n        while (uniqueNumbers.size() < size) {\n            // Generates numbers from 0 to 999\n            uniqueNumbers.add(rng.nextInt(1000));\n        }\n\n        // Convert HashSet to an array\n        int[] result = new int[size];\n        int index = 0;\n        for (int num : uniqueNumbers) {\n            result[index++] = num;\n        }\n\n        return result;\n    }\n\n    public static void main(String[] args) {\n\n        // create sample data\n        int[] sampleKeys;\n        int numOfKeys = 50;\n        int searchKey = 0;\n        String status;\n        \n        \n        \n        Scanner myScan = new Scanner(System.in);\n        BST myBST = new BST();\n\n        sampleKeys = generateUniqueArray(numOfKeys);\n\n        System.out.println(\"\\nInput Data\\n\");\n        for (int i = 0; i < sampleKeys.length; i++) {\n            myBST.insert(sampleKeys[i]);\n            System.out.print(sampleKeys[i] + \" \");\n\n            if (i % 10 == 0 && i > 0) {\n                System.out.println(\"\");\n            }\n        }\n\n        System.out.println(\"\\n-----------------------------\\n\");\n\n        myBST.inorder();\n        \n        System.out.print(\" Enter Search Key: \");\n        searchKey = Integer.parseInt(myScan.nextLine());\n        \n        System.out.println(\"\\nSearch Iteratively\");\n        status = myBST.searchIterative(searchKey)? \"Found\" : \"Not Found\";\n        System.out.println(\"The items was - \" + status);\n        \n        System.out.println(\"\\nSearch Recursively\");\n        status = myBST.searchRecursive(searchKey)? \"Found\" : \"Not Found\";\n        System.out.println(\"The items was - \" + status);\n        \n\n    }\n\n}","type":"content","url":"/xbst-iterative-recursion-search#demo-code","position":5},{"hierarchy":{"lvl1":"Red Black Tree"},"type":"lvl1","url":"/xbst-redblack","position":0},{"hierarchy":{"lvl1":"Red Black Tree"},"content":"A Red-Black Tree is a type of self-balancing binary search tree in computer science. Let’s delve into its fascinating properties:\n\nStructure and Color:\n\nEach node in a Red-Black Tree has an extra bit that represents its color (either red or black).\n\nThese color bits are used to ensure that the tree remains approximately balanced during insertions and deletions.\n\nThe tree’s structure guarantees that operations like searching, insertion, and deletion complete within a known time.\n\nProperties of Red-Black Trees:\n\nRoot Property: The root node is always black.\n\nExternal Property: Every leaf (which is a NULL child of a node) is black.\n\nInternal Property: The children of a red node are black. Thus, a red node’s possible parent is a black node.\n\nDepth Property: All leaves have the same black depth.\n\nPath Property: Every simple path from the root to a descendant leaf node contains the same number of black nodes.\n\nWhy Red-Black Trees?:\n\nMost Binary Search Tree (BST) operations (e.g., search, max, min, insert, delete) take O(h) time, where h is the height of the BST.\n\nIf we ensure that the tree’s height remains O(log n) after every insertion and deletion, we guarantee an upper bound of O(log n) for all these operations.\n\nThe height of a Red-Black tree is always O(log n), where n is the number of nodes in the tree.","type":"content","url":"/xbst-redblack","position":1},{"hierarchy":{"lvl1":"Red Black Tree","lvl2":"Insertion Process"},"type":"lvl2","url":"/xbst-redblack#insertion-process","position":2},{"hierarchy":{"lvl1":"Red Black Tree","lvl2":"Insertion Process"},"content":"Initial Setup:\n\nWhen inserting a new node, it is initially colored red.\n\nIf the tree is empty, the new node becomes the root (colored black).\n\nOtherwise, we insert the node as a leaf (colored red).\n\nInsertion Algorithm:\n\nPerform a standard BST insertion (similar to a regular binary search tree).\n\nColor the newly inserted nodes as RED.\n\nIf the newly inserted node is the root, change its color to BLACK (increasing the black height of the tree by 1).\n\nBalancing Steps:\n\nIf the parent of the newly inserted node is not BLACK and the node is not the root :\n\nCase 1: If the uncle of the node is RED :\n\nChange the color of the parent and uncle to BLACK.\n\nChange the color of the grandparent to RED.\n\nRepeat steps 2 and 3 for the new grandparent.\n\nCase 2: If the uncle is BLACK :\n\nThere are four possible configurations (similar to AVL Tree rotations):\n\nLeft Left Case (LL rotation)\n\nLeft Right Case (LR rotation)\n\nRight Right Case (RR rotation)\n\nRight Left Case (RL rotation)\n\nAfter these rotations, re-color according to the rotation case.\n\nRe-coloring after Rotations:\n\nFor Left Left Case and Right Right Case, swap colors of grandparent and parent after rotations.\n\nFor Left Right Case and Right Left Case, swap colors of grandparent and inserted node after rotations.","type":"content","url":"/xbst-redblack#insertion-process","position":3},{"hierarchy":{"lvl1":"Red Black Tree","lvl2":"Deletion Process"},"type":"lvl2","url":"/xbst-redblack#deletion-process","position":4},{"hierarchy":{"lvl1":"Red Black Tree","lvl2":"Deletion Process"},"content":"Initial Setup:\n\nWhen deleting a node, it can fall into three cases:\n\nThe node has no children: Simply remove it and update the parent node.\n\nThe node has one child: Replace the node with its child.\n\nThe node has two children: Replace the node with its in-order successor, which is the leftmost node in the right subtree.\n\nDeletion Algorithm:\n\nPerform a standard BST delete operation (similar to regular binary search tree deletion).\n\nColor the newly inserted nodes as RED.\n\nIf the deleted node was BLACK, we introduce the concept of double black (marking the replacement child as double black).\n\nBalancing Steps:\n\nAfter deletion, the Red-Black Tree properties might be violated.\n\nTo restore these properties, perform color changes and rotations similar to those during insertion, but with different conditions.\n\nThe main goal is to convert the double black node back to a single black node.\n\nThe cases for restructuring and recoloring are determined by the color of the sibling of the double black node.","type":"content","url":"/xbst-redblack#deletion-process","position":5},{"hierarchy":{"lvl1":"Red Black Tree","lvl2":"RED BLACK Class"},"type":"lvl2","url":"/xbst-redblack#red-black-class","position":6},{"hierarchy":{"lvl1":"Red Black Tree","lvl2":"RED BLACK Class"},"content":"/*\n * To change this license header, choose License Headers in Project Properties.\n * To change this template file, choose Tools | Templates\n * and open the template in the editor.\n */\n\n\nimport java.util.Random;\n\npublic class RedBlackTree\n{\n\n    //An inner nested class can be declared private and only accessed\n    //within the class\n    //A inner nested class can be declared static and can be accessed\n    //from outside the class. \n    //Example in main or other function outside of class\n    // RedBlackTree.Node tempNode = new RedBlackTree.Node(); \n    \n    static class Node\n    {\n\n        int key; // holds the key\n        Node parent; // pointer to the parent\n        Node left; // pointer to left child\n        Node right; // pointer to right child\n        int color; // 1 . Red, 0 . Black\n\n        //some data - in this case string\n        String sdata;\n    }\n\n    private Node root;\n    private Node TNULL;\n\n    private void preOrderHelper(Node node)\n    {\n        if (node != TNULL)\n        {\n            System.out.print(node.key + \" \");\n            preOrderHelper(node.left);\n            preOrderHelper(node.right);\n        }\n    }\n\n    private void inOrderHelper(Node node)\n    {\n        if (node != TNULL)\n        {\n            inOrderHelper(node.left);\n            System.out.print(node.key + \" \");\n            inOrderHelper(node.right);\n        }\n    }\n\n    private void postOrderHelper(Node node)\n    {\n        if (node != TNULL)\n        {\n            postOrderHelper(node.left);\n            postOrderHelper(node.right);\n            System.out.print(node.key + \" \");\n        }\n    }\n\n    void preOrder()\n    {\n        System.out.println(\"\\nPreOder\");\n        Node node = root;\n        if (node != TNULL)\n        {\n            System.out.print(\" **\" + node.key + \"** \");\n            preOrderHelper(node.left);\n            preOrderHelper(node.right);\n        }\n        System.out.println(\"\\n------------------\\n\");\n    }\n\n    // In-Order traversal\n    // Left Subtree . Node . Right Subtree\n    public void inOrder()\n    {\n        System.out.println(\"\\ninOder\");\n        Node node = root;\n        if (node != TNULL)\n        {\n            inOrderHelper(node.left);\n            System.out.print(\" **\" + node.key + \"** \");\n            inOrderHelper(node.right);\n        }\n        System.out.println(\"\\n------------------\\n\");\n    }\n\n    // Post-Order traversal\n    // Left Subtree . Right Subtree . Node\n    public void postOrder()\n    {\n        System.out.println(\"\\npostOder\");\n        Node node = root;\n        if (node != TNULL)\n        {\n            postOrderHelper(node.left);\n            postOrderHelper(node.right);\n            System.out.print(\" **\" + node.key + \"** \");\n        }\n        System.out.println(\"\\n------------------\\n\");\n    }\n\n    // search the tree for the key k\n    // and return the corresponding node\n    public Node searchTree(int k)\n    {\n        return searchTreeHelper(this.root, k);\n    }\n\n    private Node searchTreeHelper(Node node, int key)\n    {\n        if (node == TNULL || key == node.key)\n        {\n            //if(node == null)\n\n            return node;\n        }\n\n        if (key < node.key)\n        {\n            return searchTreeHelper(node.left, key);\n        }\n        return searchTreeHelper(node.right, key);\n    }\n\n    // fix the rb tree modified by the delete operation\n    private void fixDelete(Node x)\n    {\n        Node s;\n        while (x != root && x.color == 0)\n        {\n            if (x == x.parent.left)\n            {\n                s = x.parent.right;\n                if (s.color == 1)\n                {\n                    // case 3.1\n                    s.color = 0;\n                    x.parent.color = 1;\n                    leftRotate(x.parent);\n                    s = x.parent.right;\n                }\n\n                if (s.left.color == 0 && s.right.color == 0)\n                {\n                    // case 3.2\n                    s.color = 1;\n                    x = x.parent;\n                } else\n                {\n                    if (s.right.color == 0)\n                    {\n                        // case 3.3\n                        s.left.color = 0;\n                        s.color = 1;\n                        rightRotate(s);\n                        s = x.parent.right;\n                    }\n\n                    // case 3.4\n                    s.color = x.parent.color;\n                    x.parent.color = 0;\n                    s.right.color = 0;\n                    leftRotate(x.parent);\n                    x = root;\n                }\n            } else\n            {\n                s = x.parent.left;\n                if (s.color == 1)\n                {\n                    // case 3.1\n                    s.color = 0;\n                    x.parent.color = 1;\n                    rightRotate(x.parent);\n                    s = x.parent.left;\n                }\n\n                if (s.right.color == 0 && s.right.color == 0)\n                {\n                    // case 3.2\n                    s.color = 1;\n                    x = x.parent;\n                } else\n                {\n                    if (s.left.color == 0)\n                    {\n                        // case 3.3\n                        s.right.color = 0;\n                        s.color = 1;\n                        leftRotate(s);\n                        s = x.parent.left;\n                    }\n\n                    // case 3.4\n                    s.color = x.parent.color;\n                    x.parent.color = 0;\n                    s.left.color = 0;\n                    rightRotate(x.parent);\n                    x = root;\n                }\n            }\n        }\n        x.color = 0;\n    }\n\n    private void rbTransplant(Node u, Node v)\n    {\n        if (u.parent == null)\n        {\n            root = v;\n        } else if (u == u.parent.left)\n        {\n            u.parent.left = v;\n        } else\n        {\n            u.parent.right = v;\n        }\n        v.parent = u.parent;\n    }\n\n    private void deleteNodeHelper(Node node, int key)\n    {\n        // find the node containing key\n        Node z = TNULL;\n        Node x, y;\n        while (node != TNULL)\n        {\n            if (node.key == key)\n            {\n                z = node;\n            }\n\n            if (node.key <= key)\n            {\n                node = node.right;\n            } else\n            {\n                node = node.left;\n            }\n        }\n\n        if (z == TNULL)\n        {\n            System.out.println(\"Couldn't find key in the tree\");\n            return;\n        }\n\n        y = z;\n        int yOriginalColor = y.color;\n        if (z.left == TNULL)\n        {\n            x = z.right;\n            rbTransplant(z, z.right);\n        } else if (z.right == TNULL)\n        {\n            x = z.left;\n            rbTransplant(z, z.left);\n        } else\n        {\n            y = minimum(z.right);\n            yOriginalColor = y.color;\n            x = y.right;\n            if (y.parent == z)\n            {\n                x.parent = y;\n            } else\n            {\n                rbTransplant(y, y.right);\n                y.right = z.right;\n                y.right.parent = y;\n            }\n\n            rbTransplant(z, y);\n            y.left = z.left;\n            y.left.parent = y;\n            y.color = z.color;\n        }\n        if (yOriginalColor == 0)\n        {\n            fixDelete(x);\n        }\n    }\n\n    // fix the red-black tree\n    private void fixInsert(Node k)\n    {\n        Node u;\n        while (k.parent.color == 1)\n        {\n            if (k.parent == k.parent.parent.right)\n            {\n                u = k.parent.parent.left; // uncle\n                if (u.color == 1)\n                {\n                    // case 3.1\n                    u.color = 0;\n                    k.parent.color = 0;\n                    k.parent.parent.color = 1;\n                    k = k.parent.parent;\n                } else\n                {\n                    if (k == k.parent.left)\n                    {\n                        // case 3.2.2\n                        k = k.parent;\n                        rightRotate(k);\n                    }\n                    // case 3.2.1\n                    k.parent.color = 0;\n                    k.parent.parent.color = 1;\n                    leftRotate(k.parent.parent);\n                }\n            } else\n            {\n                u = k.parent.parent.right; // uncle\n\n                if (u.color == 1)\n                {\n                    // mirror case 3.1\n                    u.color = 0;\n                    k.parent.color = 0;\n                    k.parent.parent.color = 1;\n                    k = k.parent.parent;\n                } else\n                {\n                    if (k == k.parent.right)\n                    {\n                        // mirror case 3.2.2\n                        k = k.parent;\n                        leftRotate(k);\n                    }\n                    // mirror case 3.2.1\n                    k.parent.color = 0;\n                    k.parent.parent.color = 1;\n                    rightRotate(k.parent.parent);\n                }\n            }\n            if (k == root)\n            {\n                break;\n            }\n        }\n        root.color = 0;\n    }\n\n    private void printHelper(Node root, String indent, boolean last)\n    {\n        // print the tree structure on the screen\n        if (root != TNULL)\n        {\n            System.out.print(indent);\n            if (last)\n            {\n                System.out.print(\"R----\");\n                indent += \"     \";\n            } else\n            {\n                System.out.print(\"L----\");\n                indent += \"|    \";\n            }\n\n            String sColor = root.color == 1 ? \"RED\" : \"BLACK\";\n            System.out.println(root.key + \"-\" + root.sdata\n                    + \"(\" + sColor + \")\");\n            printHelper(root.left, indent, false);\n            printHelper(root.right, indent, true);\n        }\n    }\n\n    public RedBlackTree()\n    {\n        TNULL = new Node();\n        TNULL.color = 0;\n        TNULL.left = null;\n        TNULL.right = null;\n        root = TNULL;\n    }\n\n    // find the node with the minimum key\n    public Node minimum(Node node)\n    {\n        while (node.left != TNULL)\n        {\n            node = node.left;\n        }\n        return node;\n    }\n\n    // find the node with the maximum key\n    public Node maximum(Node node)\n    {\n        while (node.right != TNULL)\n        {\n            node = node.right;\n        }\n        return node;\n    }\n\n    // find the successor of a given node\n    public Node successor(Node x)\n    {\n        // if the right subtree is not null,\n        // the successor is the leftmost node in the\n        // right subtree\n        if (x.right != TNULL)\n        {\n            return minimum(x.right);\n        }\n\n        // else it is the lowest ancestor of x whose\n        // left child is also an ancestor of x.\n        Node y = x.parent;\n        while (y != TNULL && x == y.right)\n        {\n            x = y;\n            y = y.parent;\n        }\n        return y;\n    }\n\n    // find the predecessor of a given node\n    public Node predecessor(Node x)\n    {\n        // if the left subtree is not null,\n        // the predecessor is the rightmost node in the \n        // left subtree\n        if (x.left != TNULL)\n        {\n            return maximum(x.left);\n        }\n\n        Node y = x.parent;\n        while (y != TNULL && x == y.left)\n        {\n            x = y;\n            y = y.parent;\n        }\n\n        return y;\n    }\n\n    // rotate left at node x\n    public void leftRotate(Node x)\n    {\n        Node y = x.right;\n        x.right = y.left;\n        if (y.left != TNULL)\n        {\n            y.left.parent = x;\n        }\n        y.parent = x.parent;\n        if (x.parent == null)\n        {\n            this.root = y;\n        } else if (x == x.parent.left)\n        {\n            x.parent.left = y;\n        } else\n        {\n            x.parent.right = y;\n        }\n        y.left = x;\n        x.parent = y;\n    }\n\n    // rotate right at node x\n    public void rightRotate(Node x)\n    {\n        Node y = x.left;\n        x.left = y.right;\n        if (y.right != TNULL)\n        {\n            y.right.parent = x;\n        }\n        y.parent = x.parent;\n        if (x.parent == null)\n        {\n            this.root = y;\n        } else if (x == x.parent.right)\n        {\n            x.parent.right = y;\n        } else\n        {\n            x.parent.left = y;\n        }\n        y.right = x;\n        x.parent = y;\n    }\n\n    // insert the key to the tree in its appropriate position\n    // and fix the tree\n    public void insert(int key, String sdata)\n    {\n        // Ordinary Binary Search Insertion\n        Node node = new Node();\n        node.parent = null;\n        node.key = key;\n\n        node.sdata = sdata;\n\n        node.left = TNULL;\n        node.right = TNULL;\n        node.color = 1; // new node must be red\n\n        Node y = null;\n        Node x = this.root;\n\n        while (x != TNULL)\n        {\n            y = x;\n            if (node.key < x.key)\n            {\n                x = x.left;\n            } else\n            {\n                x = x.right;\n            }\n        }\n\n        // y is parent of x\n        node.parent = y;\n        if (y == null)\n        {\n            root = node;\n        } else if (node.key < y.key)\n        {\n            y.left = node;\n        } else\n        {\n            y.right = node;\n        }\n\n        // if new node is a root node, simply return\n        if (node.parent == null)\n        {\n            node.color = 0;\n            return;\n        }\n\n        // if the grandparent is null, simply return\n        if (node.parent.parent == null)\n        {\n            return;\n        }\n\n        // Fix the tree\n        fixInsert(node);\n    }\n\n    public Node getRoot()\n    {\n        return this.root;\n    }\n\n    // delete the node from the tree\n    public void deleteNode(int key)\n    {\n        deleteNodeHelper(this.root, key);\n    }\n\n    // print the tree structure on the screen\n    public void prettyPrint()\n    {\n        printHelper(this.root, \"\", true);\n    }\n\n   // static RedBlackTree bst = new RedBlackTree();\n\n    void insertRandom()\n    {\n        int amt = 12;\n        int amts = 5;\n        int amtNodes, amtLetters;\n        int[] keys;\n\n        int selectKey = -1;\n        int selectIndex = -1;\n        boolean run = true;\n\n        String numberOrder = \"\";\n        int numberOrderCount = 0;\n\n        Random RNG = new Random();\n        amtNodes = RNG.nextInt(amt);\n        //amtNodes = 15; //hard code the amount \n        amtLetters = 3;\n\n        System.out.println(amtNodes);\n        keys = new int[amtNodes];\n\n        //load keys\n        for (int i = 0; i < keys.length; i++)\n        {\n            keys[i] = i;\n        }\n\n        for (int i = 0; i < amtNodes; i++)\n        {\n            //create random letter patterns\n            String ld = \"\";\n            for (int j = 0; j < amtLetters; j++)\n            {\n                ld = ld + (char) (RNG.nextInt(25) + 65);\n            }\n\n            //pick random key\n            int cntr = 0;\n            selectIndex = RNG.nextInt(amtNodes);\n\n            selectKey = keys[selectIndex];\n            run = true;\n            while (run)\n            {\n\n                if (selectKey > -1)\n                {\n                    run = false;\n                } else\n                {\n                    selectIndex = selectIndex + 1;\n                    if (selectIndex >= amtNodes)\n                    {\n                        selectIndex = 0;\n                    }\n\n                }\n                selectKey = keys[selectIndex];\n\n            }\n            //System.out.print(selectKey + \" \");\n\n            numberOrder = numberOrder + selectKey + \" \";\n            numberOrderCount++;\n            if (numberOrderCount > 20)\n            {\n                numberOrder = numberOrder + \"\\n\";\n                numberOrderCount = 0;\n\n            }\n\n            insert(selectKey, ld);\n            keys[selectKey] = -1;\n        }\n        System.out.println(\"\\n\" + numberOrder + \"\\n\");\n        System.out.println(\"\");\n\n    }\n\n}\n","type":"content","url":"/xbst-redblack#red-black-class","position":7},{"hierarchy":{"lvl1":"Splay Trees"},"type":"lvl1","url":"/xbst-splaytrees-2025","position":0},{"hierarchy":{"lvl1":"Splay Trees"},"content":"","type":"content","url":"/xbst-splaytrees-2025","position":1},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Splay Trees"},"type":"lvl2","url":"/xbst-splaytrees-2025#splay-trees","position":2},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Splay Trees"},"content":"A splay tree is a type of self-adjusting binary search tree (BST) where recently accessed elements are moved to the root of the tree using a process called splaying. This helps ensure that frequently accessed elements are quicker to access.","type":"content","url":"/xbst-splaytrees-2025#splay-trees","position":3},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Who Invented It:"},"type":"lvl2","url":"/xbst-splaytrees-2025#who-invented-it","position":4},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Who Invented It:"},"content":"Splay trees were invented by Daniel Sleator and Robert Tarjan in 1985. The invention was part of their research on self-adjusting data structures.","type":"content","url":"/xbst-splaytrees-2025#who-invented-it","position":5},{"hierarchy":{"lvl1":"Splay Trees","lvl3":"When Was It Invented:","lvl2":"Who Invented It:"},"type":"lvl3","url":"/xbst-splaytrees-2025#when-was-it-invented","position":6},{"hierarchy":{"lvl1":"Splay Trees","lvl3":"When Was It Invented:","lvl2":"Who Invented It:"},"content":"The splay tree was introduced in 1985.","type":"content","url":"/xbst-splaytrees-2025#when-was-it-invented","position":7},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Major Uses:"},"type":"lvl2","url":"/xbst-splaytrees-2025#major-uses","position":8},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Major Uses:"},"content":"Dynamic sets: Splay trees are used to maintain a dynamic set of elements that can support a variety of search and update operations.\n\nMemory-efficient: Since splay trees do not require additional space for balancing data like AVL trees or Red-Black trees, they can be more memory-efficient.\n\nEfficient in practice for certain workloads: Splay trees perform well when there are repeated accesses to a small subset of elements (i.e., the access pattern exhibits locality).","type":"content","url":"/xbst-splaytrees-2025#major-uses","position":9},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Typical Applications:"},"type":"lvl2","url":"/xbst-splaytrees-2025#typical-applications","position":10},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Typical Applications:"},"content":"Cache systems: Frequently accessed items bubble to the front.\n\nText editors: Recently opened files or commands can be organized in a splay list.\n\nAutocomplete lists: Recently or frequently used search terms are moved to the front.","type":"content","url":"/xbst-splaytrees-2025#typical-applications","position":11},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Insert Function:"},"type":"lvl2","url":"/xbst-splaytrees-2025#insert-function","position":12},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Insert Function:"},"content":"Insertion in a splay tree is similar to that in a regular binary search tree. The node is inserted following the normal BST rules. However, after insertion, the tree is “splayed” to bring the newly inserted node to the root.public void insert(int value) {\n    root = insertRec(root, value);\n    splay(root, value);\n}\n\nprivate Node insertRec(Node root, int value) {\n    if (root == null) {\n        root = new Node(value);\n        return root;\n    }\n\n    if (value < root.data) {\n        root.left = insertRec(root.left, value);\n    } else if (value > root.data) {\n        root.right = insertRec(root.right, value);\n    }\n\n    return root;\n}","type":"content","url":"/xbst-splaytrees-2025#insert-function","position":13},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Delete Function:"},"type":"lvl2","url":"/xbst-splaytrees-2025#delete-function","position":14},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Delete Function:"},"content":"Deletion is performed in the same way as in a normal binary search tree. After finding the node to delete, it is removed, and then the tree is splayed to restore the tree’s structure.public void delete(int value) {\n    root = deleteRec(root, value);\n}\n\nprivate Node deleteRec(Node root, int value) {\n    if (root == null) return root;\n\n    if (value < root.data) {\n        root.left = deleteRec(root.left, value);\n    } else if (value > root.data) {\n        root.right = deleteRec(root.right, value);\n    } else {\n        // node with value found\n        if (root.left == null) return root.right;\n        else if (root.right == null) return root.left;\n    }\n\n    return root;\n}","type":"content","url":"/xbst-splaytrees-2025#delete-function","position":15},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Find Function:"},"type":"lvl2","url":"/xbst-splaytrees-2025#find-function","position":16},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Find Function:"},"content":"The find function searches for a value in the tree, and if the value is found, it performs a splay operation to bring that value to the root. If the value is not found, the tree remains unchanged.public boolean find(int value) {\n    root = splay(root, value);\n    return (root != null && root.data == value);\n}","type":"content","url":"/xbst-splaytrees-2025#find-function","position":17},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Rules for Rotations:"},"type":"lvl2","url":"/xbst-splaytrees-2025#rules-for-rotations","position":18},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Rules for Rotations:"},"content":"Splay trees use three types of rotations to adjust the tree during splaying:\n\nZig: When the node is the child of the root.\n\nZig-Zig: When the node is the left or right child of a left or right child (two-level deep).\n\nZig-Zag: When the node is the left child of the right child or the right child of the left child.","type":"content","url":"/xbst-splaytrees-2025#rules-for-rotations","position":19},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Rotations:"},"type":"lvl2","url":"/xbst-splaytrees-2025#rotations","position":20},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Rotations:"},"content":"Single Rotation (Zig): If the node is the child of the root, perform a single rotation (right or left depending on the situation).\n\nDouble Rotation (Zig-Zig or Zig-Zag): In these cases, two rotations are needed. They help in cases where the tree has more than one level to adjust.private Node splay(Node root, int value) {\n    if (root == null || root.data == value) return root;\n\n    if (value < root.data) {\n        if (root.left == null) return root;\n        if (value < root.left.data) {\n            root.left.left = splay(root.left.left, value);\n            root = rotateRight(root);\n        } else if (value > root.left.data) {\n            root.left.right = splay(root.left.right, value);\n            if (root.left.right != null) {\n                root.left = rotateLeft(root.left);\n            }\n        }\n        return (root.left == null) ? root : rotateRight(root);\n    } else {\n        if (root.right == null) return root;\n        if (value > root.right.data) {\n            root.right.right = splay(root.right.right, value);\n            root = rotateLeft(root);\n        } else if (value < root.right.data) {\n            root.right.left = splay(root.right.left, value);\n            if (root.right.left != null) {\n                root.right = rotateRight(root.right);\n            }\n        }\n        return (root.right == null) ? root : rotateLeft(root);\n    }\n}","type":"content","url":"/xbst-splaytrees-2025#rotations","position":21},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Java Program Demonstrating Insert, Find, Delete, and Pretty Print:"},"type":"lvl2","url":"/xbst-splaytrees-2025#java-program-demonstrating-insert-find-delete-and-pretty-print","position":22},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Java Program Demonstrating Insert, Find, Delete, and Pretty Print:"},"content":"package inst_splay_2025;\n\nclass SplayTree {\n\n    private Node root;\n\n    // Inner class representing a node in the splay tree\n    class Node {\n\n        int data;\n        Node left, right;\n\n        public Node(int item)\n        {\n            data = item;\n            left = right = null;\n        }\n    }\n\n    // Inserts a value into the tree\n    public void insert(int value)\n    {\n        if (root == null) {\n            root = new Node(value);\n            return;\n        }\n\n        // Splay the tree to bring the value (or closest) to the root\n        root = splay(root, value);\n\n        // If the value already exists, no need to insert\n        if (root.data == value) {\n            return;\n        }\n\n        Node newNode = new Node(value);\n\n        // If the new value is smaller, make the new node root and adjust pointers\n        if (value < root.data) {\n            newNode.right = root;\n            newNode.left = root.left;\n            root.left = null;\n        } else { // If the new value is greater\n            newNode.left = root;\n            newNode.right = root.right;\n            root.right = null;\n        }\n\n        root = newNode; // Update root\n    }\n\n    // Searches for a value in the tree\n    public boolean find(int value)\n    {\n        root = splay(root, value);\n        return (root != null && root.data == value);\n    }\n\n    // Deletes a node with the given value\n    public void delete(int value)\n    {\n        if (root == null) {\n            return;\n        }\n\n        // Splay the tree so that the value (or closest) is at the root\n        root = splay(root, value);\n\n        if (root.data != value) {\n            return; // If not found, do nothing\n        }\n        if (root.left == null) {\n            root = root.right;\n        } else {\n            Node temp = root;\n            // Splay the largest node in the left subtree to make it new root\n            root = splay(root.left, value);\n            root.right = temp.right;\n        }\n    }\n\n    // Right rotation (Zig rotation)\n    private Node rotateRight(Node root)\n    {\n        if (root == null || root.left == null) {\n            return root;\n        }\n        Node newRoot = root.left;\n        root.left = newRoot.right;\n        newRoot.right = root;\n        return newRoot;\n    }\n\n    // Left rotation (Zag rotation)\n    private Node rotateLeft(Node root)\n    {\n        if (root == null || root.right == null) {\n            return root;\n        }\n        Node newRoot = root.right;\n        root.right = newRoot.left;\n        newRoot.left = root;\n        return newRoot;\n    }\n\n    /*\n     * Splay Operation: Moves the given value to the root if present, or the closest value.\n     * \n     * Splay tree follows these rules for rotations:\n     * \n     * - Zig Rotation (Single Right): When the value is in the left child of the root.\n     * - Zag Rotation (Single Left): When the value is in the right child of the root.\n     * - Zig-Zig (Double Right Rotation): When the value is in the left child of the left child.\n     * - Zag-Zag (Double Left Rotation): When the value is in the right child of the right child.\n     * - Zig-Zag (Left-Right Rotation): When the value is in the right child of the left child.\n     * - Zag-Zig (Right-Left Rotation): When the value is in the left child of the right child.\n     */\n    private Node splay(Node root, int value)\n    {\n        if (root == null || root.data == value) {\n            return root;\n        }\n\n        if (value < root.data) {\n            if (root.left == null) {\n                return root;\n            }\n\n            // Zig-Zig case (left-left)\n            if (value < root.left.data) {\n                root.left.left = splay(root.left.left, value);\n                root = rotateRight(root);\n            } // Zig-Zag case (left-right)\n            else if (value > root.left.data) {\n                root.left.right = splay(root.left.right, value);\n                if (root.left.right != null) {\n                    root.left = rotateLeft(root.left);\n                }\n            }\n\n            // Perform a final Zig rotation\n            return (root.left == null) ? root : rotateRight(root);\n        } else {\n            if (root.right == null) {\n                return root;\n            }\n\n            // Zag-Zag case (right-right)\n            if (value > root.right.data) {\n                root.right.right = splay(root.right.right, value);\n                root = rotateLeft(root);\n            } // Zag-Zig case (right-left)\n            else if (value < root.right.data) {\n                root.right.left = splay(root.right.left, value);\n                if (root.right.left != null) {\n                    root.right = rotateRight(root.right);\n                }\n            }\n\n            // Perform a final Zag rotation\n            return (root.right == null) ? root : rotateLeft(root);\n        }\n    }\n\n    // Prints the tree structure\n    public void prettyPrint(Node root, String indent)\n    {\n        if (root == null) {\n            return;\n        }\n        prettyPrint(root.right, indent + \"   \");\n        System.out.println(indent + root.data);\n        prettyPrint(root.left, indent + \"   \");\n    }\n\n    // Initiates tree printing\n    public void printTree()\n    {\n        prettyPrint(root, \"\");\n    }\n}\n\n// Driver class to test the Splay Tree implementation\npublic class Inst_splay_2025 {\n\n    public static void main(String[] args)\n    {\n        SplayTree tree = new SplayTree();\n\n        tree.insert(10);\n        tree.insert(20);\n        tree.insert(5);\n        tree.insert(55);\n        tree.insert(60);\n        tree.insert(65);\n        tree.insert(70);\n        tree.insert(75);\n        tree.insert(30);\n        tree.insert(15);\n        tree.insert(25);\n\n        tree.printTree();\n        System.out.println(\"\\n----------------\\n\");\n\n        tree.find(20);\n        tree.printTree();\n        System.out.println(\"\\n----------------\\n\");\n\n        tree.find(5);\n        tree.printTree();\n        System.out.println(\"\\n----------------\\n\");\n\n        tree.find(65);\n        tree.printTree();\n        System.out.println(\"\\n----------------\\n\");\n\n        tree.delete(10);\n        tree.printTree();\n        System.out.println(\"\\n----------------\\n\");\n\n        tree.delete(30);\n        tree.printTree();\n        System.out.println(\"\\n----------------\\n\");\n\n        tree.delete(15);\n        tree.printTree();\n        System.out.println(\"\\n----------------\\n\");\n\n        tree.delete(5);\n        tree.printTree();\n    }\n}\n\n","type":"content","url":"/xbst-splaytrees-2025#java-program-demonstrating-insert-find-delete-and-pretty-print","position":23},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Explanation of Rotation Rules:"},"type":"lvl2","url":"/xbst-splaytrees-2025#explanation-of-rotation-rules","position":24},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Explanation of Rotation Rules:"},"content":"Zig (Single Rotation): If the node to be accessed is the left or right child of the root, perform a single rotation (either left or right).\n\nZig-Zig (Double Rotation): If the node is the left or right child of a left or right child (two levels deep), perform two rotations. This optimizes the tree by rotating both the node and its parent.\n\nZig-Zag (Double Rotation): If the node is the left child of the right child, or the right child of the left child (mixed child directions), perform a rotation on the child followed by a rotation on the node itself.\n\nThis program demonstrates how to use splay tree operations and includes helpful comments and explanations of the rotation rules. Each rotation helps ensure the tree remains balanced by moving frequently accessed nodes towards the root.","type":"content","url":"/xbst-splaytrees-2025#explanation-of-rotation-rules","position":25},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Splay using for loops"},"type":"lvl2","url":"/xbst-splaytrees-2025#splay-using-for-loops","position":26},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Splay using for loops"},"content":"This version avoids the recursive calls and uses loops to handle the tree traversal and adjustments.class SplayTree {\n    private Node root;\n\n    // Node class to represent each node in the tree\n    class Node {\n        int data;  // Data stored in the node\n        Node left, right;  // Left and right child nodes\n\n        // Constructor to create a new node with the given value\n        public Node(int item) {\n            data = item;\n            left = right = null;\n        }\n    }\n\n    // Insert function to add a new value into the splay tree\n    public void insert(int value) {\n        if (root == null) {\n            root = new Node(value);  // If tree is empty, create a new node as root\n            return;\n        }\n\n        Node node = root;\n        Node parent = null;\n\n        // Loop to find the correct position for insertion\n        while (node != null) {\n            parent = node;\n            if (value < node.data) {\n                node = node.left;\n            } else if (value > node.data) {\n                node = node.right;\n            } else {\n                return;  // If the value is already present, do nothing\n            }\n        }\n\n        // Create a new node and attach it to the parent\n        node = new Node(value);\n        if (value < parent.data) {\n            parent.left = node;\n        } else {\n            parent.right = node;\n        }\n\n        // After insertion, splay the tree to bring the inserted node to the root\n        root = splay(root, value);\n    }\n\n    // Delete function to remove a node from the splay tree\n    public void delete(int value) {\n        if (root == null) return;\n\n        // Splay the tree to bring the node to be deleted to the root\n        root = splay(root, value);\n\n        if (root == null || root.data != value) return;  // Node not found\n\n        // Node to be deleted is at the root\n        if (root.left == null) {\n            root = root.right;  // If left child is null, replace root with right child\n        } else {\n            Node rightSubtree = root.right;\n            root = root.left;\n            root = splay(root, value);  // Splay the left subtree to bring the max element to the root\n            root.right = rightSubtree;  // Attach the right subtree to the new root\n        }\n    }\n\n    // Find function to search for a value in the splay tree\n    public boolean find(int value) {\n        if (root == null) return false;\n\n        // Splay the tree to bring the searched node to the root\n        root = splay(root, value);\n\n        return (root != null && root.data == value);\n    }\n\n    // Function to perform a right rotation on the tree (used during splaying)\n    private Node rotateRight(Node root) {\n        Node newRoot = root.left;  // Make the left child the new root\n        root.left = newRoot.right;  // Make the right child of the new root the left child of the old root\n        newRoot.right = root;  // Make the old root the right child of the new root\n        return newRoot;  // Return the new root\n    }\n\n    // Function to perform a left rotation on the tree (used during splaying)\n    private Node rotateLeft(Node root) {\n        Node newRoot = root.right;  // Make the right child the new root\n        root.right = newRoot.left;  // Make the left child of the new root the right child of the old root\n        newRoot.left = root;  // Make the old root the left child of the new root\n        return newRoot;  // Return the new root\n    }\n\n    // Splay function to bring the node with the given value to the root\n    private Node splay(Node root, int value) {\n        while (root != null) {\n            // Base case: if the node is found or we reach the leaf, break out of the loop\n            if (root.data == value) return root;\n\n            // Zig (single rotation): If the node is the left child or right child of the root\n            if (value < root.data) {\n                if (root.left == null) break;  // If there's no left child, stop\n\n                // Zig-Zig (double rotation): If node's value is in the left subtree of left child\n                if (value < root.left.data) {\n                    root = rotateRight(root);\n                } else if (value > root.left.data) {\n                    // Zig-Zag (double rotation): If node's value is in the right subtree of left child\n                    root.left = rotateLeft(root.left);\n                    root = rotateRight(root);\n                }\n            } else {\n                if (root.right == null) break;  // If there's no right child, stop\n\n                // Zig-Zig (double rotation): If node's value is in the right subtree of right child\n                if (value > root.right.data) {\n                    root = rotateLeft(root);\n                } else if (value < root.right.data) {\n                    // Zig-Zag (double rotation): If node's value is in the left subtree of right child\n                    root.right = rotateRight(root.right);\n                    root = rotateLeft(root);\n                }\n            }\n        }\n        return root;\n    }\n\n    // Pretty print function to display the tree visually\n    public void prettyPrint(Node root, String indent) {\n        if (root == null) return;  // If the root is null, return\n\n        // Print the right subtree first with increased indentation\n        prettyPrint(root.right, indent + \"   \");\n        System.out.println(indent + root.data);  // Print the current node\n        // Print the left subtree with increased indentation\n        prettyPrint(root.left, indent + \"   \");\n    }\n\n    // Wrapper function to print the tree\n    public void printTree() {\n        prettyPrint(root, \"\");  // Call the prettyPrint function starting from the root\n    }\n\n    public static void main(String[] args) {\n        SplayTree tree = new SplayTree();\n\n        // Inserting values into the tree\n        tree.insert(10);\n        tree.insert(20);\n        tree.insert(30);\n        tree.insert(15);\n\n        // Pretty print the tree after insertion\n        System.out.println(\"Tree after insertion:\");\n        tree.printTree();\n\n        // Find a value in the tree and bring it to the root\n        tree.find(20);\n        System.out.println(\"\\nTree after finding 20:\");\n        tree.printTree();\n\n        // Delete a value from the tree\n        tree.delete(10);\n        System.out.println(\"\\nTree after deleting 10:\");\n        tree.printTree();\n    }\n}","type":"content","url":"/xbst-splaytrees-2025#splay-using-for-loops","position":27},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Explanation of Changes:"},"type":"lvl2","url":"/xbst-splaytrees-2025#explanation-of-changes","position":28},{"hierarchy":{"lvl1":"Splay Trees","lvl2":"Explanation of Changes:"},"content":"Insert Method: The insertion now uses a loop to traverse the tree and find the correct position to insert the new node. The insertion process is followed by a splay operation to move the newly inserted node to the root.\n\nDelete Method: Similar to insertion, the delete method now uses a loop to traverse the tree and delete the node. It also includes a splay operation to move the necessary nodes after deletion.\n\nSplay Method: The splay function has been rewritten to use a loop instead of recursion. It continuously adjusts the tree until the target node is either found or no further adjustments are necessary.\n\nRotation Methods: The left and right rotations remain the same, as these are simple tree manipulations that don’t depend on recursion.\n\nThis approach eliminates recursion in favor of iterative methods using loops, which may help avoid potential stack overflow issues with deep trees, though it may still be less efficient compared to a more balanced tree like an AVL or Red-Black tree. However, the splay tree performs well with specific access patterns, especially when there is locality of reference.","type":"content","url":"/xbst-splaytrees-2025#explanation-of-changes","position":29},{"hierarchy":{"lvl1":"Tree Traversal"},"type":"lvl1","url":"/xbst-treetraversal","position":0},{"hierarchy":{"lvl1":"Tree Traversal"},"content":"Pre-order, post-order, and in-order are not “order types” in the general sense, but rather tree traversal methods used to visit all nodes in a tree structure. They define the order in which we visit the root, left subtree, and right subtree of each node. Here’s a breakdown of each:\n\nPre-order:\n\nVisit the root of the node.\n\nRecursively visit the left subtree.\n\nRecursively visit the right subtree.\n\nThink of it as visiting the parent first, then the children, like inspecting a family photo by focusing on the parents before moving to their individual pictures.\n\nIn-order:\n\nRecursively visit the left subtree.\n\nVisit the root of the node.\n\nRecursively visit the right subtree.\n\nImagine reading a sentence word by word: you start at the leftmost word, move to the next, and so on, reaching the root (middle word) last.\n\nPost-order:\n\nRecursively visit the left subtree.\n\nRecursively visit the right subtree.\n\nVisit the root of the node.\n\nThis is like cleaning up after a plant’s growth: you prune the left and right branches before finally taking care of the main trunk.\n\nHere are some examples of how these traversals are used in real life:\n\nPre-order: Building a file system where folders are processed before their contents, or printing the document outline with headings first.\n\nIn-order: Sorting a list of numbers in ascending order using a binary search tree, or printing the words in a sentence in the correct order.\n\nPost-order: Evaluating an arithmetic expression where leaves (operands) are processed before the operators, or calculating the size of a directory by first traversing all subdirectories.","type":"content","url":"/xbst-treetraversal","position":1},{"hierarchy":{"lvl1":"CSCI 232 Data Structures and Algorithms"},"type":"lvl1","url":"/xcsci232-intro","position":0},{"hierarchy":{"lvl1":"CSCI 232 Data Structures and Algorithms"},"content":"","type":"content","url":"/xcsci232-intro","position":1},{"hierarchy":{"lvl1":"CSCI 232 Data Structures and Algorithms","lvl2":"Advanced Data Structures and Programming Techniques - Course Introduction"},"type":"lvl2","url":"/xcsci232-intro#advanced-data-structures-and-programming-techniques-course-introduction","position":2},{"hierarchy":{"lvl1":"CSCI 232 Data Structures and Algorithms","lvl2":"Advanced Data Structures and Programming Techniques - Course Introduction"},"content":"Welcome to the continuation of CSC 132! This course builds upon the foundational knowledge acquired in its prerequisite and dives deeper into advanced data structures and programming techniques, equipping students with the tools to tackle complex computational problems. Whether your goal is to enhance your programming expertise, refine algorithmic thinking, or understand the intricate mechanics behind software systems, this course provides the necessary framework to achieve those objectives.\n\nThe curriculum introduces a variety of data structures such as trees, balanced trees, graphs, dictionaries, hash tables, and heaps, exploring both their theoretical underpinnings and practical applications. Emphasis is placed on understanding the efficiency and correctness of algorithms, ensuring students can critically evaluate and implement solutions in real-world scenarios. A key component of the learning experience is the hands-on application of these concepts using Java, offering students the opportunity to reinforce their understanding through practical exercises and projects.","type":"content","url":"/xcsci232-intro#advanced-data-structures-and-programming-techniques-course-introduction","position":3},{"hierarchy":{"lvl1":"CSCI 232 Data Structures and Algorithms","lvl2":"Course Learning Outcomes"},"type":"lvl2","url":"/xcsci232-intro#course-learning-outcomes","position":4},{"hierarchy":{"lvl1":"CSCI 232 Data Structures and Algorithms","lvl2":"Course Learning Outcomes"},"content":"By the end of the course, students will have developed the skills to confidently explain and implement recursive algorithms, perform time-complexity analyses, and compare various sorting techniques. The course also introduces the implementation of basic Abstract Data Types (ADTs) such as vectors, lists, sorted lists, stacks, and queues. Furthermore, students will gain in-depth knowledge of specialized structures and algorithms, including general trees, binary trees, balanced search trees, and hash tables.\n\nA significant focus is placed on the evaluation and selection of appropriate data structures for solving specific problems. This critical thinking skill ensures that students are not only proficient in implementation but also capable of making informed design decisions in their programming endeavors.\n\nThis course sets the stage for advanced study and professional application in computer science, making it an essential step in your academic and career journey. Prepare to engage with challenging concepts, build robust programming skills, and expand your understanding of the dynamic field of computer science!","type":"content","url":"/xcsci232-intro#course-learning-outcomes","position":5},{"hierarchy":{"lvl1":"DFS - Stored Paths"},"type":"lvl1","url":"/xdfsstoredpaths","position":0},{"hierarchy":{"lvl1":"DFS - Stored Paths"},"content":"This Java code defines a DFS class that implements Depth-First Search for an undirected graph represented using an adjacency list. It provides standard DFS traversal methods (both recursive and iterative) that print the visited node order, as well as specialized methods (also recursive and iterative) designed to find and store all possible paths starting from a given source vertex discovered during the DFS exploration. The Main class demonstrates how to create a graph, add edges, and utilize both the traversal and path-finding functionalities provided by the DFS class.\n\nJavaimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Stack;\n\nclass DFS {\n\n    // Num Vertices\n    private final int numVertices;\n\n    // Adjacency list to store edges\n    public final List<LinkedList<Integer>> adjencyList;\n\n    // List to store all paths found by the last DFS run\n    private List<List<Integer>> allPaths;\n\n    // Constructor\n    public DFS(int vertices) {\n        this.numVertices = vertices;\n        this.adjencyList = new ArrayList<>(vertices);\n        this.allPaths = new ArrayList<>(); // Initialize the path list\n\n        for (int i = 0; i < vertices; i++) {\n            this.adjencyList.add(new LinkedList<>());\n        }\n    }\n\n    // Add edges (undirected graph)\n    public void addEdge(int source, int destination) {\n        // Ensure vertices are within bounds\n        if (source < 0 || source >= numVertices || destination < 0 || destination >= numVertices) {\n            System.err.println(\"Warning: Vertex index out of bounds. Edge not added.\");\n            return;\n        }\n        adjencyList.get(source).add(destination);\n        adjencyList.get(destination).add(source); // For undirected graph\n    }\n\n    // --- Recursive DFS Path Finding ---\n\n    /**\n     * Finds all paths starting from startVertex using recursive DFS.\n     * Stores the paths in the allPaths list.\n     *\n     * @param startVertex The vertex to start the search from.\n     */\n    public void findAllPathsRecursive(int startVertex) {\n        if (startVertex < 0 || startVertex >= numVertices) {\n             System.err.println(\"Error: Start vertex out of bounds.\");\n             return;\n        }\n        boolean[] visited = new boolean[numVertices];\n        this.allPaths = new ArrayList<>(); // Reset paths for new search\n        List<Integer> currentPath = new ArrayList<>();\n\n        System.out.println(\"\\nFinding all paths (Recursive DFS) starting from vertex \" + startVertex + \":\");\n        findAllPathsRecursiveUtil(startVertex, visited, currentPath);\n    }\n\n    /**\n     * Recursive helper function for DFS path finding.\n     *\n     * @param vertex      The current vertex being visited.\n     * @param visited     Array to keep track of visited nodes in the current recursion path.\n     * @param currentPath The path taken to reach the current vertex.\n     */\n    private void findAllPathsRecursiveUtil(int vertex, boolean[] visited, List<Integer> currentPath) {\n        // Mark the current node as visited and add it to the path\n        visited[vertex] = true;\n        currentPath.add(vertex);\n\n        // Store a copy of the current path\n        // This captures the path to the *current* vertex\n        allPaths.add(new ArrayList<>(currentPath));\n        // System.out.println(\"Path found: \" + currentPath); // Optional: print paths as they are found\n\n        // Recur for all adjacent vertices\n        for (int neighbor : adjencyList.get(vertex)) {\n            if (!visited[neighbor]) {\n                findAllPathsRecursiveUtil(neighbor, visited, currentPath);\n            }\n        }\n\n        // Backtrack: remove current vertex from path and mark as unvisited\n        // for other potential paths.\n        currentPath.remove(currentPath.size() - 1);\n        visited[vertex] = false;\n    }\n\n\n    // --- Iterative DFS Path Finding ---\n\n     /**\n      * Finds paths using iterative DFS and stores them.\n      * This version uses a stack storing pairs of (node, path_to_node).\n      * Note: The order of path discovery might differ from the recursive version.\n      *\n      * @param startVertex The vertex to start the search from.\n      */\n    public void findAllPathsIterative(int startVertex) {\n         if (startVertex < 0 || startVertex >= numVertices) {\n             System.err.println(\"Error: Start vertex out of bounds.\");\n             return;\n         }\n         this.allPaths = new ArrayList<>(); // Reset paths\n         System.out.println(\"\\nFinding all paths (Iterative DFS) starting from vertex \" + startVertex + \":\");\n\n         // Stack stores pairs: the node and the path to reach it\n         Stack<Pair<Integer, List<Integer>>> stack = new Stack<>();\n\n         // Initial path contains only the start vertex\n         List<Integer> initialPath = new ArrayList<>();\n         initialPath.add(startVertex);\n         stack.push(new Pair<>(startVertex, initialPath));\n\n         // Keep track of visited nodes *globally* across different path explorations\n         // This prevents infinite loops in cyclic graphs and redundant processing.\n         boolean[] globallyVisited = new boolean[numVertices];\n\n\n         while (!stack.isEmpty()) {\n             Pair<Integer, List<Integer>> currentPair = stack.pop();\n             int currentVertex = currentPair.getKey();\n             List<Integer> currentPath = currentPair.getValue();\n\n             // If we haven't processed this node *through this specific path expansion*\n             // Mark it visited *globally* only after processing its path.\n             // This allows finding different paths to the same node, but standard\n             // iterative DFS usually uses a simpler visited check.\n             // For simplicity matching the recursive intent, let's only proceed\n             // if the node hasn't been the *end* of a stored path yet.\n             // A better approach might be needed for complex path requirements.\n\n             // Store the path found to this vertex\n             allPaths.add(new ArrayList<>(currentPath)); // Store a copy\n             // System.out.println(\"Path found: \" + currentPath); // Optional: print\n\n\n             if (!globallyVisited[currentVertex]) {\n                 globallyVisited[currentVertex] = true; // Mark globally visited\n\n                  // Explore neighbors\n                 // Iterate in reverse to mimic recursive DFS neighbor order more closely (optional)\n                 List<Integer> neighbors = adjencyList.get(currentVertex);\n                 // Collections.reverse(neighbors); // Uncomment to push neighbors in reverse order\n\n                 for (int neighbor : neighbors) {\n                     // Check if the neighbor is already in the *current* path to avoid cycles within a single path\n                     boolean visitedInCurrentPath = false;\n                     for(int nodeInPath : currentPath) {\n                         if (nodeInPath == neighbor) {\n                             visitedInCurrentPath = true;\n                             break;\n                         }\n                     }\n\n                     // If the neighbor hasn't been visited *in this specific path*\n                     if (!visitedInCurrentPath) {\n                         List<Integer> newPath = new ArrayList<>(currentPath);\n                         newPath.add(neighbor);\n                         stack.push(new Pair<>(neighbor, newPath));\n                     }\n                 }\n                 // Collections.reverse(neighbors); // Reverse back if reversed earlier\n             }\n         }\n     }\n\n\n    // --- Original Traversal Methods (for comparison/demonstration) ---\n\n    /**\n     * Performs the original iterative DFS traversal, printing nodes as visited.\n     * Does not store paths.\n     * @param startVertex The vertex to start from.\n     */\n    public void performDFSTraversalIterative(int startVertex) {\n        if (startVertex < 0 || startVertex >= numVertices) {\n            System.err.println(\"Error: Start vertex out of bounds.\");\n            return;\n        }\n        boolean[] visited = new boolean[numVertices];\n        Stack<Integer> stack = new Stack<>(); // Use Stack's push/pop for LIFO (DFS)\n\n        visited[startVertex] = true;\n        stack.push(startVertex); // Push onto stack\n\n        System.out.println(\"\\nDFS Traversal Order (Iterative): starting from \" + startVertex + \" \");\n\n        while (!stack.isEmpty()) {\n            int currentVertex = stack.pop(); // Pop from stack (LIFO)\n            System.out.print(currentVertex + \" \");\n\n            // Get neighbors and push unvisited ones onto the stack\n            // Process neighbors in natural order (or reverse to mimic recursion)\n            List<Integer> neighbors = adjencyList.get(currentVertex);\n             // Collections.reverse(neighbors); // To more closely match typical recursive order\n\n            for (int neighbor : neighbors) {\n                if (!visited[neighbor]) {\n                    visited[neighbor] = true;\n                    stack.push(neighbor);\n                }\n            }\n             // Collections.reverse(neighbors); // Reverse back if needed\n        }\n        System.out.println();\n    }\n\n     /**\n     * Performs the original recursive DFS traversal, printing nodes as visited.\n     * Does not store paths.\n     * @param startVertex The vertex to start from.\n     */\n    public void performDFSTraversalRecursive(int startVertex) {\n         if (startVertex < 0 || startVertex >= numVertices) {\n             System.err.println(\"Error: Start vertex out of bounds.\");\n             return;\n         }\n        boolean[] visited = new boolean[numVertices];\n        System.out.println(\"\\nDFS Traversal Order (Recursive) starting from vertex \" + startVertex + \":\");\n        performDFSTraversalRecursiveUtil(startVertex, visited);\n        System.out.println();\n    }\n\n    private void performDFSTraversalRecursiveUtil(int vertex, boolean[] visited) {\n        visited[vertex] = true;\n        System.out.print(vertex + \" \");\n\n        for (int neighbor : adjencyList.get(vertex)) {\n            if (!visited[neighbor]) {\n                performDFSTraversalRecursiveUtil(neighbor, visited);\n            }\n        }\n    }\n\n    // --- Utility ---\n\n    /**\n     * Returns the list of paths found by the last pathfinding call.\n     * @return A list where each element is a list of integers representing a path.\n     */\n    public List<List<Integer>> getAllPaths() {\n        return allPaths;\n    }\n\n     /**\n      * Prints all stored paths.\n      */\n     public void printAllPaths() {\n         if (allPaths == null || allPaths.isEmpty()) {\n             System.out.println(\"No paths have been generated or stored yet.\");\n             return;\n         }\n         System.out.println(\"\\n--- Stored Paths ---\");\n         int pathNum = 1;\n         for (List<Integer> path : allPaths) {\n             System.out.println(\"Path \" + (pathNum++) + \": \" + path);\n         }\n         System.out.println(\"--------------------\");\n     }\n\n     // Simple generic Pair class (or use javafx.util.Pair if available/allowed)\n     private static class Pair<K, V> {\n         private final K key;\n         private final V value;\n\n         public Pair(K key, V value) {\n             this.key = key;\n             this.value = value;\n         }\n\n         public K getKey() { return key; }\n         public V getValue() { return value; }\n     }\n}\n\nclass Main {\n\n    public static void main(String[] args) {\n\n        DFS graph = new DFS(12);\n\n        // Build the graph\n        graph.addEdge(0, 1);\n        graph.addEdge(0, 2);\n        graph.addEdge(1, 3);\n        graph.addEdge(2, 4);\n        graph.addEdge(4, 5);\n        graph.addEdge(0, 6); // 0 -> 6\n        graph.addEdge(0, 7); // 0 -> 7\n        graph.addEdge(7, 8); // 7 -> 8\n        graph.addEdge(7, 9); // 7 -> 9\n        graph.addEdge(9, 10); // 9 -> 10\n        graph.addEdge(5, 11); // 5 -> 11\n\n        // Print Adjacency List (for verification)\n        System.out.println(\"--- Adjacency List ---\");\n        for (int i = 0; i < graph.adjencyList.size(); i++) {\n            System.out.println(\"Vertex \" + i + \": \" + graph.adjencyList.get(i));\n        }\n         System.out.println(\"----------------------\");\n\n        // --- Demonstrate Original Traversals ---\n        graph.performDFSTraversalIterative(0);\n        graph.performDFSTraversalRecursive(0);\n\n        // --- Find and Store Paths (Recursive) ---\n        graph.findAllPathsRecursive(0);\n        // Print the paths found by the recursive method\n        graph.printAllPaths();\n\n        // --- Find and Store Paths (Iterative) ---\n        graph.findAllPathsIterative(0);\n         // Print the paths found by the iterative method\n         // Note: The order and exact paths might differ slightly depending on implementation details\n         graph.printAllPaths();\n\n         // Example: Get paths and process them\n         System.out.println(\"\\nAccessing paths manually after iterative search:\");\n         List<List<Integer>> storedPaths = graph.getAllPaths();\n         if (storedPaths != null && !storedPaths.isEmpty()) {\n             System.out.println(\"Total paths found: \" + storedPaths.size());\n             System.out.println(\"First path found: \" + storedPaths.get(0));\n             System.out.println(\"Last path found: \" + storedPaths.get(storedPaths.size() - 1));\n         }\n    }\n}\n\nThis code defines a DFS class that represents a graph and provides methods for performing Depth-First Search (DFS) operations on it. It specifically includes implementations for:\n\nStandard DFS Traversal (Recursive & Iterative): These methods visit nodes in DFS order and typically print them, primarily demonstrating the traversal algorithm itself.\n\nFinding All Paths via DFS (Recursive & Iterative): These are more complex methods designed to find and store all possible paths starting from a given vertex that can be discovered through a DFS exploration.\n\nHere’s a breakdown of the components:\n\nDFS Class:\n\nFields:\n\nnumVertices: An integer storing the number of vertices in the graph.\n\nadjencyList: A List<LinkedList<Integer>>. This is the core graph representation using an adjacency list. The outer list has an index for each vertex (0 to numVertices - 1). The LinkedList at each index i stores the vertices directly connected (adjacent) to vertex i.\n\nallPaths: A List<List<Integer>>. This list is used to store the results of the path-finding operations (findAllPathsRecursive or findAllPathsIterative). Each element within allPaths is itself a List<Integer> representing a single path found.\n\nConstructor (DFS(int vertices)):\n\nInitializes the graph with a specified number of vertices.\n\nCreates the adjencyList structure, adding an empty LinkedList for each vertex.\n\nInitializes the allPaths list.\n\naddEdge(int source, int destination):\n\nAdds an edge between the source vertex and the destination vertex.\n\nIncludes basic error checking to ensure vertex indices are valid.\n\nAdds destination to source’s list and source to destination’s list. This makes the graph undirected (an edge exists in both directions).\n\nRecursive Path Finding (findAllPathsRecursive and findAllPathsRecursiveUtil):\n\nfindAllPathsRecursive(startVertex): The public method to initiate the search. It sets up a visited array (local to the current path exploration) and resets the allPaths list before calling the helper function.\n\nfindAllPathsRecursiveUtil(vertex, visited, currentPath)\n\n:\n\nThis is the core recursive logic.\n\nIt marks the current vertex as visited for the current path exploration.\n\nAdds the vertex to the currentPath.\n\nCrucially: It adds a copy of the currentPath (up to the current vertex) to the allPaths list. This means every node encountered during the DFS becomes the end of a stored path.\n\nIt iterates through the neighbors of the current vertex. If a neighbor hasn’t been visited in the current recursive call stack, it recursively calls itself for that neighbor.\n\nBacktracking: After exploring all paths stemming from the current vertex, it removes the vertex from currentPath and marks it as unvisited (visited[vertex] = false). This is essential to allow the algorithm to explore other paths that might reach this vertex through a different sequence.\n\nIterative Path Finding (findAllPathsIterative):\n\nThis method attempts to find all paths using an iterative approach with a Stack.\n\nIt uses aStack\n\nwhere each element is aPair\n\ncontaining:\n\nThe current vertex (Integer).\n\nThe path (List<Integer>) taken to reach that vertex.\n\nIt also uses agloballyVisited\n\narray. The logic here is slightly different from the recursive version’svisited\n\narray:\n\nIt adds the path to allPaths when a Pair is popped from the stack.\n\nIt checks globallyVisited after storing the path. If the node hasn’t been globally visited yet, it marks it and explores its neighbors.\n\nWhen exploring neighbors, it checks if the neighbor is already present in the current specific path (visitedInCurrentPath loop) to prevent cycles within that single path.\n\nIf a neighbor is valid (not creating a cycle in the current path), a new path is created by extending the current one, and a new Pair is pushed onto the stack.\n\nNote: The use of globallyVisited prevents re-exploring from a node once any path ending there has been processed. This helps avoid infinite loops in cyclic graphs but might prune some paths compared to a pure recursive backtracking approach if the goal was all simple paths. The order of paths found might also differ from the recursive version due to stack LIFO order and neighbor processing order.\n\nStandard Traversal Methods (performDFSTraversalIterative, performDFSTraversalRecursive, performDFSTraversalRecursiveUtil):\n\nThese implement the more “standard” DFS algorithm where the goal is just to visit each reachable node once.\n\nThey use a visited array to keep track of nodes already visited during the entire traversal.\n\nThey print the vertex when it’s visited (recursive) or popped (iterative).\n\nThey do not store paths.\n\nUtility Methods:\n\ngetAllPaths(): Returns the allPaths list (containing results from the last path-finding call).\n\nprintAllPaths(): Prints all the paths currently stored in the allPaths list in a readable format.\n\nPair<K, V>: A simple private static inner class to hold pairs of objects (used in the iterative path finding).\n\nMain Class:\n\nCreates an instance of the DFS graph with 12 vertices.\n\nAdds edges to define the graph structure.\n\nPrints the adjacency list to show the graph’s structure.\n\nDemonstrates the standard iterative and recursive DFS traversals, printing the order nodes are visited.\n\nCalls findAllPathsRecursive(0) to find paths starting from vertex 0 using recursion and prints the results.\n\nCalls findAllPathsIterative(0) to find paths starting from vertex 0 using iteration and prints those results.\n\nShows how to retrieve the list of paths using getAllPaths() after a search.\n\nIn essence, this code provides a robust DFS class for undirected graphs, offering both standard traversal and more complex path-finding capabilities, implemented recursively and iteratively.","type":"content","url":"/xdfsstoredpaths","position":1},{"hierarchy":{"lvl1":"End"},"type":"lvl1","url":"/xend","position":0},{"hierarchy":{"lvl1":"End"},"content":"End Of  Content","type":"content","url":"/xend","position":1},{"hierarchy":{"lvl1":"Graphs"},"type":"lvl1","url":"/xgraphs","position":0},{"hierarchy":{"lvl1":"Graphs"},"content":"In computer science, a graph is an abstract representation of a set of objects, known as vertices or nodes, connected by a set of edges. Graphs offer a flexible way to depict relationships and interactions between different entities. \n\nThey can be either directed (where edges have a specific direction) or undirected (where edges have no specific direction) \n\n1\n\n2. Let’s delve deeper into the world of graphs:\n\nGraph Data Structure: A graph data structure consists of nodes (vertices) and edges. It’s used to represent relationships between different entities. \n\nGraph algorithms manipulate and analyze graphs, solving various problems like finding the shortest path or detecting cycles \n\n1.\n\nTypes of Graphs:\n\nDirected Graph (Digraph): Edges have a specific direction, forming an ordered pair (u, v).\n\nUndirected Graph: Edges have no specific direction, forming an unordered pair {u, v}.\n\nWeighted Graph: Edges have associated weights (e.g., distances, costs).\n\nCyclic Graph: Contains cycles (closed loops).\n\nAcyclic Graph: Has no cycles.\n\nConnected Graph: Every pair of vertices is connected by a path.\n\nDisconnected Graph: Contains isolated components.\n\nBipartite Graph: Vertices can be divided into two disjoint sets such that no edge connects vertices within the same set.\n\nGraph Algorithms:\n\nBreadth-First Search (BFS): Traverses the graph layer by layer.\n\nDepth-First Search (DFS): Explores as far as possible along each branch before backtracking.\n\nDijkstra’s Algorithm: Finds the shortest path in weighted graphs.\n\nMinimum Spanning Tree (MST): Connects all vertices with minimum total edge weight.\n\nTopological Sorting: Orders vertices based on dependencies.\n\nArticulation Points: Critical vertices in a connected graph.\n\nStrongly Connected Components: Maximal strongly connected subgraphs.\n\nEulerian Path/Circuit: Visits each edge exactly once.\n\nBellman–Ford Algorithm: Detects negative cycles.\n\nTransitive Closure: Determines reachability between vertices.\n\nGraphs are everywhere in computer science, from social networks to algorithms. They provide a conceptual and computational framework for solving complex problems. So next time you encounter a network, think of it as a graph connecting nodes of information!\n\n​","type":"content","url":"/xgraphs","position":1},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms"},"type":"lvl1","url":"/xgraphsanalysisofbfsanddfs","position":0},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms"},"content":"","type":"content","url":"/xgraphsanalysisofbfsanddfs","position":1},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"1. Introduction to Graph Traversal: BFS and DFS"},"type":"lvl2","url":"/xgraphsanalysisofbfsanddfs#id-1-introduction-to-graph-traversal-bfs-and-dfs","position":2},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"1. Introduction to Graph Traversal: BFS and DFS"},"content":"Graphs serve as fundamental data structures in computer science, representing entities (nodes or vertices) and the connections or relationships between them (edges). Many computational problems across diverse domains, from network routing and social network analysis to state-space exploration in artificial intelligence, can be modeled using graphs. A common requirement when working with graphs is the ability to systematically visit or process each node. This process is known as graph traversal. Efficient graph traversal algorithms are essential for exploring graph structures and solving problems like finding paths, checking connectivity, identifying cycles, and analyzing network properties.\n\nTwo of the most foundational and widely used graph traversal algorithms are Breadth-First Search (BFS) and Depth-First Search (DFS).  While both aim to visit all reachable nodes from a starting point, they employ fundamentally different strategies, leading to distinct characteristics, performance trade-offs, and suitability for various applications. BFS explores the graph level by level, expanding outwards from the source, whereas DFS explores as deeply as possible along one path before backtracking to explore alternatives. This report provides a detailed technical explanation and comparative analysis of BFS and DFS, examining their underlying mechanisms, core data structures (queues and stacks/recursion), strengths, weaknesses, and practical real-world applications.","type":"content","url":"/xgraphsanalysisofbfsanddfs#id-1-introduction-to-graph-traversal-bfs-and-dfs","position":3},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"2. Breadth-First Search (BFS): The Level-by-Level Explorer"},"type":"lvl2","url":"/xgraphsanalysisofbfsanddfs#id-2-breadth-first-search-bfs-the-level-by-level-explorer","position":4},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"2. Breadth-First Search (BFS): The Level-by-Level Explorer"},"content":"","type":"content","url":"/xgraphsanalysisofbfsanddfs#id-2-breadth-first-search-bfs-the-level-by-level-explorer","position":5},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Fundamental Mechanism","lvl2":"2. Breadth-First Search (BFS): The Level-by-Level Explorer"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#fundamental-mechanism","position":6},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Fundamental Mechanism","lvl2":"2. Breadth-First Search (BFS): The Level-by-Level Explorer"},"content":"Breadth-First Search operates by exploring a graph in layers, systematically visiting all nodes at a given distance (in terms of number of edges) from a starting source node before moving on to nodes at the next distance level.7 This methodical, breadth-wise expansion can be visualized as ripples spreading outwards in concentric circles after a pebble is dropped into still water 8, or akin to exploring a multi-story building by examining every room on one floor before proceeding to the next. The algorithm starts at a designated source vertex and visits all its immediate neighbors (nodes one edge away). Then, it visits all the neighbors of those nodes that haven’t been visited yet (nodes two edges away), and continues this process, level by level. This level-order exploration strategy is fundamental to BFS’s properties, most notably its ability to find the shortest path in terms of the number of edges in unweighted graphs.","type":"content","url":"/xgraphsanalysisofbfsanddfs#fundamental-mechanism","position":7},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"The Role of the Queue Data Structure (FIFO)","lvl2":"2. Breadth-First Search (BFS): The Level-by-Level Explorer"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#the-role-of-the-queue-data-structure-fifo","position":8},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"The Role of the Queue Data Structure (FIFO)","lvl2":"2. Breadth-First Search (BFS): The Level-by-Level Explorer"},"content":"The key to achieving this level-by-level exploration lies in BFS’s use of a queue data structure. A queue operates on the First-In, First-Out (FIFO) principle: the first element added to the queue is the first one to be removed.1 In the context of BFS, the queue stores nodes that have been discovered but whose neighbors have not yet been fully explored.\n\nThe process typically involves adding (enqueuing) the starting node to the queue. Then, while the queue is not empty, a node is removed (dequeued) from the front. When this node is processed, all its adjacent neighbors that have not yet been visited are added (enqueued) to the back of the queue. This FIFO behavior ensures that nodes are processed in the order of their distance from the source. All nodes at distance k are dequeued and processed before any node at distance k+1 is dequeued, because the nodes at distance k+1 were only added to the queue after the nodes at distance k.\n\nThis strict ordering imposed by the FIFO queue is the direct mechanism enabling BFS to guarantee finding the shortest path in unweighted graphs. Since the algorithm explores all paths of length k before exploring any path of length k+1, the first time it encounters a target node, it must have reached it via a path with the minimum possible number of edges.1","type":"content","url":"/xgraphsanalysisofbfsanddfs#the-role-of-the-queue-data-structure-fifo","position":9},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Step-by-Step BFS Algorithm Walkthrough","lvl2":"2. Breadth-First Search (BFS): The Level-by-Level Explorer"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#step-by-step-bfs-algorithm-walkthrough","position":10},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Step-by-Step BFS Algorithm Walkthrough","lvl2":"2. Breadth-First Search (BFS): The Level-by-Level Explorer"},"content":"The BFS algorithm can be implemented systematically as follows 8:\n\nInitialization:\n\nCreate an empty queue (e.g., using a deque in Python or LinkedList in Java) to store nodes pending exploration.\n\nCreate a set or boolean array called visited to keep track of nodes already encountered. This prevents reprocessing nodes and potential infinite loops in graphs containing cycles.\n\nOptionally, create a map or dictionary called predecessors to store the path taken to reach each node (useful for reconstructing the shortest path). Initialize it as empty.\n\nSelect a starting node s. Add s to the visited set. Enqueue s into the queue. If using predecessors, set predecessors[s] to null.\n\nIteration:\n\nWhile the queue is not empty:\n\nDequeue the node from the front of the queue; let this be currentNode.\n\nProcess currentNode. This might involve checking if it is the target node, performing an operation, or simply marking its traversal.\n\nRetrieve all neighbors of currentNode.\n\nFor each  neighbor  of  currentNode  :\n\nCheck if neighbor is in the visited set.\n\nIf  neighbor  has  not been visited:\n\nAdd neighbor to the visited set.\n\nIf using predecessors, set predecessors[neighbor] = currentNode.\n\nEnqueue neighbor into the back of the queue.\n\nTermination:\n\nThe algorithm terminates when the queue becomes empty, signifying that all nodes reachable from the starting node s have been visited, or when the target node (if specified) is dequeued and processed.\n\nThe visited set plays a critical role in ensuring the correctness and termination of BFS, particularly when dealing with graphs that contain cycles.10 Without tracking visited nodes, the algorithm could enter an infinite loop by repeatedly enqueueing and dequeueing nodes within a cycle (e.g., A -> B -> C -> A). The visited set prevents a node from being enqueued and processed more than once, effectively breaking potential cycles during traversal.10","type":"content","url":"/xgraphsanalysisofbfsanddfs#step-by-step-bfs-algorithm-walkthrough","position":11},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"3. Depth-First Search (DFS): The Deep Dive Explorer"},"type":"lvl2","url":"/xgraphsanalysisofbfsanddfs#id-3-depth-first-search-dfs-the-deep-dive-explorer","position":12},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"3. Depth-First Search (DFS): The Deep Dive Explorer"},"content":"","type":"content","url":"/xgraphsanalysisofbfsanddfs#id-3-depth-first-search-dfs-the-deep-dive-explorer","position":13},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Fundamental Mechanism","lvl2":"3. Depth-First Search (DFS): The Deep Dive Explorer"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#fundamental-mechanism-1","position":14},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Fundamental Mechanism","lvl2":"3. Depth-First Search (DFS): The Deep Dive Explorer"},"content":"In contrast to BFS’s breadth-wise exploration, Depth-First Search (DFS) employs a strategy of exploring as far as possible along a single path or branch before backtracking. The core idea is to go deeper into the graph whenever possible. Starting from a source node, DFS selects an unvisited neighbor and recursively explores from that neighbor. This continues until it reaches a node with no unvisited neighbors (a “dead end”) or the target node.\n\nA crucial component of DFS is backtracking. When the algorithm reaches a dead end or completes the exploration from a particular node, it returns to the node from which it arrived (the previous node in the path) and attempts to explore other unvisited neighbors from that point  This process resembles navigating a complex maze: one follows a chosen path until it terminates, then retraces steps back to the last junction where an alternative path was available, and explores that new path.","type":"content","url":"/xgraphsanalysisofbfsanddfs#fundamental-mechanism-1","position":15},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"The Role of the Stack (LIFO) or Recursion","lvl2":"3. Depth-First Search (DFS): The Deep Dive Explorer"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#the-role-of-the-stack-lifo-or-recursion","position":16},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"The Role of the Stack (LIFO) or Recursion","lvl2":"3. Depth-First Search (DFS): The Deep Dive Explorer"},"content":"DFS is typically implemented using either recursion, which implicitly utilizes the program’s function call stack, or an iterative approach using an explicit stack data structure.2 A stack operates on the Last-In, First-Out (LIFO) principle.\n\nRecursive Implementation: The recursive approach mirrors the DFS definition directly. A function calls itself for each unvisited neighbor, naturally diving deeper into the graph. The function call stack implicitly keeps track of the path taken and the nodes to return to upon backtracking (when a function call returns).\n\nIterative Implementation (Stack): The iterative version uses an explicit stack. The starting node is pushed onto the stack. In each step, a node is popped from the stack. If it hasn’t been visited, it’s marked as visited and processed. Then, its unvisited neighbors are pushed onto the stack. The LIFO nature ensures that the most recently discovered neighbor (the one deepest along the current path) is explored next.\n\nThe choice between recursive and iterative implementations involves trade-offs. Recursion often leads to more concise and arguably more elegant code that directly reflects the algorithm’s definition.21 However, for very deep graphs, the recursive approach can lead to a stack overflow error if the depth of recursion exceeds the limit imposed by the system’s call stack.18 The iterative approach, using an explicit stack managed in the program’s heap memory, avoids this recursion depth limitation and is only constrained by available system memory, making it potentially more robust for extremely deep traversals, though it might be slightly more complex to write.18","type":"content","url":"/xgraphsanalysisofbfsanddfs#the-role-of-the-stack-lifo-or-recursion","position":17},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Step-by-Step DFS Algorithm Walkthrough","lvl2":"3. Depth-First Search (DFS): The Deep Dive Explorer"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#step-by-step-dfs-algorithm-walkthrough","position":18},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Step-by-Step DFS Algorithm Walkthrough","lvl2":"3. Depth-First Search (DFS): The Deep Dive Explorer"},"content":"Here are the step-by-step procedures for both implementations 2:\n\nRecursive DFS:\n\nInitialization: Create a visited set (or boolean array) to track visited nodes.\n\nDefine Recursive Function:\n\nCreate a function, say DFS_recursive(graph, currentNode, visited)   :\n\nMark currentNode as visited (add it to the visited set).\n\nProcess currentNode (e.g., print it, add to a list).\n\nFor each neighbor  of  currentNode in the  graph  :\n\nIf neighbor  is not in the visited        set:\n\nCall DFS_recursive(graph, neighbor, visited).\n\nInitial Call: Start the traversal by calling DFS_recursive(graph, startNode, visited). If the graph might be disconnected, iterate through all nodes and call DFS_recursive if a node hasn’t been visited yet.\n\nIterative DFS (using Stack):\n\nInitialization: Create an empty stack. Create a visited set.\n\nStart: Push the startNode onto the stack.\n\nIteration:\n\nWhile the stack is not empty:\n\nPop a node from the top of the stack; let this be currentNode.\n\nIf currentNode  is  not  in the  visited\n\nset:\n\nMark currentNode as visited (add it to the visited set).\n\nProcess currentNode.\n\nRetrieve all neighbors of currentNode.\n\nFor each  neighbor of  currentNode   :\n\nIf neighbor is not in the visited\nset:\n\nPush neighbor onto the stack. (Note: Pushing neighbors in reverse order of how they appear in the adjacency list often helps mimic the traversal order of the typical recursive implementation).\n\nTermination: The loop finishes when the stack is empty, meaning all reachable nodes have been explored.\n\nThe backtracking mechanism is an inherent consequence of the LIFO nature of the stack (explicit or implicit). When the exploration along a certain path reaches a node with no further unvisited neighbors, the algorithm naturally reverts to the node it came from – either by returning from the recursive function call or by popping the next element from the explicit stack, which corresponds to the parent node in the traversal path. This allows the algorithm to systematically explore alternative branches from previously visited nodes.2","type":"content","url":"/xgraphsanalysisofbfsanddfs#step-by-step-dfs-algorithm-walkthrough","position":19},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"4. Analyzing Breadth-First Search (BFS)"},"type":"lvl2","url":"/xgraphsanalysisofbfsanddfs#id-4-analyzing-breadth-first-search-bfs","position":20},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"4. Analyzing Breadth-First Search (BFS)"},"content":"","type":"content","url":"/xgraphsanalysisofbfsanddfs#id-4-analyzing-breadth-first-search-bfs","position":21},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Strengths","lvl2":"4. Analyzing Breadth-First Search (BFS)"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#strengths","position":22},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Strengths","lvl2":"4. Analyzing Breadth-First Search (BFS)"},"content":"BFS possesses several key strengths stemming directly from its level-by-level exploration strategy:\n\nShortest Paths (Unweighted Graphs): BFS is guaranteed to find the shortest path, measured by the number of edges, between a source node and any other reachable node in an unweighted graph. As explained earlier, the use of a queue ensures that nodes closer to the source are always visited before nodes farther away. This makes BFS the standard algorithm for solving shortest path problems where all edge weights are uniform (or non-existent).\n\nCompleteness: BFS is a complete algorithm, meaning if a path exists from the source node to a target node, BFS is guaranteed to find it. Because it systematically explores every reachable node layer by layer, it cannot get stuck in a deep path while potentially missing a solution at a shallower level. It explores the entire reachable portion of the graph exhaustively.","type":"content","url":"/xgraphsanalysisofbfsanddfs#strengths","position":23},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Weaknesses","lvl2":"4. Analyzing Breadth-First Search (BFS)"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#weaknesses","position":24},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Weaknesses","lvl2":"4. Analyzing Breadth-First Search (BFS)"},"content":"The primary drawback of BFS relates to its resource consumption:\n\nMemory Consumption: BFS can be memory-intensive, particularly for graphs with a high branching factor (nodes having many neighbors).3 The algorithm needs to store all nodes at the frontier of the search in the queue simultaneously.\n\nThe size of the queue, and thus the memory requirement, is determined by the maximum number of nodes present at any single level or depth in the graph. For graphs that are “wide” (having many nodes at the same distance from the source) but relatively “shallow”, the queue can grow very large, potentially requiring space proportional to the total number of vertices (O(V)) in the worst-case scenario.6 This can be a significant limitation when dealing with massive graphs where memory is constrained.","type":"content","url":"/xgraphsanalysisofbfsanddfs#weaknesses","position":25},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"5. Analyzing Depth-First Search (DFS)"},"type":"lvl2","url":"/xgraphsanalysisofbfsanddfs#id-5-analyzing-depth-first-search-dfs","position":26},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"5. Analyzing Depth-First Search (DFS)"},"content":"","type":"content","url":"/xgraphsanalysisofbfsanddfs#id-5-analyzing-depth-first-search-dfs","position":27},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Strengths","lvl2":"5. Analyzing Depth-First Search (DFS)"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#strengths-1","position":28},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Strengths","lvl2":"5. Analyzing Depth-First Search (DFS)"},"content":"DFS offers a different set of advantages, often complementing the weaknesses of BFS:\n\nMemory Efficiency: DFS generally requires less memory than BFS, especially for graphs that are very deep but not necessarily wide. The space complexity is primarily determined by the maximum depth of the path being explored, as the stack (explicit or implicit) only needs to store the nodes along the current path from the source to the current node.12 For a graph with maximum depth H, the space complexity can be O(H), which can be significantly less than O(V) for deep, narrow graphs where BFS might struggle with memory.\n\nPathfinding Utility: While not optimal for shortest paths, DFS is useful for simply determining if a path exists between two nodes, or for finding any path. It’s also well-suited for exploring all possible paths or configurations, such as in solving puzzles or traversing decision trees.\n\nCycle Detection: DFS is highly effective for detecting cycles in both directed and undirected graphs. By keeping track of nodes currently in the recursion path (using recursion stack status or an auxiliary set in iterative DFS), DFS can identify a “back edge” – an edge leading to an ancestor node already in the current path – which signifies a cycle.\n\nTopological Sorting: DFS is a standard algorithm for performing topological sorting on Directed Acyclic Graphs (DAGs). This process orders vertices such that for every directed edge from vertex u to vertex v, u comes before v in the ordering. This is crucial for scheduling tasks with dependencies. DFS achieves this by adding a node to the front of the sorted list only after all its descendants have been fully explored and added.\n\nThe inherent nature of DFS, exploring full paths before backtracking, makes it particularly well-suited for problems where the structure of paths, connectivity, or dependencies is the primary concern, such as cycle detection, finding connected components, and topological sorting.","type":"content","url":"/xgraphsanalysisofbfsanddfs#strengths-1","position":29},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Weaknesses","lvl2":"5. Analyzing Depth-First Search (DFS)"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#weaknesses-1","position":30},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Weaknesses","lvl2":"5. Analyzing Depth-First Search (DFS)"},"content":"DFS also has notable limitations:\n\nPath Optimality: DFS does not guarantee finding the shortest path between two nodes in a graph. Because it explores deeply along one branch first, it might discover a very long path to the target before it backtracks to explore a potentially much shorter path.\n\nCompleteness Issues: DFS is not complete for infinite graphs. It could potentially follow an infinitely long path and never backtrack to explore other parts of the graph. In finite graphs with cycles, if visited nodes are not properly tracked (using a visited set), DFS can get trapped in an infinite loop, also leading to incompleteness.16 However, when implemented correctly with visited node tracking, DFS is complete for finite graphs.\n\nThere exists a fundamental trade-off: DFS might find a solution relatively quickly if the solution happens to lie deep down the first path explored. However, this potential speed advantage comes at the cost of potentially finding a non-optimal (longer) path. BFS, while potentially slower to reach deep nodes, guarantees finding the shortest path in unweighted graphs.","type":"content","url":"/xgraphsanalysisofbfsanddfs#weaknesses-1","position":31},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"6. Comparative Analysis: BFS vs. DFS"},"type":"lvl2","url":"/xgraphsanalysisofbfsanddfs#id-6-comparative-analysis-bfs-vs-dfs","position":32},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"6. Comparative Analysis: BFS vs. DFS"},"content":"","type":"content","url":"/xgraphsanalysisofbfsanddfs#id-6-comparative-analysis-bfs-vs-dfs","position":33},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Key Differences Summarized","lvl2":"6. Comparative Analysis: BFS vs. DFS"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#key-differences-summarized","position":34},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Key Differences Summarized","lvl2":"6. Comparative Analysis: BFS vs. DFS"},"content":"BFS and DFS represent two distinct approaches to graph traversal with contrasting characteristics :\n\nStrategy: BFS explores level by level (breadth-first); DFS explores as deep as possible before backtracking (depth-first).\n\nData Structure: BFS uses a Queue (FIFO); DFS uses a Stack (LIFO) or recursion (implicit stack).\n\nPathfinding: BFS finds the shortest path in unweighted graphs; DFS finds a path, but not necessarily the shortest.\n\nMemory: BFS memory usage depends on graph width (can be high); DFS memory usage depends on graph depth (often lower, especially for deep graphs).\n\nCompleteness: BFS is complete; DFS is complete for finite graphs (with visited tracking) but not for infinite graphs.","type":"content","url":"/xgraphsanalysisofbfsanddfs#key-differences-summarized","position":35},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Comparison Table","lvl2":"6. Comparative Analysis: BFS vs. DFS"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#comparison-table","position":36},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Comparison Table","lvl2":"6. Comparative Analysis: BFS vs. DFS"},"content":"The following table provides a concise side-by-side comparison:\n\nFeature\n\nBreadth-First Search (BFS)\n\nDepth-First Search (DFS)\n\nTraversal Strategy\n\nLevel-by-level\n\nDepth-first (explore branch fully, then backtrack)\n\nData Structure\n\nQueue (FIFO)\n\nStack (LIFO) or Recursion (Call Stack)\n\nPath Optimality\n\nFinds shortest path (unweighted graphs)\n\nDoes not guarantee shortest path\n\nCompleteness\n\nComplete\n\nComplete (finite graphs, with cycle handling); Not complete (infinite graphs)\n\nMemory Complexity\n\nO(V) worst case (depends on graph width)\n\nO(H) or O(V) worst case (depends on graph depth)\n\nTime Complexity\n\nO(V + E) (adjacency list)\n\nO(V + E) (adjacency list)\n\nKey Use Cases\n\nShortest path (unweighted), Web Crawling, Social Network Analysis, Network Broadcast\n\nCycle Detection, Topological Sort, Maze Solving, Path Existence, Exploring Hierarchies\n\n(V = number of vertices, E = number of edges, H = maximum depth of the graph)","type":"content","url":"/xgraphsanalysisofbfsanddfs#comparison-table","position":37},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Guidance on Choosing the Right Algorithm","lvl2":"6. Comparative Analysis: BFS vs. DFS"},"type":"lvl3","url":"/xgraphsanalysisofbfsanddfs#guidance-on-choosing-the-right-algorithm","position":38},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl3":"Guidance on Choosing the Right Algorithm","lvl2":"6. Comparative Analysis: BFS vs. DFS"},"content":"The choice between BFS and DFS depends heavily on the specific problem requirements and the characteristics of the graph being traversed 6:\n\nUse BFS when:\n\nThe shortest path (in terms of edges) in an unweighted graph is required.\n\nExploring nodes layer by layer or finding nodes closest to the source is important.\n\nThe graph is relatively shallow, or memory is not a primary constraint (as wide graphs can consume significant memory).\n\nThe solution is expected to be relatively close to the starting node.\n\nUse DFS when:\n\nFinding any path or simply checking for path existence is sufficient.\n\nExploring the full depth of paths is necessary (e.g., for cycle detection, topological sorting, exploring all possibilities in a puzzle).\n\nMemory efficiency is crucial, especially if the graph might be very deep but not excessively wide.\n\nThe solution might be located deep within the graph structure.\n\nUltimately, neither algorithm is universally superior. The optimal choice involves a careful consideration of the trade-offs between path optimality, memory usage, completeness requirements, and the specific nature of the problem being addressed.","type":"content","url":"/xgraphsanalysisofbfsanddfs#guidance-on-choosing-the-right-algorithm","position":39},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"7. Real-World Applications of Breadth-First Search (BFS)"},"type":"lvl2","url":"/xgraphsanalysisofbfsanddfs#id-7-real-world-applications-of-breadth-first-search-bfs","position":40},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"7. Real-World Applications of Breadth-First Search (BFS)"},"content":"BFS’s level-by-level exploration and shortest path guarantee in unweighted graphs make it suitable for numerous practical applications:\n\nNetworking:\n\nShortest Path Routing: Used in network protocols to find the path with the minimum number of hops between devices (routers, switches). This is fundamental for efficient data packet delivery in networks where hop count is the primary metric.\n\nBroadcasting: Employed to efficiently disseminate information from one node to all other nodes in a network, ensuring minimal propagation delay in terms of hops. Examples include network service discovery protocols or distributing updates.\n\nPeer-to-Peer (P2P) Networks: Used to discover nearby peers in networks like BitTorrent. Starting from a known peer, BFS can find other peers within a certain number of network hops.\n\nWeb Crawling:\n\nSearch Engine Indexing: Web crawlers used by search engines often employ BFS to discover and index web pages. Starting from a set of known “seed” URLs, the crawler explores links level by level. This ensures that pages closer (in terms of link distance) to the seed URLs are typically discovered and indexed before pages that are many links away, providing a broad initial coverage of the web.\n\nSocial Network Analysis:\n\nFinding Degrees of Separation: BFS is ideal for calculating the shortest connection path between two users in a social network (e.g., finding out if someone is a “friend of a friend”). This directly applies the shortest path property.\n\nFriend Recommendations: Social platforms can use BFS to suggest potential friends by exploring the network outwards from a user. Users found within a small number of hops (e.g., friends of friends) but not yet connected are prime candidates for recommendation.\n\nOther Examples:\n\nGPS Navigation: While complex routing uses weighted graphs and algorithms like Dijkstra’s or A*, BFS can be used in simpler models to find routes with the minimum number of turns or road segments.\n\nConnected Components: Identifying all nodes reachable from a starting node, which helps in finding connected components in an undirected graph.\n\nPuzzle Solving: Finding the minimum number of moves required to solve certain puzzles, like the 8-puzzle or Rubik’s Cube (by exploring the state space graph).\n\nAI Pathfinding: Used in games for pathfinding on grids or unweighted maps where the shortest path in terms of steps is desired.\n\nA common theme across many BFS applications is the need to find something “minimal” or “closest” – the shortest path, the nearest neighbors, the minimum number of steps – which aligns perfectly with its systematic, level-by-level exploration.","type":"content","url":"/xgraphsanalysisofbfsanddfs#id-7-real-world-applications-of-breadth-first-search-bfs","position":41},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"8. Real-World Applications of Depth-First Search (DFS)"},"type":"lvl2","url":"/xgraphsanalysisofbfsanddfs#id-8-real-world-applications-of-depth-first-search-dfs","position":42},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"8. Real-World Applications of Depth-First Search (DFS)"},"content":"DFS’s strategy of deep exploration and backtracking lends itself to applications focused on path discovery, structural properties, and dependencies:\n\nMaze Solving:\n\nDFS is a natural fit for finding a path through a maze from an entrance to an exit. It explores one possible path completely until it hits a dead end, then backtracks to the last junction and tries an alternative path. This mimics a common human strategy for maze solving. The backtracking mechanism is essential for systematically exploring all possibilities from junctions.\n\nTopological Sorting:\n\nTask Scheduling: DFS is fundamental for topological sorting in Directed Acyclic Graphs (DAGs). This is used extensively in scheduling systems where tasks have prerequisites (e.g., ordering course requirements, resolving dependencies in software build systems or project management). DFS ensures that a task is added to the sorted list only after all tasks that depend on it have been processed.\n\nCycle Detection:\n\nDependency Analysis: Detecting cycles is crucial in systems where circular dependencies are problematic, such as in software module imports, spreadsheet formulas, or database schemas. DFS can efficiently detect such cycles by identifying back edges during traversal.\n\nHierarchical Structures (File Systems):\n\nFile System Traversal: DFS is well-suited for navigating hierarchical structures like file systems. Operations like searching for a file within a directory and its subdirectories, calculating the total size of a directory tree, or performing recursive operations naturally follow a depth-first pattern.25\n\nOther Examples:\n\nPathfinding: Determining if any path exists between two points in a network or graph.\n\nSolving Puzzles: Used in solving puzzles that involve exploring sequences of moves or states, like Sudoku, where exploring one possibility deeply before backtracking is effective.\n\nFinding Connected Components: Similar to BFS, DFS can be used to identify connected components in a graph by starting a traversal from an unvisited node and marking all reachable nodes.\n\nCompiler Design: Used in various phases of compilation, such as analyzing control flow graphs.\n\nArtificial Intelligence: Exploring game trees or state spaces in planning problems.\n\nThe applications of DFS often revolve around exhaustive exploration of possibilities along paths, analyzing the structure of connections (cycles, connectivity), or handling hierarchical or dependent relationships.","type":"content","url":"/xgraphsanalysisofbfsanddfs#id-8-real-world-applications-of-depth-first-search-dfs","position":43},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"9. Conclusion"},"type":"lvl2","url":"/xgraphsanalysisofbfsanddfs#id-9-conclusion","position":44},{"hierarchy":{"lvl1":"A Comparative Analysis of Breadth-First Search and Depth-First Search Algorithms","lvl2":"9. Conclusion"},"content":"Breadth-First Search (BFS) and Depth-First Search (DFS) are cornerstone algorithms for graph traversal, each offering a unique approach with distinct advantages and disadvantages. BFS, characterized by its level-by-level exploration using a queue (FIFO), excels at finding the shortest path in unweighted graphs and guarantees completeness. However, its memory consumption can be substantial for graphs with large branching factors.\n\nConversely, DFS employs a depth-first strategy, utilizing a stack (LIFO) or recursion to explore as far as possible along each branch before backtracking. This often results in lower memory usage, particularly for deep graphs, and makes it highly effective for tasks like cycle detection, topological sorting, and exploring hierarchical structures or exhaustive path possibilities (like maze solving). Its main drawbacks include the lack of a guarantee for finding optimal (shortest) paths and potential incompleteness in infinite graphs.\n\nBoth algorithms typically exhibit a time complexity of O(V + E) when implemented with adjacency lists, making them efficient for many graph sizes. The choice between BFS and DFS is not about inherent superiority but about selecting the appropriate tool for the specific problem context. Understanding their fundamental mechanisms, performance characteristics, and the trade-offs between path optimality, memory usage, and exploration strategy is crucial for computer scientists and software engineers aiming to design efficient and effective solutions for graph-related problems. Their wide-ranging applications underscore their enduring importance in diverse fields, from network engineering and web technology to artificial intelligence and bioinformatics.","type":"content","url":"/xgraphsanalysisofbfsanddfs#id-9-conclusion","position":45},{"hierarchy":{"lvl1":"Breadth First"},"type":"lvl1","url":"/xgraphsbfs","position":0},{"hierarchy":{"lvl1":"Breadth First"},"content":"Breadth-First Search (BFS) is an algorithm used to traverse or search tree or graph data structures. It visits nodes level by level, exploring all the neighbor nodes at the current depth before moving down to the next level. Imagine exploring a maze - BFS would check every path on one floor before moving down to the floor below.\n\nHere’s a breakdown of BFS for graphs:\n\nConcept:\n\nStart at a chosen node (usually called the root node).\n\nVisit all the unvisited neighbor nodes of the current node. Add them to a queue data structure (think of a line where you add people at the back).\n\nMark the current node as visited to avoid revisiting.\n\nDequeue a node from the queue (remove the first person in line). This becomes the current node.\n\nRepeat steps 2-4 until the queue is empty.\n\nKey Points:\n\nBFS uses a Queue to store neighbor nodes for exploration.  A Queue functions like “first in, first out”  - similar to a waiting line.\n\nIt ensures we explore all nodes at a level before moving deeper into the graph.\n\nBFS is useful for finding shortest paths (assuming all edges have the same weight) in unweighted graphs.\n\nExample:\n\nImagine a social network graph where nodes are people and edges are friendships. You can use BFS to find all your friends’ friends (people two connections away). You’d start with yourself, then explore all your friends (level 1), then all their friends you haven’t met yet (level 2).\n\nFurther Exploration:\n\nYou can find visualizations of BFS on YouTube ([YouTube video on BFS]).\n\nFor code examples, explore resources like GeeksforGeeks ([Breadth First Search for Graphs])","type":"content","url":"/xgraphsbfs","position":1},{"hierarchy":{"lvl1":"Breadth First","lvl2":"Lecture Code"},"type":"lvl2","url":"/xgraphsbfs#lecture-code","position":2},{"hierarchy":{"lvl1":"Breadth First","lvl2":"Lecture Code"},"content":"import java.util.ArrayList;\nimport java.util.LinkedList;\nimport java.util.List;\n\npublic class BreadthFirstSearch {\n\n  static class Graph {\n    private int V; // number of vertices\n    private List<List<Integer>> adj; // Adjacency List representation\n\n    Graph(int V) {\n      this.V = V;\n      adj = new ArrayList<>(V);\n      for (int i = 0; i < V; i++) {\n        adj.add(new LinkedList<>());\n      }\n    }\n\n    public void addEdge(int v, int w) {\n      adj.get(v).add(w);\n    }\n\n    public void BFS(int s) {\n      boolean visited[] = new boolean[V];\n\n      LinkedList<Integer> queue = new LinkedList<Integer>();\n\n      visited[s] = true;\n      queue.add(s);\n\n      while (queue.size() != 0) {\n        s = queue.poll();\n        System.out.print(s + \" \");\n\n        for (int neighbor : adj.get(s)) {\n          if (!visited[neighbor]) {\n            visited[neighbor] = true;\n            queue.add(neighbor);\n          }\n        }\n      }\n    }\n  }\n\n  public static void main(String args[]) {\n\n    int vertices = 4;\n\n    BreadthFirstSearch.Graph g = new BreadthFirstSearch.Graph (vertices);\n\n\n    g.addEdge(0, 1);\n    g.addEdge(0, 2);\n    g.addEdge(1, 2);\n    g.addEdge(2, 0);\n    g.addEdge(2, 3);\n    g.addEdge(3, 3);\n\n    System.out.println(\"Following is Breadth First Traversal (starting from vertex 0)\");\n\n    for(int i= 0; i < vertices; i++)\n    {\n        System.out.print(\"V = \" + i + \" : \");\n        g.BFS(i);\n        System.out.println();\n    }\n  }\n}\n/*\nFollowing is Breadth First Traversal (starting from vertex 0)\nV = 0 : 0 1 2 3 \nV = 1 : 1 2 0 3 \nV = 2 : 2 0 3 1 \nV = 3 : 3 \n*/\n\nThis code defines a Graph class with an adjacency list to represent the graph. The BFS method takes a starting vertex s and performs the following steps:\n\nCreates a boolean array visited to keep track of visited nodes.\n\nInitializes a queue using LinkedList to store nodes for exploration.\n\nMarks the starting node s as visited and adds it to the queue.\n\nLoops as long as the queue is not empty:\n\nDequeues a node from the queue (the current node).\n\nPrints the current node.\n\nIterates through the neighbors of the current node.\n\nIf a neighbor is not visited, mark it visited and add it to the queue.\n\nThis ensures a level-by-level exploration of the graph.","type":"content","url":"/xgraphsbfs#lecture-code","position":3},{"hierarchy":{"lvl1":"Depth-First Search (DFS)"},"type":"lvl1","url":"/xgraphsdfs","position":0},{"hierarchy":{"lvl1":"Depth-First Search (DFS)"},"content":"Depth-First Search (DFS) is an algorithm for exploring tree or graph data structures. Imagine you’re navigating a maze, and DFS is like taking a very narrow path, going as far as you can down one tunnel before checking any side passages. Here’s how it works on graphs:\n\nStart at a Node: You begin at any node (like the entrance to the maze).\n\nExplore Deepest Path: Visit all the unvisited neighbors of that node (like going down the main tunnel).\n\nMark and Backtrack:  Mark the current node as visited to avoid revisiting it. If you reach a dead end (a node with no unvisited neighbors), backtrack to the most recent un-explored path (like going back to a fork in the maze and taking a different tunnel).\n\nRepeat:  Keep repeating steps 2 and 3 until you’ve explored all possible paths from the starting node.\n\nData Structures Used:\n\nStack: DFS typically uses a stack (LIFO - Last In, First Out) to keep track of the path being explored. Nodes are added to the stack as you move deeper into the graph, and removed as you backtrack.\n\nVisited List:  An additional data structure, like a visited list or array, is used to keep track of the nodes already explored and avoid revisiting them.\n\nApplications of DFS:\n\nFinding paths in mazes or games.\n\nTopological sorting (ordering a directed acyclic graph where each node has dependencies only on nodes preceding it in the order).\n\nCycle detection in graphs.\n\nFinding connected components in graphs (groups of nodes connected by edges).\n\nAdvantages and Disadvantages:\n\nAdvantages: DFS can be efficient for certain graph structures and finding specific paths quickly.\n\nDisadvantages:  DFS might not be ideal for finding the shortest path between two nodes, and it can get stuck in infinite loops if there are cycles in the graph (without proper handling).\n\nHere are some resources for further learning:\n\nA visual explanation of DFS on graphs: YouTube video on Depth First Search: \n\nYouTube\n\nA step-by-step explanation of the DFS algorithm: \n\nhttps://​www​.programiz​.com​/dsa​/graph​-dfs","type":"content","url":"/xgraphsdfs","position":1},{"hierarchy":{"lvl1":"Depth-First Search (DFS)","lvl2":"Lecture Code"},"type":"lvl2","url":"/xgraphsdfs#lecture-code","position":2},{"hierarchy":{"lvl1":"Depth-First Search (DFS)","lvl2":"Lecture Code"},"content":"import java.util.ArrayList;\nimport java.util.List;\n\nclass Node {\n  int data;\n  boolean visited;\n\n  public Node(int data) {\n    this.data = data;\n  }\n}\n\nclass Graph {\n  List<List<Node>> adjList;\n\n  public Graph(int vertices) {\n    adjList = new ArrayList<>(vertices);\n    for (int i = 0; i < vertices; i++) {\n      adjList.add(new ArrayList<>());\n    }\n  }\n\n  public void addEdge(int src, int dest) {\n    adjList.get(src).add(new Node(dest));\n  }\n\n  public void DFS(int startNode) {\n    boolean visited[] = new boolean[adjList.size()];\n    DFSUtil(startNode, visited);\n  }\n\n  private void DFSUtil(int node, boolean[] visited) {\n    visited[node] = true;\n    System.out.print(node + \" \");\n\n    // Visit all unvisited neighbors\n    for (Node neighbor : adjList.get(node)) {\n      if (!visited[neighbor.data]) {\n        DFSUtil(neighbor.data, visited);\n      }\n    }\n  }\n}\n\npublic class Main {\n  public static void main(String[] args) {\n    int vertices = 6;\n    Graph graph = new Graph(vertices);\n\n    graph.addEdge(0, 1);\n    graph.addEdge(0, 2);\n    graph.addEdge(1, 2);\n    graph.addEdge(1, 3);\n    graph.addEdge(2, 3);\n    graph.addEdge(4, 5);\n\n    System.out.println(\"Depth First Traversal (starting from vertex 0)\");\n    \n    for(int i= 0; i < vertices; i++)\n    {\n        System.out.print(\"V = \" + i + \" : \");\n        graph.DFS(i);\n        System.out.println();\n    }\n  }\n}\n/*\nDepth First Traversal (starting from vertex 0)\nV = 0 : 0 1 2 3 \nV = 1 : 1 2 3 \nV = 2 : 2 3 \nV = 3 : 3 \nV = 4 : 4 5 \nV = 5 : 5 \n*/","type":"content","url":"/xgraphsdfs#lecture-code","position":3},{"hierarchy":{"lvl1":"Dijkstra’s Algorithm"},"type":"lvl1","url":"/xgraphsdijkstra","position":0},{"hierarchy":{"lvl1":"Dijkstra’s Algorithm"},"content":"Dijkstra’s algorithm is a famous algorithm for finding the shortest paths between nodes in a weighted graph. Imagine you have a map like a road network, where cities are represented by nodes and roads connecting them are the edges. Each road has a weight, which could be its distance, travel time, or cost. Dijkstra’s algorithm helps you find the most efficient route (shortest path) between two points on this map, considering the weights.\n\nHere’s a simplified breakdown of how it works:\n\nStart at a specific node (source): You choose a starting point on the map (source node).\n\nTrack distances: The algorithm keeps track of the tentative shortest distance from the source node to all other nodes. Initially, these distances are set to infinity, except for the source node itself (distance 0).\n\nExplore neighbors: The algorithm examines the neighboring nodes of the source node. For each neighbor, it calculates the distance by traveling through the source node and adds that to the source’s distance to that neighbor.\n\nUpdate and Repeat: If this calculated distance is shorter than the currently known distance to that neighbor, the algorithm updates the neighbor’s distance. Then, it picks the unvisited node with the shortest distance (tentatively the most promising path to explore) and repeats steps 3 and 4 for that node as the new center.\n\nShortest paths found: The algorithm continues exploring and updating distances until all nodes have been visited. At this point, the distances from the source node to all other nodes represent the shortest paths.\n\nDijkstra’s algorithm is widely used in various applications like GPS navigation systems, finding optimal routes in transportation networks, or planning efficient delivery paths.","type":"content","url":"/xgraphsdijkstra","position":1},{"hierarchy":{"lvl1":"Dijkstra’s Algorithm","lvl2":"Lecture Code Explanation"},"type":"lvl2","url":"/xgraphsdijkstra#lecture-code-explanation","position":2},{"hierarchy":{"lvl1":"Dijkstra’s Algorithm","lvl2":"Lecture Code Explanation"},"content":"This code implements Dijkstra’s algorithm to find the shortest paths from a single source vertex to all other vertices in a weighted graph. Here’s a breakdown of the code:\n\n1. Class Dijkstra:\n\nThis class represents the core functionalities of Dijkstra’s algorithm.\n\nIt has properties like totalVertexes to store the number of vertices in the graph and startVertex to store the starting point for finding shortest paths.\n\nThe constructor Dijkstra(int totalVertexes) initializes these properties.\n\n2. Utility methods:\n\nminimumDistance(int distance[], boolean visited[]): This method finds the unvisited vertex with the minimum tentative distance from the source vertex. It iterates through the distance array and the visited array to find the closest unvisited vertex.\n\nprintSolution(int distance[], int n): This method prints the calculated shortest distances from the source vertex to all other vertices. It iterates through the distance array and prints the distance for each vertex.\n\n3. calculate(int graph[][], int startVertex, int totalVertexes):\n\nThis is the main method that implements Dijkstra’s algorithm.\n\nIt takes the adjacency matrix representation of the graph (graph), the starting vertex (startVertex), and the total number of vertices (totalVertexes) as input.\n\nIt initializes two arrays: distance to store the tentative distances from the source vertex, and visited to keep track of visited vertices.\n\nIt sets all distances in the distance array to infinity (except the source vertex which is set to 0).\n\nIt iteratestotalVertexes-1\n\ntimes (because we need to find shortest paths to all vertices):\n\nIn each iteration, it finds the unvisited vertex with the minimum tentative distance from the source vertex using minimumDistance.\n\nIt marks the found vertex as visited.\n\nIt iterates through all unvisited neighbors of the visited vertex.\n\nFor each neighbor, it calculates the tentative distance if going through the visited vertex is shorter than the current tentative distance.\n\nIf the new tentative distance is shorter, it updates the distance in the distance array.\n\nFinally, it calls printSolution to print the calculated shortest distances.\n\n4. Main method:\n\nThis method creates a sample adjacency matrix representing a weighted graph.\n\nIt creates an instance of the Dijkstra class (dgrpah) with the number of vertices in the graph (9).\n\nIt calls the calculate method of the dgrpah object, providing the graph, starting vertex (8), and total vertices (9).\n\nOverall, this code demonstrates how to implement Dijkstra’s algorithm to find the shortest paths in a weighted graph.","type":"content","url":"/xgraphsdijkstra#lecture-code-explanation","position":3},{"hierarchy":{"lvl1":"Dijkstra’s Algorithm","lvl3":"int minimumDistance(int distance[], boolean visited[])","lvl2":"Lecture Code Explanation"},"type":"lvl3","url":"/xgraphsdijkstra#int-minimumdistance-int-distance-boolean-visited","position":4},{"hierarchy":{"lvl1":"Dijkstra’s Algorithm","lvl3":"int minimumDistance(int distance[], boolean visited[])","lvl2":"Lecture Code Explanation"},"content":"This code snippet implements the minimumDistance function within the Dijkstra’s algorithm class. Here’s a breakdown of what it does:\n\n1. Finding the Unvisited Vertex with Minimum Tentative Distance:\n\nIt initializes two variables:\n\nm: This variable stores the current minimum tentative distance found so far. It’s initialized to the maximum integer value (Integer.MAX_VALUE) to ensure the first encountered unvisited vertex becomes the initial minimum.\n\nm_index: This variable stores the index of the vertex with the minimum tentative distance. It’s initialized to -1 to indicate no vertex found yet.\n\nThe code iterates through all vertices in the graph using a loop (for(int vx= 0; vx < totalVertexes; vx++)).\n\nInside the loop, it checks two conditions for each vertex (vx):\n\nvisited[vx] == false: This condition checks if the vertex is not yet visited. We only care about unvisited vertices because we’re looking for the next closest unvisited point to explore.\n\ndistance[vx] <= m: This condition checks if the current tentative distance of the vertex (distance[vx]) is less than or equal to the current minimum distance (m).\n\nIf both conditions are true, it means we found an unvisited vertex with a tentative distance that’s either smaller than or equal to the current minimum. In this case:\n\nThe value of distance[vx] (the vertex’s tentative distance) is assigned to m, updating the current minimum.\n\nThe index of the vertex (vx) is assigned to m_index, keeping track of the vertex with the current minimum tentative distance.\n\n2. Returning the Index of the Minimum Distance Vertex:\n\nAfter iterating through all vertices, the m_index will hold the index of the unvisited vertex with the minimum tentative distance from the source vertex (or -1 if no unvisited vertices were found).\n\nFinally, the function returns the m_index.\n\nIn summary, this function finds the unvisited vertex in the graph with the closest (minimum tentative distance) to the source vertex among all unvisited vertices. This vertex becomes the next point to explore in Dijkstra’s algorithm for finding the shortest paths.\n\nThis code snippet iterates through the unvisited neighbors of a vertex (ux) in Dijkstra’s algorithm and updates the tentative distances of those neighbors if necessary. Here’s a breakdown of what it does:            for(int vx = 0; vx <totalVertexes; vx++)\n            {\n                if(!visited[vx] && graph[ux][vx]  != -1 && \n                   distance[ux] + graph[ux][vx] != Integer.MAX_VALUE && \n                   distance[ux] + graph[ux][vx]  < distance[vx] )\n                   {\n                        distance[vx]= distance[ux] + graph[ux][vx];\n                   }\n            }\n\n1. Looping through Unvisited Neighbors:\n\nThe code uses a loop (for(int vx = 0; vx <totalVertexes; vx++)) to iterate through all vertices (vx) in the graph.\n\n2. Checking Conditions for Neighbor Update:\n\nInside the loop, it checks four conditions to determine if the tentative distance of the current neighbor (vx ) needs to be updated:\n\n!visited[vx]: This condition checks if the neighbor (vx) is not visited. We only care about unvisited neighbors because we’re exploring possible paths through the graph.\n\ngraph[ux][vx] != -1: This condition checks if there’s an edge (connection) between the current vertex (ux) and the neighbor (vx) in the graph. A value of -1 in the adjacency matrix typically represents no connection.\n\ndistance[ux] + graph[ux][vx] != Integer.MAX_VALUE: This condition checks if adding the tentative distance of the current vertex (distance[ux]) and the weight of the edge between ux and vx (graph[ux][vx]) doesn’t overflow to infinity. This ensures we don’t encounter invalid distances.\n\ndistance[ux] + graph[ux][vx] < distance[vx]: This is the most important condition. It checks if the tentative distance from the source vertex to the current neighbor (vx) going through the current vertex (ux) is shorter than the current tentative distance of the neighbor (distance[vx]).\n\n3. Updating Tentative Distance:\n\nIf all four conditions are true, it means we found a shorter path to the neighbor (vx  ) by going through the current vertex (ux). In this case:\n\nThe new tentative distance is calculated by adding the tentative distance of the current vertex (distance[ux]) and the weight of the edge between them (graph[ux][vx]).\n\nThis new tentative distance is assigned to distance[vx], effectively updating the tentative distance of the neighbor in the distance array.\n\nIn summary, this code snippet iterates through the unvisited neighbors of a vertex and updates the tentative distances of those neighbors if going through the current vertex provides a shorter path. This is a crucial step in Dijkstra’s algorithm for finding the shortest paths from a source vertex to all other vertices in the graph.","type":"content","url":"/xgraphsdijkstra#int-minimumdistance-int-distance-boolean-visited","position":5},{"hierarchy":{"lvl1":"Dijkstra’s Algorithm","lvl2":"Lecture Code"},"type":"lvl2","url":"/xgraphsdijkstra#lecture-code","position":6},{"hierarchy":{"lvl1":"Dijkstra’s Algorithm","lvl2":"Lecture Code"},"content":"/*\nProject: Dijkstra's Algorithm\nProgrammer: James Goudy\n */\n/*\n\n */\npackage ds_dijstraka_demo;\n\n\nclass Dijkstra {\n\n    // Number of vertices in the graph\n    int totalVertexes;\n    // Starting vertex for finding shortest paths\n    int startVertex;\n\n    public Dijkstra(int totalVertexes) {\n        this.totalVertexes = totalVertexes;\n    }\n\n    // Finds the unvisited vertex with the minimum tentative distance from the source vertex\n    int minimumDistance(int distance[], boolean visited[]) {\n        // Initialize minimum value\n        int m = Integer.MAX_VALUE;\n        int m_index = -1;\n\n        for (int vx = 0; vx < totalVertexes; vx++) {\n            // Check if vertex is unvisited and has a tentative distance less than or equal to current minimum\n            if (!visited[vx] && distance[vx] <= m) {\n                m = distance[vx];\n                m_index = vx;\n            }\n        }\n\n        return m_index;\n    }\n\n    // Utility function to print the calculated shortest distances\n    void printSolution(int distance[], int n) {\n        System.out.println(String.format(\"The shortest distance from source %1$sth node\\nto all of the other nodes are: \\n\", n));\n\n        for (int i = 0; i < n; i++) {\n            System.out.println(n + \" To \" + i + \" the shortest distance is : \" + distance[i]);\n        }\n\n        System.out.println(\"\\n-----------\\n\\n\");\n    }\n\n    // Main function to calculate Dijkstra's shortest paths\n    void calculate(int graph[][], int startVertex, int totalVertexes) {\n        this.totalVertexes = totalVertexes;\n        this.startVertex = startVertex;\n\n        // Arrays to store tentative distances and visited status for vertices\n        int distance[] = new int[totalVertexes];\n        boolean visited[] = new boolean[totalVertexes];\n\n        // Initialize all distances as infinite (except the starting vertex which is 0)\n        for (int j = 0; j < totalVertexes; j++) {\n            distance[j] = Integer.MAX_VALUE;\n        }\n        distance[startVertex] = 0;\n\n        // Find shortest paths for all vertices iteratively\n        for (int c = 0; c < totalVertexes - 1; c++) {\n            // Get the unvisited vertex with the minimum tentative distance from the source vertex\n            int ux = minimumDistance(distance, visited);\n            visited[ux] = true; // Mark the vertex as visited\n\n            // Iterate through unvisited neighbors of the visited vertex\n            for (int vx = 0; vx < totalVertexes; vx++) {\n                // Check conditions to update tentative distance of the neighbor\n                if (!visited[vx] && graph[ux][vx] != -1 &&\n                        distance[ux] + graph[ux][vx] != Integer.MAX_VALUE &&\n                        distance[ux] + graph[ux][vx] < distance[vx]) {\n                    distance[vx] = distance[ux] + graph[ux][vx]; // Update tentative distance\n                }\n            }\n        }\n\n        // Print the calculated shortest distances\n        printSolution(distance, totalVertexes);\n    }\n}\n\n\n\n\n\npublic class DS_Dijstraka_Demo {\n\n\n    public static void main(String[] args) {\n        int graph[][] = new int[][]{\n            {-1, 3,-1,-1,-1,-1,-1, 7,-1},\n            { 3,-1, 7,-1,-1,-1,-1,10, 4},\n            {-1, 7,-1, 6,-1, 2,-1,-1, 1},\n            {-1,-1, 6,-1, 8,13,-1,-1, 3},\n            {-1,-1,-1, 8,-1, 9,-1,-1,-1},\n            {-1,-1, 2,13, 9,-1, 4,-1, 5},\n            {-1,-1,-1,-1,-1, 4,-1, 2, 5},\n            { 7,10,-1,-1,-1,-1, 2,-1, 6},\n            {-1, 4, 1, 3,-1, 5, 5, 6,-1}\n        };\n\n        Dijkstra dgrpah = new Dijkstra(9);\n        dgrpah.calculate(graph, 8,9);\n        \n    }\n    \n}    \n}","type":"content","url":"/xgraphsdijkstra#lecture-code","position":7},{"hierarchy":{"lvl1":"DSF - Maze Solving"},"type":"lvl1","url":"/xgraphsmazesolverdfs","position":0},{"hierarchy":{"lvl1":"DSF - Maze Solving"},"content":"This program defines constants for different characters in the maze and implements two methods:\n\nsolveMaze: Finds the starting point and calls the recursive solveMazeDFS method.\n\nsolveMazeDFS: Uses depth-first search to explore the maze. It marks visited cells, checks all four directions (up, down, left, right) for a solution, and backtracks if necessary.\n\nThe main method demonstrates how to use the program with a sample maze.","type":"content","url":"/xgraphsmazesolverdfs","position":1},{"hierarchy":{"lvl1":"DSF - Maze Solving","lvl3":"Lecture Code"},"type":"lvl3","url":"/xgraphsmazesolverdfs#lecture-code","position":2},{"hierarchy":{"lvl1":"DSF - Maze Solving","lvl3":"Lecture Code"},"content":"/*\nProgrammer: James Goudy with JGEM\n */\npackage mazesolver;\n\nimport java.util.Scanner;\n\npublic class MazeSolver {\n\n    public static final char START = 'S';\n    public static final char END = 'E';\n    public static final char WALL = 'W';\n    public static final char OPEN = '.';\n    public static final char VISITED = 'V';\n    public static final char ROUTE = '*'; // New character to mark the route\n\n    public static boolean solveMaze(char[][] maze) {\n        int startRow = -1;\n        int startCol = -1;\n\n        // Find the starting point\n        for (int row = 0; row < maze.length; row++) {\n            for (int col = 0; col < maze[row].length; col++) {\n                if (maze[row][col] == START) {\n                    startRow = row;\n                    startCol = col;\n                    break;\n                }\n            }\n        }\n\n        if (startRow == -1 || startCol == -1) {\n            System.out.println(\"Error: Starting point not found in maze\");\n            return false;\n        }\n\n        return solveMazeDFS(maze, startRow, startCol);\n    }\n\n    private static boolean solveMazeDFS(char[][] maze, int row, int col) {\n        // Check if we reached the end or hit a wall/visited cell\n        if (maze[row][col] == END) {\n            return true;\n        } else if (maze[row][col] == WALL || maze[row][col] == VISITED) {\n            return false;\n        }\n\n        // Mark current cell as visited\n        maze[row][col] = VISITED;\n\n        // Try all four directions (up, down, left, right)\n        if (row > 0 && solveMazeDFS(maze, row - 1, col)) {\n            maze[row][col] = ROUTE; // Mark as part of the route on successful return\n            return true; // Found solution going up\n        }\n        if (row < maze.length - 1 && solveMazeDFS(maze, row + 1, col)) {\n            maze[row][col] = ROUTE;\n            return true; // Found solution going down\n        }\n        if (col > 0 && solveMazeDFS(maze, row, col - 1)) {\n            maze[row][col] = ROUTE;\n            return true; // Found solution going left\n        }\n        if (col < maze[row].length - 1 && solveMazeDFS(maze, row, col + 1)) {\n            maze[row][col] = ROUTE;\n            return true; // Found solution going right\n        }\n\n        // Backtrack if no solution found in any direction\n        maze[row][col] = OPEN; // Unmark cell as visited (backtracking)\n        return false;\n    }\n\n    public static void printMaze(char[][] maze) {\n        for (char[] row : maze) {\n            for (char c : row) {\n                System.out.print(c + \" \");\n            }\n            System.out.println();\n        }\n    }\n    \n    public static void main(String[] args) {\n        \n        char[][] maze = new char[1][1];\n        \n        char[][] maze1 = {\n            {'W', 'W', 'W', '.'},\n            {'.', '.', 'S', '.'},\n            {'W', 'W', 'W', '.'},\n            {'W', '.', '.', 'E'}\n        };\n\n        char[][] maze2 = {\n            {'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W'},\n            {'.', '.', '.', '.', 'W', '.', '.', '.', '.', '.'},\n            {'W', 'W', '.', 'W', 'W', '.', 'W', 'W', 'W', 'W'},\n            {'.', '.', 'S', '.', '.', '.', '.', '.', '.', '.'},\n            {'W', 'W', '.', 'W', 'W', 'W', 'W', '.', 'W', 'W'},\n            {'.', '.', '.', '.', '.', '.', '.', '.', '.', '.'},\n            {'W', 'W', 'W', 'W', '.', 'W', 'W', 'W', 'W', 'W'},\n            {'.', '.', '.', '.', '.', '.', '.', '.', '.', '.'},\n            {'W', 'W', '.', 'W', '.', 'W', '.', 'W', 'W', 'W'},\n            {'.', '.', '.', 'W', '.', '.', '.', '.', '.', '.'},\n            {'.', 'W', 'W', '.', 'W', '.', '.', '.', '.', '.'},\n            {'.', '.', '.', '.', '.', 'W', '.', '.', '.', '.'},\n            {'.', '.', '.', '.', '.', 'W', 'E', 'W', '.', '.'}\n        };\n        \n        char[][] maze3 = {\n            {'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W'},\n            {'.', '.', '.', '.', 'W', '.', '.', '.', '.', '.'},\n            {'W', 'W', '.', 'W', 'W', '.', 'W', 'W', 'W', 'W'},\n            {'.', '.', 'S', '.', '.', '.', '.', 'W', '.', '.'},\n            {'W', 'W', '.', 'W', 'W', 'W', 'W', 'W', 'W', 'W'},\n            {'.', '.', '.', '.', '.', '.', '.', 'W', '.', 'E'},\n            {'W', 'W', 'W', 'W', '.', 'W', 'W', 'W', '.', 'W'},\n            {'.', '.', '.', '.', '.', '.', '.', 'W', '.', 'W'},\n            {'W', 'W', '.', 'W', '.', 'W', '.', 'W', '.', 'W'},\n            {'.', '.', '.', 'W', '.', '.', '.', 'W', '.', 'W'},\n            {'.', 'W', 'W', '.', 'W', '.', '.', '.', '.', 'W'},\n            {'.', '.', '.', '.', '.', 'W', '.', '.', '.', 'W'},\n            {'.', '.', '.', '.', '.', 'W', 'W', 'W', 'W', 'W'}\n        };\n        \n        char[][] maze4 = {\n            {'W', 'W', 'W', 'W'},\n            {'.', '.', 'S', '.'},\n            {'W', 'W', 'W', '.'},\n            {'W', 'W', '.', '.'},\n            {'W', 'W', '.', '.'},\n            {'W', 'W', 'W', 'W'},\n            {'W', '.', '.', 'E'}\n        };\n\n        String choice;\n        Scanner myScan = new Scanner(System.in);\n        \n        System.out.println(\"Choose maze 1,2 3 or 4\");\n        choice = myScan.nextLine();\n        \n        switch(choice){\n           case \"1\" -> maze = maze1;\n           case \"2\" -> maze = maze2;\n           case \"3\" -> maze = maze3;\n           case \"4\" -> maze = maze4;\n           default ->  {System.out.println(\"Not a choice\");}\n        }\n        \n        \n        printMaze(maze);\n        System.out.println(\"\\n\");\n        \n        if (solveMaze(maze)) {\n            System.out.println(\"Maze solved!\");\n            printMaze(maze); // Print the maze with the solved route\n        } else {\n            System.out.println(\"No solution found for the maze\");\n        }\n    }\n}","type":"content","url":"/xgraphsmazesolverdfs#lecture-code","position":3},{"hierarchy":{"lvl1":"DSF - Maze Solving","lvl2":"Sample Output"},"type":"lvl2","url":"/xgraphsmazesolverdfs#sample-output","position":4},{"hierarchy":{"lvl1":"DSF - Maze Solving","lvl2":"Sample Output"},"content":"Choose maze 1,2 3 or 4\n3\nW W W W W W W W W W \n. . . . W . . . . . \nW W . W W . W W W W \n. . S . . . . W . . \nW W . W W W W W W W \n. . . . . . . W . E \nW W W W . W W W . W \n. . . . . . . W . W \nW W . W . W . W . W \n. . . W . . . W . W \n. W W . W . . . . W \n. . . . . W . . . W \n. . . . . W W W W W \n\n\nMaze solved!\nW W W W W W W W W W \n. . . . W . . . . . \nW W . W W . W W W W \n. . * . . . . W . . \nW W * W W W W W W W \n. . * * * . . W * E \nW W W W * W W W * W \n. . . . * . . W * W \nW W . W * W . W * W \n. . . W * * . W * W \n. W W . W * * * * W \n. . . . . W * * . W \n. . . . . W W W W W ","type":"content","url":"/xgraphsmazesolverdfs#sample-output","position":5},{"hierarchy":{"lvl1":"Seven Bridges of Königsberg"},"type":"lvl1","url":"/xgraphssevenbridges","position":0},{"hierarchy":{"lvl1":"Seven Bridges of Königsberg"},"content":"The Seven Bridges of Königsberg is a historically notable problem in mathematics that laid the foundations for graph theory and prefigured the idea of topology. Let’s delve into the details:\n\nThe City of Königsberg:\n\nKönigsberg (now Kaliningrad, Russia) was a city set on both sides of the Pregel River.\n\nIt included two large islands: Kneiphof and Lomse.\n\nThese islands were connected to each other and to the two mainland portions of the city by seven bridges.\n\nThe Problem:\n\nThe challenge was to find a walk through the city that would cross each bridge once and only once.\n\nThe rules were strict:\n\nSolutions couldn’t involve reaching an island or mainland bank without using a bridge.\n\nAccessing any bridge without crossing to its other end was unacceptable.\n\nEuler’s Insight:\n\nLeonhard Euler, a brilliant mathematician, analyzed the problem.\n\nHe realized that the choice of route inside each landmass (island or mainland) was irrelevant.\n\nThe crucial aspect was the sequence of bridges crossed.\n\nEuler reformulated the problem in abstract terms, focusing only on the list of landmasses and the bridges connecting them.\n\nGraph Theory Approach:\n\nEuler replaced each landmass with an abstract “vertex” or node.\n\nEach bridge became an abstract connection or “edge” between vertices.\n\nThe resulting mathematical structure is a graph.\n\nThe shape of the graph could be distorted without changing its essence—only the number of edges between nodes mattered.\n\nEuler’s Solution:\n\nEuler observed that whenever one enters a vertex by a bridge, one must leave it by a bridge (except at the endpoints of the walk).\n\nIf every bridge had been traversed exactly once, the number of bridges touching each landmass must be even.\n\nEuler proved that the problem had no solution because the number of bridges touching each landmass was odd.\n\nLegacy:\n\nEuler’s negative resolution of the Seven Bridges problem laid the groundwork for graph theory.\n\nIt also prefigured the concept of topology, which studies properties preserved under continuous deformations.","type":"content","url":"/xgraphssevenbridges","position":1},{"hierarchy":{"lvl1":"HashSet, LinkedHashSet, and TreeSet Comparision"},"type":"lvl1","url":"/xhashsetlinkedhashsettreesetcomparision","position":0},{"hierarchy":{"lvl1":"HashSet, LinkedHashSet, and TreeSet Comparision"},"content":"Comparison of HashSet, LinkedHashSet, and TreeSet in Java. These are all implementations of the Set interface, meaning they store unique elements. Their main differences lie in their internal implementation, element ordering, performance characteristics, and handling of null values.\n\nCore Similarity:\n\nImplement Set Interface: All three classes implement the java.util.Set interface.\n\nStore Unique Elements: They do not allow duplicate elements. Adding an element that is already present (according to the equals() method) has no effect.\n\nKey Differences:\n\nHere’s a table summarizing the main distinctions:\n\nFeature\n\nHashSet\n\nLinkedHashSet\n\nTreeSet\n\nUnderlying Structure\n\nHashMap\n\nLinkedHashMap\n\nTreeMap (Red-Black Tree)\n\nOrdering\n\nUnordered\n\nInsertion Order\n\nSorted Order (Natural or Custom)\n\nPerformance (Avg)\n\nO(1) for add, remove, contains\n\nO(1) for add, remove, contains (slightly higher constant factor than HashSet)\n\nO(logn) for add, remove, contains\n\nIteration Performance\n\nProportional to capacity + size\n\nProportional to size\n\nProportional to size (O(n) total)\n\nNull Elements\n\nAllows one null element\n\nAllows one null element\n\nDoes not allow null elements (by default)¹\n\nInterfaces Implemented\n\nSet, Cloneable, Serializable\n\nSet, Cloneable, Serializable\n\nSet, NavigableSet, SortedSet, Cloneable, Serializable\n\nKey Requirement\n\nhashCode() and equals() must be consistent\n\nhashCode() and equals() must be consistent\n\nElements must be mutually comparable (implement Comparable or use a Comparator)²\n\nDetailed Explanations:\n\nHashSet\n\nImplementation: Uses a HashMap internally. The elements you add to the HashSet become the keys in the underlying HashMap, and a dummy Object is used as the value.\n\nOrdering: It makes no guarantees about the iteration order of the elements. The order might even change over time as more elements are added and the internal hash table is resized.\n\nPerformance: Offers the best average-case performance (O(1)) for basic operations (add, remove, contains), assuming the hash function disperses elements properly among the buckets. However, iteration performance depends on both the number of elements (size) and the hash table’s capacity.\n\nNulls: Allows one null element.\n\nUse Case: Best choice when you need a general-purpose Set, don’t care about the order of elements, and want the fastest performance for adding, removing, and checking for presence.\n\nLinkedHashSet\n\nImplementation: It’s a subclass of HashSet. Internally, it uses a LinkedHashMap (which maintains both a hash table like HashMap and a doubly-linked list connecting the elements).\n\nOrdering: Maintains the insertion order of elements. When you iterate over a LinkedHashSet, the elements appear in the order they were added.\n\nPerformance: Offers the same O(1) average-case performance for add, remove, and contains as HashSet, although with a slightly higher constant overhead due to maintaining the linked list. Iteration performance is better than HashSet in typical scenarios because it only depends on the number of elements (size), not the capacity.\n\nNulls: Allows one null element.\n\nUse Case: Ideal when you need the uniqueness of a Set but also need to maintain the order in which elements were inserted. Useful for creating predictable sequences or caches where insertion order matters.\n\nTreeSet\n\nImplementation: Uses a TreeMap internally, which is based on a Red-Black Tree data structure.\n\nOrdering: Keeps elements sorted according to their natural ordering (if the elements implement the Comparable interface) or according to a Comparator provided when the TreeSet is created.\n\nPerformance: Offers O(logn) performance for add, remove, and contains operations due to the balanced tree structure. Iteration is efficient (O(n) for the whole set).\n\nNulls: ¹ Does not allow null elements by default because null cannot be compared to other elements using natural ordering (it would cause a NullPointerException). If you use a Comparator that explicitly handles null, you might be able to store one, but it’s generally not recommended.\n\nInterfaces: Implements NavigableSet and SortedSet, providing additional methods for navigation (e.g., first(), last(), headSet(), tailSet(), ceiling(), floor()).\n\nRequirements: ² Elements added must be mutually comparable. This usually means they must all implement the Comparable interface, or you must supply a suitable Comparator. Adding non-comparable elements (or elements of incompatible types) will result in a ClassCastException.\n\nUse Case: The go-to choice when you need a Set that automatically keeps elements sorted, or when you need the navigational capabilities provided by the SortedSet and NavigableSet interfaces.\n\nWhen to Use Which:\n\nUse HashSet if: You need maximum speed and don’t care about element order.\n\nUse LinkedHashSet if: You need the performance benefits of hashing but also need to maintain the order of insertion.\n\nUse TreeSet if: You need elements to be kept in a sorted order (either natural or custom) or require navigational methods.\n\nBy understanding these differences, you can choose the most appropriate Set implementation for your specific needs in Java.\n/**\nDeveloper: James Goudy \nProject HashSet, LinkedHashSet, TreeSet - Demo \n\nSets - can only contain unique values \n\n\n */\npackage java_sets; // Declares the package name for this Java file\n\n/**\n *\n * @author jgoudy \n */\n// Import statements for necessary Java utility classes\n\n\n// Imports the HashSet class, which implements the Set interface \n// using a hash table (no guaranteed order)\nimport java.util.HashSet;\n\n// Imports the LinkedHashSet class, which maintains insertion order\nimport java.util.LinkedHashSet;\n\n// Imports the Set interface, the base interface for all set collections\nimport java.util.Set;\n\n// Imports the TreeSet class, which stores elements \n// in a sorted order (natural ordering or by Comparator)\nimport java.util.TreeSet;\n\n// Public class definition named Java_Sets\npublic class Java_Sets {\n\n\n    /*\n    Notice how easy it is to switch between the different sets. \n    Difference being is how order is being stored/not stored pending \n    the algorithm \n    \n    */\n    \n    \n    // The main method, the entry point of the Java application\n    public static void main(String[] args) \n    {\n\n        // Declare a variable 'mySet' of type Set that can hold String objects. \n        // This uses the interface type, allowing different \n        // implementations to be assigned later.\n        Set<String> mySet; \n        \n\n        // Initialize a String array 'myData' with some sample data, \n        // including duplicate values.\n        String[] myData = {\"AA\",\"AA.\",\"BB\", \"CC\", \"DD\", \"BB\", \"EE.\", \n                           \"CC\", \"AA\", \"FF\", \"AA\",\"BB\", \"GG\",\"EE\"};\n        \n        // --------------- HashSet Demonstration -----------------------------------      \n        \n        // Instantiate 'mySet' as a new HashSet. \n        // HashSet does not guarantee any specific order of elements.\n        mySet = new HashSet<>(); \n        \n        // Loop through each 'value' in the 'myData' array\n        for (String value : myData) {\n            \n            // Add the 'value' to the HashSet. If the value is already present,\n            // add() returns false and \n            // the set remains unchanged (ensuring uniqueness).\n            \n            mySet.add(value); \n        }\n\n        // Print a header indicating the output is from the HashSet\n        System.out.println(\"\\nHashset - no guarantee of order\");\n        \n        // Loop through each 'value' currently in the HashSet\n        for (String value : mySet) {\n            // Print the value followed by a space. The order is unpredictable.\n            System.out.print(value + \" \"); \n        }\n        \n        // Print newlines for better formatting in the console output\n        System.out.println(\"\\n\"); \n        \n\n        // --------------- LinkedHashSet Demonstration -----------------------\n        // Re-instantiate 'mySet' as a new LinkedHashSet. \n        // LinkedHashSet maintains the order in which elements were inserted.\n        mySet = new LinkedHashSet<>(); \n\n        // Loop through each 'value' in the 'myData' array again\n        for (String value : myData) {\n            // Add the 'value' to the LinkedHashSet. \n            // Duplicates are ignored. Insertion order is preserved.\n            mySet.add(value); \n        }\n\n        // Print a header indicating the output is from the LinkedHashSet and \n        // its characteristic (Insertion Order)\n        System.out.println(\"\\nLinkedSet - Insertion Order\"); \n        \n        \n        // Loop through each 'value' currently in the LinkedHashSet\n        for (String value : mySet) {\n            \n            // Print the value followed by a space. \n            // The order will match the insertion sequence \n            // of unique elements from myData.\n            System.out.print(value + \" \"); \n        }\n        // Print newlines for formatting\n        System.out.println(\"\\n\"); \n        \n\n        // ------------------ TreeSet Demonstration --------------------------\n        // Re-instantiate 'mySet' as a new TreeSet. \n        // TreeSet stores elements in a sorted order \n        // (natural alphabetical order for Strings).\n        mySet = new TreeSet<>(); \n\n        // Loop through each 'value' in the 'myData' array once more\n        for (String value : myData) {\n            \n            // Add the 'value' to the TreeSet. \n            // Duplicates are ignored. \n            //Elements are automatically sorted upon insertion.\n            mySet.add(value); \n        }\n\n        // Print a header indicating the output is from the TreeSet and \n        // its sorting mechanism (based on Red-Black Tree, \n        // resulting in sorted order)\n        System.out.println(\"\\nTreeSet - Items put in order based \"\n                           + \"on Red Black Tree\");\n        \n        \n        // Loop through each 'value' currently in the TreeSet\n        for (String value : mySet) {\n            // Print the value followed by a space. \n            // The order will be alphabetical.\n            System.out.print(value + \" \"); \n        }\n        \n        \n        // Print newlines for formatting\n        System.out.println(\"\\n\"); \n\n    } // End of the main method\n\n} // End of the Java_Sets class\n","type":"content","url":"/xhashsetlinkedhashsettreesetcomparision","position":1},{"hierarchy":{"lvl1":"Hash Tables - Chaining"},"type":"lvl1","url":"/xhashing-chaining","position":0},{"hierarchy":{"lvl1":"Hash Tables - Chaining"},"content":"In hash tables, chaining is a collision resolution technique used to address the issue of collisions. A collision occurs when two different keys map to the same index in the hash table’s internal array. Chaining provides a way to store these colliding elements efficiently.\n\nHere’s how chaining works:\n\nHash Function: Like other collision resolution techniques, chaining starts with a hash function. This function takes a key as input and generates a hash value, which is used as an index to access a specific location (bucket) in the hash table’s array.\n\nCollision: If two different keys happen to have the same hash value, a collision occurs.\n\nLinked List: Instead of overwriting the existing element at the collided index, chaining uses a linked list. This linked list is attached to the bucket in the hash table array.\n\nStoring the Colliding Element: The colliding element is then added as a new node to the linked list attached to the collided bucket.\n\nSearching and Accessing: When searching for a specific key, the hash function is used again to generate the index. Then, the linked list at that index is traversed to find the node containing the key-value pair you’re looking for. The process compares keys until the desired one is found.\n\nBenefits of Chaining:\n\nEfficient for Handling Collisions: Chaining allows efficient handling of collisions, especially when the number of collisions is relatively low. Each bucket can hold multiple elements, preventing the need to re-hash and find a new location for the colliding element, which can be a costly operation.\n\nFlexible: Chaining can dynamically adapt to varying numbers of collisions. As the data grows and more collisions occur, the linked lists attached to buckets simply grow longer.\n\nDrawbacks of Chaining:\n\nSpace Overhead: Chaining uses additional memory to store the linked lists, which can be a slight overhead compared to other techniques like separate chaining (using a separate array for each bucket).\n\nPotential for Longer Lookup Times: In the worst case scenario, if too many elements collide and form very long linked lists, searching for a specific key can become slower as the entire list needs to be traversed.\n\nOverall, chaining is a common and effective collision resolution technique used in hash tables. It provides a flexible and efficient way to handle collisions while keeping lookup times relatively fast in most cases.+--------------------+\n| Hash Table Array   |\n+--------------------+\n| [0] -> Node1(K1, V1) | --> Linked List 1\n|                    | --> Node2(K2, V2)\n+--------------------+\n| [1] -> None        |\n+--------------------+\n| [2] -> Node3(K3, V3) | --> Linked List 2\n|                    | --> Node4(K4, V4)\n+--------------------+\n| [3] -> Node5(K5, V5) |\n+--------------------+\n| [4] -> None        |\n+--------------------+\n| [5] -> Node6(K6, V6) | --> Linked List 3\n|                    | --> Node7(K7, V7)\n+--------------------+\n| [6] -> None        |\n+--------------------+\n| [7] -> Node8(K8, V8) |\n+--------------------+\n| [8] -> None        |\n+--------------------+\n| [9] -> None        |\n+--------------------+\n\nK: Key      V: Value\n\nThis diagram represents a hash table with 10 buckets (index 0 to 9) and uses chaining for collision resolution. Here’s a breakdown of the elements:\n\nHash Table Array: This is the main array that stores the hash table entries. Each element in the array, called a bucket, can potentially hold a linked list of key-value pairs.\n\nLinked Lists: Each bucket that experiences a collision has an attached linked list. This list stores the key-value pairs that collided at that index.\n\nNodes: Each node in the linked list represents a key-value pair (K1, V1) in the hash table.\n\nEmpty Buckets: Buckets without collisions have a value of None to indicate they are empty.\n\nFor example:\n\nKey K1 and Key K2 collided and are stored in a linked list attached to bucket 0.\n\nKey K3 and Key K4 collided and are stored in a linked list attached to bucket 2.\n\nKeys K5, K6, K7, and K8 do not have collisions and are stored directly in their respective buckets (3, 5, and 7).\n\nThis is a simplified example, and in practice, hash tables may use different data structures for linked lists and have more complex logic for handling collisions and ensuring efficient retrieval of key-value pairs.","type":"content","url":"/xhashing-chaining","position":1},{"hierarchy":{"lvl1":"Hash Table"},"type":"lvl1","url":"/xhashing-hashtable","position":0},{"hierarchy":{"lvl1":"Hash Table"},"content":"A hash table, also known as a hash map or a hash set, is a fundamental data structure used in computer science. Let’s explore its key characteristics:\n\nPurpose and Function:\n\nA hash table is designed to efficiently associate keys with values.\n\nIt allows you to store and retrieve data based on a unique key.\n\nThe primary operation it supports is lookup: given a key (e.g., a person’s name), find the corresponding value (e.g., their telephone number).\n\nHow It Works:\n\nA hash table uses a hash function to compute an index (also called a hash code) into an array of buckets or slots.\n\nEach bucket can hold a value associated with a specific key.\n\nDuring a lookup, the key is hashed, and the resulting hash points to the bucket where the corresponding value is stored.\n\nIdeally, the hash function assigns each key to a unique bucket.\n\nHowever, most hash table designs use an imperfect hash function, which may cause hash collisions (where multiple keys map to the same bucket).\n\nCollisions are typically resolved using techniques like chaining or open addressing.\n\nTime Complexity:\n\nIn a well-designed hash table, the average time complexity for each lookup is independent of the number of elements stored.\n\nMany hash table implementations allow arbitrary insertions and deletions of key–value pairs at amortized constant average cost per operation.\n\nApplications:\n\nHash tables are widely used in various software applications:\n\nAssociative Arrays: Efficiently store key-value pairs.\n\nDatabase Indexing: Speed up data retrieval.\n\nCaches: Store frequently accessed data.\n\nSets: Implement sets with fast membership checks.\n\nHistory:\n\nThe idea of hashing arose independently in different places.\n\nIn 1953, Hans Peter Luhn proposed hashing with chaining.\n\nGene Amdahl and others at IBM Research implemented hashing for the IBM 701 assembler.\n\nHashing has become a fundamental tool in computer science.\n\nIn summary, hash tables provide a powerful way to organize and access data efficiently, making them essential for various programming tasks.\n\nA hash table, also known as a hash map or hash set, is a data structure that stores key-value pairs and allows fast retrieval based on the key. It uses a technique called hashing to achieve this efficiency.\n\nHere’s how it works:\n\nKeys and Values: You store data in the form of key-value pairs. The key acts like a unique identifier, and the value is the actual data you want to store.\n\nHash Function: The key is fed into a hash function. This function acts like a special code that transforms the key into a fixed-length index within an array. Ideally, different keys should map to different indexes, minimizing collisions (where multiple keys map to the same index).\n\nArray and Buckets: The hash table uses an array to store the key-value pairs. Each element in the array, called a bucket, can hold one or more key-value pairs.\n\nAccessing Data: To find a specific value, you provide its key. The key is hashed again, generating the same index as before. Then, the hash table searches the corresponding bucket in the array for the matching key-value pair.\n\nBenefits of Hash Tables:\n\nFast Lookup: Compared to searching a linear list, a hash table allows very fast retrieval of values based on their keys. This is because the key directly points to the location (bucket) of the data.\n\nEfficient for Large Datasets: As the data size grows, the lookup time in a hash table remains relatively constant on average, making it efficient for handling large datasets.\n\nHowever, it’s important to note:\n\nCollisions: Although hash functions aim to minimize collisions, they can still occur. When multiple keys map to the same index, additional steps are needed to resolve the collision and find the desired value.\n\nNot Suitable for Ordered Data: Hash tables are not ideal when you need to access data in a specific order, as the order of elements is not preserved.\n\nHash tables are widely used in various applications:\n\nCaches: They are a common choice for implementing caches, where frequently accessed data is stored for quick retrieval.\n\nDatabases: They are used for indexing data in databases, allowing fast access based on specific criteria.\n\nProgramming Languages: Many programming languages use hash tables for implementing associative arrays and dictionaries, where data is accessed using keys.\n\nOverall, hash tables offer a powerful and efficient way to store and retrieve data based on keys, making them valuable tools in various computing scenarios.","type":"content","url":"/xhashing-hashtable","position":1},{"hierarchy":{"lvl1":"Modulus Hash Function"},"type":"lvl1","url":"/xhashing-modulushashfunction","position":0},{"hierarchy":{"lvl1":"Modulus Hash Function"},"content":"Modulus hashing, also known as division hashing, is a simple and efficient technique for mapping data to a fixed-size range. It utilizes the modulo operation (denoted by %) to achieve this mapping.\n\nHere’s how it works:\n\nInput: You have a piece of data like a number, a string, or any other information you want to map to a specific range.\n\nHash Function: The hash function in modulus hashing simply uses the modulo operation with a pre-defined modulus value (often denoted by m). The modulus value determines the size of the output range.\n\nOutput: The output is the remainder obtained when the data is divided by the modulus value. This remainder becomes the hash value, representing the data in the desired range (from 0 to m-1).\n\nExample:\n\nLet’s say you want to map the number 23 to a range of 0 to 4 (using a modulus value of m = 5).\n\nApplying the modulo operation: 23 % 5 = 3.\n\nTherefore, the hash value for 23 in this case is 3.\n\nBenefits of Modulus Hashing:\n\nSimplicity: It is a very basic and easy-to-implement technique for generating hash values.\n\nEfficiency: The modulo operation is usually a fast and efficient operation, making it suitable for situations where speed is crucial.\n\nLimitations of Modulus Hashing:\n\nCollision Prone: While simple, modulus hashing is susceptible to collisions. This occurs when different data points map to the same hash value. Collisions can lead to issues like incorrect data retrieval or insertion in hash tables.\n\nLimited Distribution: The distribution of hash values highly depends on the chosen modulus value. A poorly chosen modulus can lead to uneven distribution, where some parts of the range receive more data than others, impacting efficiency.\n\nApplications of Modulus Hashing:\n\nHash Tables: While not ideal due to collision concerns, modulus hashing can be used in simple hash tables, especially when dealing with small datasets and the potential for collisions is low.\n\nLoad Balancing: It can be used in basic load balancing schemes to distribute tasks or requests across multiple servers by mapping them to a specific server based on the calculated hash value.\n\nHowever, it’s important to remember that modulus hashing is not considered a cryptographically secure hashing function. It should not be used for security-sensitive applications, like password storage, where collisions can have serious consequences.","type":"content","url":"/xhashing-modulushashfunction","position":1},{"hierarchy":{"lvl1":"Hash Table - Open Addressing"},"type":"lvl1","url":"/xhashing-openaddressing","position":0},{"hierarchy":{"lvl1":"Hash Table - Open Addressing"},"content":"Open addressing, also known as closed hashing, is a method of collision resolution in hash tables. Unlike chaining, which stores elements in separate linked lists, open addressing stores all elements directly in the hash table itself. Here’s how it works:\n\nCollision Resolution: When a hash collision occurs (i.e., two keys hash to the same index), open addressing aims to find an alternative location within the array to place the new key. It does this by probing or searching through different array slots until it either finds the target record or an unused slot.\n\nProbe Sequences: Various probe sequences are used to find the next available slot:\n\nLinear Probing: The interval between probes is fixed (often set to 1). If the initial slot is occupied, it checks the next slot, then the next, and so on.\n\nQuadratic Probing: The interval between probes increases quadratically (indices described by a quadratic function).\n\nDouble Hashing: The interval between probes is fixed for each record but computed using another hash function.\n\nTrade-offs:\n\nLinear probing has good cache performance but is sensitive to clustering (when consecutive slots are filled).\n\nDouble hashing exhibits virtually no clustering but has poor cache performance.\n\nQuadratic probing falls in-between in both areas.\n\nLoad Factor: The proportion of used slots in the array (load factor) significantly affects performance. As the load factor approaches 100%, the number of probes required rises dramatically. Load factors are typically limited to 80% to prevent performance degradation.","type":"content","url":"/xhashing-openaddressing","position":1},{"hierarchy":{"lvl1":"Hash Table - Open Addressing","lvl2":"Linear Probing"},"type":"lvl2","url":"/xhashing-openaddressing#linear-probing","position":2},{"hierarchy":{"lvl1":"Hash Table - Open Addressing","lvl2":"Linear Probing"},"content":"Linear probing is a collision resolution technique used in open addressing for hash tables. It’s a simple approach that aims to find an empty slot in the hash table when a collision occurs due to two different keys mapping to the same index. Here’s how it works:\n\nScenario:\n\nImagine you have a hash table with a size of 10 and a hash function that calculates the index for each key. You try to insert two keys: “apple” and “banana” with calculated indices of 5 and 5, respectively. Since both keys map to the same index, a collision occurs.\n\nSteps involved in linear probing:\n\nInitial placement: When a collision happens after calculating the index using the hash function (5 in this case), linear probing starts at the calculated index (position 5).\n\nCheck for availability: If the slot at the calculated index is already occupied (by “apple”), linear probing moves to the next slot in the table (position 6).\n\nRepeat check: It keeps checking for an empty slot by moving linearly to the next available slot in the table until it finds one.\n\nInsertion: Once an empty slot is found (position 6), the new key-value pair (“banana”) is inserted there.\n\nFormula for next index:\n\nThe formula for finding the next index during linear probing is:next_index = (current_index + 1) % table_size\n\ncurrent_index is the current index where a collision occurred.\n\ntable_size is the total size of the hash table.\n\nExample:\n\nIn the earlier scenario, after finding the initial index (5) occupied, linear probing would move to the next index (6) using the formula:next_index = (5 + 1) % 10 = 6\n\nAs position 6 is empty, “banana” would be inserted at that index.\n\nAdvantages:\n\nSimple to implement: Linear probing is straightforward to understand and implement compared to other probing techniques.\n\nCache-friendly: It can be faster for accessing elements due to better cache locality, as elements tend to be stored close to each other in the table.\n\nDisadvantages:\n\nClustering: As the load factor (number of elements compared to table size) increases, elements can bunch up in specific areas of the table, leading to longer probing sequences and slower performance.\n\nPrimary clustering: In the worst case, all elements can become clustered in one section, resulting in very long probing sequences and degrading performance significantly.\n\nOverall, linear probing is a viable option for hash tables with low load factors. As the load factor increases, it’s recommended to consider other probing techniques like double hashing or quadratic probing to minimize clustering and maintain good performance.","type":"content","url":"/xhashing-openaddressing#linear-probing","position":3},{"hierarchy":{"lvl1":"Hash Table - Open Addressing","lvl2":"Double Hashing"},"type":"lvl2","url":"/xhashing-openaddressing#double-hashing","position":4},{"hierarchy":{"lvl1":"Hash Table - Open Addressing","lvl2":"Double Hashing"},"content":"Double hashing is a collision resolution technique used within the context of open addressing for hash tables.  It aims to minimize the clustering effect that can occur with linear or quadratic probing techniques. Here’s how it works:\n\nTwo hash functions: In double hashing, we use two separate hash functions, let’s call them h1(key) and h2(key).\n\nInitial placement: When we want to insert a new key-value pair into the hash table, we first calculate the initial index using the first hash function h1(key).\n\nCollision: If the calculated index is already occupied, we don’t simply move to the next slot (linear probing) or in a quadratic pattern (quadratic probing). Instead...\n\nStep size calculation: We calculate a step size by applying the second hash function h2(key). The most important requirement is that h2(key) should never result in a value of zero.\n\nProbing sequence:\n\nThe probing sequence then proceeds as follows:\n\nIf the initial index is occupied, we add the step size to it.\n\nIf the resulting index is still occupied, we add the step size to that index, and so on until we find an empty slot.\n\nFormula\n\nThe formula for finding the next index during a probing sequence in double hashing is:index = (index + i * h2(key)) % table_size\n\nwhere:\n\nindex is the current index.\n\ni is the iteration number (0 for the initial try, 1 for the second try, etc.)\n\nh2(key) is the second hash function, which calculates the step size.\n\ntable_size is the size of the hash table.\n\nAdvantages\n\nLess clustering: Double hashing is highly effective in reducing clustering effects compared to linear and quadratic probing, leading to more uniform distribution of elements in the hash table.\n\nBetter performance: This decreased clustering results in better overall hash table performance, as the chances of lengthy probing sequences are reduced.","type":"content","url":"/xhashing-openaddressing#double-hashing","position":5},{"hierarchy":{"lvl1":"Hash Table - Open Addressing","lvl2":"Quadratic  Probing"},"type":"lvl2","url":"/xhashing-openaddressing#quadratic-probing","position":6},{"hierarchy":{"lvl1":"Hash Table - Open Addressing","lvl2":"Quadratic  Probing"},"content":"Quadratic probing/hashing is another collision resolution technique used in open addressing for hash tables.  It aims to reduce clustering compared to linear probing by using a quadratic formula to disperse elements and probe for empty slots. Here’s how it works:\n\nScenario\n\nImagine you have a hash table, a hash function, and keys like in the linear probing example (“apple” and “banana” mapping to index 5). Quadratic hashing still encounters the collision, but how it finds empty positions is different.\n\nSteps involved in quadratic probing:\n\nInitial placement: The first step is the same as linear probing. Quadratic probing also starts at the calculated index based on the hash function (position 5).\n\nCheck for availability: If the desired position is occupied (by “apple”), quadratic probing examines the next slots based on the quadratic pattern.\n\nQuadratic steps:\n\nInstead of a linear step size of 1, it calculates probes in the following quadratic sequence:\n\n1st probe: (initial_index + 1^2) % table_size\n\n2nd probe: (initial_index + 2^2) % table_size\n\n3rd probe: (initial_index + 3^2) % table_size\n\nAnd so on...\n\nExample:\n\nInitial Collision: Suppose the hash value for “banana” is 5 and that slot is occupied.\n\n1st Probe: The first probe would be: (5 + 1^2) % table_size = 6 % table_size = 6.\n\nChecking: If position 6 is also occupied, the next probe would be: (5 + 2^2) % table_size = 9 % table_size = 9.\n\nContinuing: This pattern continues with probes calculated as (5 + 3^2) % table_size, (5 + 4^2) % table_size, and so on until an available slot is found.\n\nBenefits of Quadratic Probing\n\nReducing primary clustering: Quadratic probing spreads out the probes more effectively than linear probing, reducing the tendency for elements to cluster very tightly in one area of the table. This can help mitigate performance degradation compared to linear probing in cases of moderate to high load factors.\n\nDrawbacks of Quadratic Probing:\n\nSecondary clustering: While it may reduce primary clustering, quadratic probing can still lead to some clustering issues known as secondary clustering.\n\nNot always guaranteed empty slot: Quadratic probing doesn’t guarantee that you’ll always find an empty slot, even if they exist in the table. This depends on the size of the hash table and the hash functions used.\n\nConclusion:\n\nQuadratic probing often provides better performance than linear probing, particularly with higher load factors, by decreasing primary clustering effects. Nonetheless, it’s important to be aware of its limitations regarding secondary clustering and the potential for not always finding available slots.","type":"content","url":"/xhashing-openaddressing#quadratic-probing","position":7},{"hierarchy":{"lvl1":"Java code for double hashing in a hash table:"},"type":"lvl1","url":"/xhashing-openaddressinghashingcodeexamples","position":0},{"hierarchy":{"lvl1":"Java code for double hashing in a hash table:"},"content":"public class DoubleHashingHashTable {\n\n    private final int tableSize;\n    private final Entry[] table;\n\n    public DoubleHashingHashTable(int tableSize) {\n        this.tableSize = tableSize;\n        this.table = new Entry[tableSize];\n    }\n\n    private int hash1(String key) {\n        return key.hashCode() % tableSize; // Replace with a better hash function\n    }\n\n    private int hash2(String key) {\n        int prime = 5; // Choose a prime number less than tableSize\n        return prime - (key.hashCode() % prime);\n    }\n\n    public void put(String key, String value) {\n        int index = insert(key, value);\n        if (index == -1) {\n            System.out.println(\"Hash table full!\");\n        }\n    }\n\n    private int insert(String key, String value) {\n        int index = hash1(key);\n        int stepSize = hash2(key);\n        int i = 0;\n\n        while (table[index] != null && table[index].key != key) {\n            index = (index + i * stepSize) % tableSize;\n            i++;\n            if (i == tableSize) {\n                return -1; // Table full\n            }\n        }\n\n        table[index] = new Entry(key, value);\n        return index;\n    }\n\n    public String get(String key) {\n        int index = find(key);\n        if (index == -1) {\n            return null;\n        }\n        return table[index].value;\n    }\n\n    private int find(String key) {\n        int index = hash1(key);\n        int stepSize = hash2(key);\n        int i = 0;\n\n        while (table[index] != null) {\n            if (table[index].key.equals(key)) {\n                return index;\n            }\n            index = (index + i * stepSize) % tableSize;\n            i++;\n            if (i == tableSize) {\n                return -1; // Key not found\n            }\n        }\n\n        return -1; // Key not found\n    }\n\n    private static class Entry {\n        String key;\n        String value;\n\n        public Entry(String key, String value) {\n            this.key = key;\n            this.value = value;\n        }\n    }\n\n    public static void main(String[] args) {\n        DoubleHashingHashTable table = new DoubleHashingHashTable(10);\n        table.put(\"apple\", \"red\");\n        table.put(\"banana\", \"yellow\");\n        table.put(\"cherry\", \"red\");\n        table.put(\"grape\", \"purple\");\n\n        System.out.println(table.get(\"apple\")); // Output: red\n        System.out.println(table.get(\"cherry\")); // Output: red\n    }\n}\n\nExplanation:\n\nThis code defines a DoubleHashingHashTable class that implements a hash table with double hashing.\n\nIt uses two separate hash functions: hash1 and hash2.\n\nThe put method inserts a key-value pair into the table. If the table is full, it returns -1.\n\nThe insert method uses the first hash function to find the initial index and then employs the second hash function to calculate the step size for probing.\n\nThe get method searches for a key in the table using a similar probing strategy.\n\nThe Entry class represents a key-value pair within the table.\n\nThe main method demonstrates how to use the DoubleHashingHashTable by inserting some key-value pairs and then retrieving them.\n\nNote: This is a basic implementation and can be further improved by considering:\n\nUsing a better hash function for hash1.\n\nImplementing deletion functionality.\n\nRehashing the table when the load factor becomes too high.\n\nHere’s a code sample demonstrating quadratic hashing in a Java hash table:\n\nJavapublic class QuadraticHashTable {\n\n    private final int tableSize;\n    private final Entry[] table;\n\n    public QuadraticHashTable(int tableSize) {\n        this.tableSize = tableSize;\n        this.table = new Entry[tableSize];\n    }\n\n    private int hash(String key) {\n        return key.hashCode() % tableSize; // Replace with a better hash function\n    }\n\n    public void put(String key, String value) {\n        int index = insert(key, value);\n        if (index == -1) {\n            System.out.println(\"Hash table full!\");\n        }\n    }\n\n    private int insert(String key, String value) {\n        int index = hash(key);\n        int i = 0;\n        int stepSize = 1;\n\n        while (table[index] != null && table[index].key != key) {\n            index = (index + stepSize * stepSize) % tableSize;\n            stepSize++;\n            if (i == tableSize) {\n                return -1; // Table full\n            }\n        }\n\n        table[index] = new Entry(key, value);\n        return index;\n    }\n\n    public String get(String key) {\n        int index = find(key);\n        if (index == -1) {\n            return null;\n        }\n        return table[index].value;\n    }\n\n    private int find(String key) {\n        int index = hash(key);\n        int i = 0;\n        int stepSize = 1;\n\n        while (table[index] != null) {\n            if (table[index].key.equals(key)) {\n                return index;\n            }\n            index = (index + stepSize * stepSize) % tableSize;\n            stepSize++;\n            if (i == tableSize) {\n                return -1; // Key not found\n            }\n        }\n\n        return -1; // Key not found\n    }\n\n    private static class Entry {\n        String key;\n        String value;\n\n        public Entry(String key, String value) {\n            this.key = key;\n            this.value = value;\n        }\n    }\n\n    public static void main(String[] args) {\n        QuadraticHashTable table = new QuadraticHashTable(10);\n        table.put(\"apple\", \"red\");\n        table.put(\"banana\", \"yellow\");\n        table.put(\"cherry\", \"red\");\n\n        System.out.println(table.get(\"apple\")); // Output: red\n        System.out.println(table.get(\"cherry\")); // Output: red\n    }\n}\n\nExplanation:\n\nThe code defines a QuadraticHashTable class with methods for inserting (put), retrieving (get), and searching for (find) key-value pairs.\n\nThe hash function calculates the initial index for a key.\n\nThe insert method implements the core logic of quadratic probing. It calculates the initial index and then uses a quadratic sequence to probe for an empty slot until it finds one or reaches the table size limit.\n\nThe get and find methods follow a similar approach to search for an existing key in the table.\n\nThe Entry class represents a key-value pair within the table.\n\nThe main method demonstrates inserting and retrieving elements from the table.\n\nNote: This is a basic implementation and can be further improved by:\n\nImplementing a better hash function for hash.\n\nImplementing deletion functionality.\n\nRehashing the table when the load factor becomes too high.","type":"content","url":"/xhashing-openaddressinghashingcodeexamples","position":1},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*"},"type":"lvl1","url":"/xhashing-understandinghashtables","position":0},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*"},"content":"A hash table (or hash map) is a data structure that efficiently stores and retrieves key-value pairs using a hash function. The function converts a key into an index used to store and locate values quickly.","type":"content","url":"/xhashing-understandinghashtables","position":1},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl2":"Real-World Use Cases of Hash Tables"},"type":"lvl2","url":"/xhashing-understandinghashtables#real-world-use-cases-of-hash-tables","position":2},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl2":"Real-World Use Cases of Hash Tables"},"content":"Hash tables are widely used in software development, databases, and networking due to their fast access times. Here are some key applications:\n\nDatabases and Caching\n\nIndexing: Hash tables help optimize database search operations.\n\nCaching: Used in applications like Redis and Memcached to store frequently accessed data.\n\nCompilers and Interpreters\n\nSymbol Tables: Stores variable names, function names, and their corresponding memory addresses.\n\nNetworking\n\nRouting Tables: Hash tables map IP addresses to network devices for efficient packet routing.\n\nDNS Resolution: Maps domain names to IP addresses.\n\nCybersecurity\n\nCryptographic Hashing: Used to store passwords securely (e.g., SHA-256, bcrypt).\n\nData Integrity Verification: Hash functions check if files have been altered.\n\nOperating Systems\n\nProcess Scheduling: Hash tables store process states efficiently.\n\nFile Systems: Used in file indexing systems.\n\nMachine Learning & AI\n\nFeature Hashing: Converts large input spaces into a fixed-size representation.\n\nNearest Neighbor Search: Accelerates similarity searches.\n\nBlockchain and Cryptography\n\nBitcoin and Ethereum use Merkle Trees, which rely on hash functions for data integrity.\n\nWeb Development\n\nSession Management: Hash maps store user sessions efficiently.\n\nAuto-Complete Features: Maps user input to predicted results.\n\nBecause of their efficiency and versatility, hash tables are a foundational data structure across various computing fields.","type":"content","url":"/xhashing-understandinghashtables#real-world-use-cases-of-hash-tables","position":3},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl2":"How Hash Tables Work"},"type":"lvl2","url":"/xhashing-understandinghashtables#how-hash-tables-work","position":4},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl2":"How Hash Tables Work"},"content":"Hashing Function: A function converts a key (e.g., a string or number) into an integer.\n\nIndexing: The computed hash determines the storage location in an array.\n\nCollision Handling: Since multiple keys can hash to the same index (collision), hash tables use methods like chaining or open addressing.","type":"content","url":"/xhashing-understandinghashtables#how-hash-tables-work","position":5},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl2":"Understanding Hash Functions"},"type":"lvl2","url":"/xhashing-understandinghashtables#understanding-hash-functions","position":6},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl2":"Understanding Hash Functions"},"content":"A hash function maps input data (keys) to an integer index in a hash table.\n\nExample of a simple hash function in Java:private int hash(String key) {\n    return Math.abs(key.hashCode()) % SIZE;  // Uses Java's built-in hashCode()\n}\n\nThe hash() method uses Java’s hashCode() function.\n\nThe modulus operation ensures the index falls within the valid range of the array.","type":"content","url":"/xhashing-understandinghashtables#understanding-hash-functions","position":7},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"Key Properties of a Good Hash Function","lvl2":"Understanding Hash Functions"},"type":"lvl3","url":"/xhashing-understandinghashtables#key-properties-of-a-good-hash-function","position":8},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"Key Properties of a Good Hash Function","lvl2":"Understanding Hash Functions"},"content":"Deterministic: The same input always produces the same output.\n\nUniform Distribution: Keys should be distributed evenly across the table.\n\nEfficient Computation: Fast calculation of hash values.\n\nMinimal Collisions: Different keys should ideally generate unique outputs.","type":"content","url":"/xhashing-understandinghashtables#key-properties-of-a-good-hash-function","position":9},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl2":"Collision Handling Methods"},"type":"lvl2","url":"/xhashing-understandinghashtables#collision-handling-methods","position":10},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl2":"Collision Handling Methods"},"content":"Since different keys may hash to the same index, hash tables use collision resolution strategies.","type":"content","url":"/xhashing-understandinghashtables#collision-handling-methods","position":11},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"1. Chaining (Separate Chaining)","lvl2":"Collision Handling Methods"},"type":"lvl3","url":"/xhashing-understandinghashtables#id-1-chaining-separate-chaining","position":12},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"1. Chaining (Separate Chaining)","lvl2":"Collision Handling Methods"},"content":"Each index in the table holds a linked list (or another data structure) to store multiple key-value pairs.\n\nIf a collision occurs, new elements are simply appended to the linked list at the index.","type":"content","url":"/xhashing-understandinghashtables#id-1-chaining-separate-chaining","position":13},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"Chaining Implementation in Java","lvl2":"Collision Handling Methods"},"type":"lvl3","url":"/xhashing-understandinghashtables#chaining-implementation-in-java","position":14},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"Chaining Implementation in Java","lvl2":"Collision Handling Methods"},"content":"import java.util.LinkedList;\n\nclass HashTableChaining {\n    private static final int SIZE = 10;\n    private LinkedList<Entry>[] table;\n\n    public HashTableChaining() {\n        table = new LinkedList[SIZE];\n        for (int i = 0; i < SIZE; i++) {\n            table[i] = new LinkedList<>();\n        }\n    }\n\n    private int hash(String key) {\n        return Math.abs(key.hashCode()) % SIZE;\n    }\n\n    public void insert(String key, String value) {\n        int index = hash(key);\n        for (Entry entry : table[index]) {\n            if (entry.key.equals(key)) {\n                entry.value = value;\n                return;\n            }\n        }\n        table[index].add(new Entry(key, value));\n    }\n\n    public String search(String key) {\n        int index = hash(key);\n        for (Entry entry : table[index]) {\n            if (entry.key.equals(key)) {\n                return entry.value;\n            }\n        }\n        return null;\n    }\n\n    public void delete(String key) {\n        int index = hash(key);\n        table[index].removeIf(entry -> entry.key.equals(key));\n    }\n\n    private static class Entry {\n        String key, value;\n        public Entry(String key, String value) { this.key = key; this.value = value; }\n    }\n\n    public static void main(String[] args) {\n        HashTableChaining ht = new HashTableChaining();\n        ht.insert(\"name\", \"Alice\");\n        ht.insert(\"age\", \"25\");\n        System.out.println(ht.search(\"name\")); // Output: Alice\n        ht.delete(\"name\");\n        System.out.println(ht.search(\"name\")); // Output: null\n    }\n}","type":"content","url":"/xhashing-understandinghashtables#chaining-implementation-in-java","position":15},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"2. Open Addressing","lvl2":"Collision Handling Methods"},"type":"lvl3","url":"/xhashing-understandinghashtables#id-2-open-addressing","position":16},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"2. Open Addressing","lvl2":"Collision Handling Methods"},"content":"Instead of using separate lists, open addressing stores all entries directly in the table. If a collision occurs, the algorithm searches for an available slot using a probing technique.","type":"content","url":"/xhashing-understandinghashtables#id-2-open-addressing","position":17},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl4":"Types of Open Addressing","lvl3":"2. Open Addressing","lvl2":"Collision Handling Methods"},"type":"lvl4","url":"/xhashing-understandinghashtables#types-of-open-addressing","position":18},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl4":"Types of Open Addressing","lvl3":"2. Open Addressing","lvl2":"Collision Handling Methods"},"content":"Linear Probing: Check the next available slot sequentially.\n\nQuadratic Probing: Check slots at increasing intervals (e.g., 1², 2², 3²…).\n\nDouble Hashing: Use a secondary hash function to find new slots.","type":"content","url":"/xhashing-understandinghashtables#types-of-open-addressing","position":19},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"Open Addressing Implementation in Java (Linear Probing)","lvl2":"Collision Handling Methods"},"type":"lvl3","url":"/xhashing-understandinghashtables#open-addressing-implementation-in-java-linear-probing","position":20},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"Open Addressing Implementation in Java (Linear Probing)","lvl2":"Collision Handling Methods"},"content":"class HashTableOpenAddressing {\n    private static final int SIZE = 10;\n    private Entry[] table;\n    private static final Entry DELETED = new Entry(null, null); // Marker for deleted entries\n\n    public HashTableOpenAddressing() {\n        table = new Entry[SIZE];\n    }\n\n    private int hash(String key) {\n        return Math.abs(key.hashCode()) % SIZE;\n    }\n\n    public void insert(String key, String value) {\n        int index = hash(key);\n        while (table[index] != null && table[index] != DELETED) {\n            index = (index + 1) % SIZE; // Linear probing\n        }\n        table[index] = new Entry(key, value);\n    }\n\n    public String search(String key) {\n        int index = hash(key);\n        while (table[index] != null) {\n            if (table[index] != DELETED && table[index].key.equals(key)) {\n                return table[index].value;\n            }\n            index = (index + 1) % SIZE;\n        }\n        return null;\n    }\n\n    public void delete(String key) {\n        int index = hash(key);\n        while (table[index] != null) {\n            if (table[index].key.equals(key)) {\n                table[index] = DELETED; // Mark as deleted\n                return;\n            }\n            index = (index + 1) % SIZE;\n        }\n    }\n\n    private static class Entry {\n        String key, value;\n        public Entry(String key, String value) { this.key = key; this.value = value; }\n    }\n\n    public static void main(String[] args) {\n        HashTableOpenAddressing ht = new HashTableOpenAddressing();\n        ht.insert(\"name\", \"Alice\");\n        ht.insert(\"age\", \"25\");\n        System.out.println(ht.search(\"name\")); // Output: Alice\n        ht.delete(\"name\");\n        System.out.println(ht.search(\"name\")); // Output: null\n    }\n}","type":"content","url":"/xhashing-understandinghashtables#open-addressing-implementation-in-java-linear-probing","position":21},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"Choosing the Right Hashing Method","lvl2":"Collision Handling Methods"},"type":"lvl3","url":"/xhashing-understandinghashtables#choosing-the-right-hashing-method","position":22},{"hierarchy":{"lvl1":"Understanding Hash Tables and Hash Functions*","lvl3":"Choosing the Right Hashing Method","lvl2":"Collision Handling Methods"},"content":"For general hash tables: MurmurHash or FNV-1a\n\nFor security: SHA-256\n\nFor simplicity: DJB2 or Remainder\n\nFor handling collisions:\n\nUse chaining when working with dynamic-sized tables.\n\nUse open addressing when memory efficiency is critical.","type":"content","url":"/xhashing-understandinghashtables#choosing-the-right-hashing-method","position":23},{"hierarchy":{"lvl1":"Huffman Code"},"type":"lvl1","url":"/xhuffmancode","position":0},{"hierarchy":{"lvl1":"Huffman Code"},"content":"","type":"content","url":"/xhuffmancode","position":1},{"hierarchy":{"lvl1":"Huffman Code","lvl2":"What is the Huffman Algorithm?"},"type":"lvl2","url":"/xhuffmancode#what-is-the-huffman-algorithm","position":2},{"hierarchy":{"lvl1":"Huffman Code","lvl2":"What is the Huffman Algorithm?"},"content":"At its core, the Huffman Algorithm is a lossless data compression algorithm.1 The “lossless” part is key – it means that when we compress data using this method and then decompress it, we get back an exact copy of the original data.2 Nothing is lost in the process.\n\nThe genius of the Huffman Algorithm, developed by David A. Huffman while he was a Ph.D. student at MIT in 1952, lies in how it assigns codes to characters.3 Instead of using a fixed number of bits for every character (like in standard ASCII, which uses 7 or 8 bits per character), Huffman coding uses variable-length codes.4 The most frequently occurring characters get shorter codes, and the less frequent characters get longer codes.5 This ultimately leads to an overall reduction in the number of bits needed to represent the data.\n\nThink of it like this: if you’re sending a message and the letter ‘e’ appears most often, wouldn’t it be more efficient to have a very short symbol for ‘e’, and perhaps a longer one for a rare letter like ‘z’? That’s the fundamental idea.","type":"content","url":"/xhuffmancode#what-is-the-huffman-algorithm","position":3},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"How Does It Work? The Encoding Process","lvl2":"What is the Huffman Algorithm?"},"type":"lvl3","url":"/xhuffmancode#how-does-it-work-the-encoding-process","position":4},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"How Does It Work? The Encoding Process","lvl2":"What is the Huffman Algorithm?"},"content":"The Huffman Algorithm works by building a special type of binary tree called a Huffman Tree (or sometimes a prefix tree).6 Here’s a step-by-step breakdown:\n\nCount Frequencies: First, we need to know how often each character (or symbol) appears in the data we want to compress. So, we scan the entire input data and count the occurrences of each unique character.\n\nExample:\n\nLet’s say our data is “ABRACADABRA”.\n\nA: 5 times\n\nB: 2 times\n\nR: 2 times\n\nC: 1 time\n\nD: 1 time\n\nCreate Leaf Nodes: For each unique character, we create a “leaf node” (think of the bottom-most parts of a tree). Each leaf node will store the character itself and its frequency.\n\nBuild the Tree (The Greedy Part): This is where the “greedy” nature of the algorithm comes in.7 A greedy algorithm is one that makes the locally optimal choice at each stage with the hope of finding a global optimum.89\n\nWe treat our list of leaf nodes as a priority queue, where the priority is determined by the frequency (lowest frequency has the highest priority for being picked).\n\nRepeat the following steps until only one node (the root of the Huffman Tree) remains:\n\na. Select Two Nodes: Extract the two nodes with the lowest frequencies from the queue.\n\nb. Create a Parent Node: Create a new internal node (a node that is not a leaf). This new node will be the parent of the two nodes selected in step (a).\n\nc. Assign Frequency to Parent: The frequency of this new parent node is the sum of the frequencies of its two children.10\n\nd. Add to Queue: Insert this new parent node back into the priority queue.\n\nLet’s visualize with our “ABRACADABRA” example:\n\nInitial nodes (Character: Frequency): (C:1), (D:1), (B:2), (R:2), (A:5)\n\nStep 1: Pick (C:1) and (D:1). Create parent (CD:2). Nodes: (CD:2), (B:2), (R:2), (A:5)\n\nStep 2: Pick (CD:2) and (B:2) (or (R:2), order doesn’t matter for same frequencies here for the selection, though it might slightly change the tree structure but not the overall compression efficiency). Let’s pick (CD:2) and (B:2). Create parent (CDB:4). Nodes: (R:2), (CDB:4), (A:5)\n\nStep 3: Pick (R:2) and (CDB:4). (Note: (R:2) has lower frequency). Create parent (RCDB:6). Nodes: (A:5), (RCDB:6)\n\nStep 4: Pick (A:5) and (RCDB:6). Create parent (ARCDB:11). This is our root node.\n\nAssign Codes: Once the Huffman Tree is built, we assign binary codes to each character.11 We do this by traversing the tree from the root to each leaf node:\n\nAssign a ‘0’ to every left branch (or edge) in the tree.\n\nAssign a ‘1’ to every right branch (or edge) in the tree.\n\nThe Huffman code for each character is the sequence of 0s and 1s encountered on the path from the root to that character’s leaf node.\n\nContinuing our example (this depends on how we arranged left/right children, let’s assume one way):\n\nA possible tree structure and codes:          (11)\n         /    \\\n        A(5)  (6)\n             /   \\\n            (4)   R(2)\n           /   \\\n          B(2) (2)\n               /  \\\n              C(1) D(1)\n\nIf we assign ‘0’ for left and ‘1’ for right:\n\nA: 0\n\nR: 11\n\nB: 100\n\nC: 1010\n\nD: 1011\n\nNotice how ‘A’ (most frequent) has the shortest code, and ‘C’ and ‘D’ (least frequent) have the longest codes. This is the magic of Huffman coding! Also, importantly, no code is a prefix of another code (e.g., ‘0’ is A’s code, no other code starts with ‘0’). This “prefix property” is crucial for decoding.\n\nEncode the Data: Replace each character in the original data with its newly generated Huffman code.\n\n“ABRACADABRA” becomes: 0 100 11 0 1010 0 1011 0 100 11 0","type":"content","url":"/xhuffmancode#how-does-it-work-the-encoding-process","position":5},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"How Does It Work? The Decoding Process","lvl2":"What is the Huffman Algorithm?"},"type":"lvl3","url":"/xhuffmancode#how-does-it-work-the-decoding-process","position":6},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"How Does It Work? The Decoding Process","lvl2":"What is the Huffman Algorithm?"},"content":"Decoding is relatively straightforward if you have the Huffman Tree (or the code table).\n\nObtain the Huffman Tree/Codes: The decoder needs the same Huffman Tree (or the mapping of codes to characters) that was used for encoding. This tree/table is often transmitted along with the compressed data.\n\nRead the Compressed Bit Stream: Start reading the encoded data bit by bit.\n\nTraverse the Tree:\n\nBegin at the root of the Huffman Tree.\n\nFor each bit read from the compressed stream:\n\nIf the bit is ‘0’, move to the left child in the tree.\n\nIf the bit is ‘1’, move to the right child in the tree.\n\nWhen you reach a leaf node, you have decoded one character. Record that character.\n\nReturn to the root of the tree and repeat the process with the next bit in the compressed stream until all bits are processed.\n\nExample of decoding 010011... using our codes:\n\nRead 0: Path is root -> left. It’s ‘A’. Output ‘A’. Back to root.\n\nRead 1: Path is root -> right. Not a leaf.\n\nRead 0: Path is current node -> left. Not a leaf.\n\nRead 0: Path is current node -> left. It’s ‘B’. Output ‘B’. Back to root.\n\nRead 1: Path is root -> right. Not a leaf.\n\nRead 1: Path is current node -> right. It’s ‘R’. Output ‘R’. Back to root. And so on.\n\nBecause of the prefix property (no code is a prefix of another), there’s no ambiguity in decoding. As soon as you reach a leaf, you know you’ve completed a character.","type":"content","url":"/xhuffmancode#how-does-it-work-the-decoding-process","position":7},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"Where is Huffman Coding Used?","lvl2":"What is the Huffman Algorithm?"},"type":"lvl3","url":"/xhuffmancode#where-is-huffman-coding-used","position":8},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"Where is Huffman Coding Used?","lvl2":"What is the Huffman Algorithm?"},"content":"Huffman coding, either in its pure form or as a component of other algorithms, is used in a wide variety of applications.12 Here are some prominent examples:\n\nFile Compression:\n\nZIP files: Classic .zip files often use a method called “Deflate,” which combines LZ77 (another compression algorithm) with Huffman coding.13\n\nGZIP files: Used extensively on Unix-like systems and for web content, GZIP also uses Deflate.14\n\nImage Compression:\n\nJPEG: While JPEG primarily uses a “lossy” compression (Discrete Cosine Transform), Huffman coding is often used as one of the final, lossless steps to compress the resulting data coefficients.\n\nPNG: This is a lossless image format, and it uses the Deflate algorithm (which includes Huffman coding) for compression.\n\nMultimedia Formats:\n\nMP3 (Audio): Huffman coding is used as part of the MP3 compression process to reduce the size of audio data.15\n\nMPEG (Video): Similar to JPEGs and MP3s, various MPEG video formats (like MPEG-2 used in DVDs, MPEG-4 used in many online videos) incorporate Huffman coding for entropy encoding parts of the video and audio data.\n\nCommunication Protocols:\n\nHTTP/2 and HTTP/3 (HPACK and QPACK): When your browser communicates with a web server using newer HTTP versions, header compression techniques like HPACK (for HTTP/2) and QPACK (for HTTP/3) use Huffman coding to reduce the size of HTTP headers, making web pages load faster.16\n\nFax machines also historically used forms of Huffman coding.17\n\nText and Data Archiving: Anytime there’s a need to store or transmit text or other data more efficiently without losing information, Huffman coding or algorithms incorporating it can be considered.\n\nIn summary, the Huffman Algorithm is a foundational technique in data compression. By assigning shorter codes to more frequent symbols and longer codes to less frequent ones, it efficiently reduces the overall size of data for storage or transmission, all while ensuring the original data can be perfectly reconstructed.18","type":"content","url":"/xhuffmancode#where-is-huffman-coding-used","position":9},{"hierarchy":{"lvl1":"Huffman Code","lvl2":"Example Code"},"type":"lvl2","url":"/xhuffmancode#example-code","position":10},{"hierarchy":{"lvl1":"Huffman Code","lvl2":"Example Code"},"content":"package huffman_code;\n\nimport java.util.*;\n\n// Node class for Huffman tree\nclass Node {\n\n    char ch;\n    int freq;\n    Node left, right;\n\n    Node(char ch, int freq)\n    {\n        this.ch = ch;\n        this.freq = freq;\n    }\n\n    Node(int freq, Node left, Node right)\n    {\n        this.ch = '\\0'; // internal node\n        this.freq = freq;\n        this.left = left;\n        this.right = right;\n    }\n\n    boolean isLeaf()\n    {\n        return left == null && right == null;\n    }\n}\n\nclass HuffmanCode {\n\n    private Node root;\n    private Map<Character, String> huffmanCode;\n\n    public HuffmanCode()\n    {\n        \n    }\n\n    public void runHuffaman(String text)\n    {\n\n        Map<Character, Integer> freqMap = buildFrequencyMap(text);\n        this.root = buildTree(freqMap);\n        this.huffmanCode = new HashMap<>();\n        buildCodes(root, \"\", huffmanCode);\n\n    }\n\n    private Map<Character, Integer> buildFrequencyMap(String text)\n    {\n        Map<Character, Integer> freqMap = new HashMap<>();\n        for (char ch : text.toCharArray()) {\n            freqMap.put(ch, freqMap.getOrDefault(ch, 0) + 1);\n        }\n        return freqMap;\n    }\n\n    private Node buildTree(Map<Character, Integer> freqMap)\n    {\n        PriorityQueue<Node> pq = new PriorityQueue<>(Comparator.comparingInt(n -> n.freq));\n        for (Map.Entry<Character, Integer> entry : freqMap.entrySet()) {\n            pq.add(new Node(entry.getKey(), entry.getValue()));\n        }\n\n        while (pq.size() > 1) {\n            Node left = pq.poll();\n            Node right = pq.poll();\n            pq.add(new Node(left.freq + right.freq, left, right));\n        }\n\n        return pq.poll(); // root\n    }\n\n    private void buildCodes(Node node, String code, Map<Character, String> map)\n    {\n        if (node == null) {\n            return;\n        }\n\n        if (node.isLeaf()) {\n            map.put(node.ch, code);\n        }\n\n        buildCodes(node.left, code + \"0\", map);\n        buildCodes(node.right, code + \"1\", map);\n    }\n\n    public String encode(String text)\n    {\n        StringBuilder encoded = new StringBuilder();\n        for (char ch : text.toCharArray()) {\n            encoded.append(huffmanCode.get(ch));\n        }\n        return encoded.toString();\n    }\n\n    public String decode(String encodedText)\n    {\n        StringBuilder decoded = new StringBuilder();\n        Node current = root;\n        for (char bit : encodedText.toCharArray()) {\n            current = (bit == '0') ? current.left : current.right;\n            if (current.isLeaf()) {\n                decoded.append(current.ch);\n                current = root;\n            }\n        }\n        return decoded.toString();\n    }\n\n    public Map<Character, String> getHuffmanCodes()\n    {\n        return this.huffmanCode;\n    }\n\n    public String stringToBinary(String text)\n    {\n\n        String newString = \"\";\n        StringBuilder sb;\n\n        for (int i = 0; i < text.length(); i++) {\n            String myBinary = \"\";\n            int asciVal = Integer.valueOf(text.charAt(i));\n\n            while (asciVal > 0) {\n                myBinary = myBinary + (asciVal % 2 == 1 ? \"1\" : \"0\");\n                asciVal /= 2;\n            }\n\n            sb = new StringBuilder(myBinary).reverse();\n            newString += sb + \"\";\n        }\n\n        return newString;\n    }\n}\n\npublic class Huffman_Code {\n\n    public static void main(String[] args)\n    {\n\n        String quit = \"n\";\n        Scanner myScan = new Scanner(System.in);\n\n        String text = \"huffman\";\n\n        \n        \n        HuffmanCode huffman = new HuffmanCode();\n        \n        System.out.println(\"Humman Code\");\n        \n        while (quit.equals(\"n\")) {\n            \n            System.out.print(\"Please enter a word or string: \");\n            text = myScan.nextLine();\n            \n            huffman.runHuffaman(text);\n\n            // Print codes\n            System.out.println(text);\n            for (var entry : huffman.getHuffmanCodes().entrySet()) {\n                System.out.println(entry.getKey() + \": \" + entry.getValue());\n            }\n\n            // Encode\n            String encoded = huffman.encode(text);\n            System.out.println(\"\\nEncoded Text : \" + encoded);\n            System.out.println(\"Binary       : \" + huffman.stringToBinary(text));\n\n            // Decode\n            String decoded = huffman.decode(encoded);\n            System.out.println(\"\\nDecoded Text:\\n\" + decoded);\n            \n            System.out.print(\"Would you like to quit: y/n:  \");\n            quit = myScan.nextLine();\n\n        }\n\n        System.out.println(\"\\nbye\\n\");\n\n\n    }\n\n}\n\n/*\nPlease enter a word or string: Mississippi\nMississippi\np: 101\ns: 0\ni: 11\nM: 100\n\nEncoded Text : 100110011001110110111\nBinary       : 10011011101001111001111100111101001111001111100111101001111000011100001101001\n\nDecoded Text:\nMississippi\nWould you like to quit: y/n: n\n\nPlease enter a word or string: Bubba blows bubbles\nBubba blows bubbles\n : 010\na: 0000\nB: 10111\nb: 11\ns: 011\nu: 100\ne: 1010\nw: 0001\nl: 001\no: 10110\n\nEncoded Text : 1011110011110000010110011011000010110101110011110011010011\nBinary       : 10000101110101110001011000101100001100000110001011011001101111111011111100111000001100010111010111000101100010110110011001011110011\n\nDecoded Text:\nBubba blows bubbles\nWould you like to quit: y/n:  y\n\n bye\n\n*/","type":"content","url":"/xhuffmancode#example-code","position":11},{"hierarchy":{"lvl1":"Huffman Code","lvl2":"Code Explanation"},"type":"lvl2","url":"/xhuffmancode#code-explanation","position":12},{"hierarchy":{"lvl1":"Huffman Code","lvl2":"Code Explanation"},"content":"We have two main pieces here: a Node class and a HuffmanCode class.","type":"content","url":"/xhuffmancode#code-explanation","position":13},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"1. The Node Class: The Building Blocks of Our Tree","lvl2":"Code Explanation"},"type":"lvl3","url":"/xhuffmancode#id-1-the-node-class-the-building-blocks-of-our-tree","position":14},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"1. The Node Class: The Building Blocks of Our Tree","lvl2":"Code Explanation"},"content":"Java// Node class for Huffman tree\nclass Node {\n\n    char ch;           // The character this node might represent (if it's a leaf)\n    int freq;          // How often this character appears, or sum of frequencies of children\n    Node left, right;  // The children of this node (null if it's a leaf)\n\n    // Constructor for LEAF nodes (nodes that represent actual characters)\n    Node(char ch, int freq)\n    {\n        this.ch = ch;\n        this.freq = freq;\n        // left and right will be null by default for a new leaf node\n    }\n\n    // Constructor for INTERNAL nodes (nodes that are created by combining two other nodes)\n    Node(int freq, Node left, Node right)\n    {\n        this.ch = '\\0'; // A null character, indicating it's not a character leaf\n        this.freq = freq;\n        this.left = left;\n        this.right = right;\n    }\n\n    // Helper method to check if this node is a leaf node\n    boolean isLeaf()\n    {\n        return left == null && right == null; // A leaf has no children\n    }\n}\n\nThink of the Node class as the blueprint for every single point or junction in our Huffman Tree.\n\nchar ch;: This variable holds the actual character (like ‘A’, ‘B’, ‘C’) if this node is a leaf node – meaning it’s at the very bottom of a branch and represents a character from our input text.\n\nint freq;\n\nThis stores the frequency.\n\nIf it’s a leaf node, freq is how many times its character (ch) appears in the text.\n\nIf it’s an internal node (a connection point within the tree, not a character itself), freq is the sum of the frequencies of all the leaves below it.\n\nNode left, right;: These are references to other Node objects. They are like the branches of the tree. left points to the child node on the left, and right points to the child node on the right. If a node is a leaf, both left and right will be null (meaning they don’t point to anything).\n\nConstructors (the Node(...) methods):\n\nThese are special methods used to create new Node objects.\n\nNode(char ch, int freq): This is used to create a leaf node. You give it a character and its frequency.\n\nNode(int freq, Node left, Node right): This is used to create an internal node. You give it the combined frequency of its children, and references to what its left child and right child should be. We use a special character '\\0' (the null character) for ch just to signify that this internal node doesn’t represent a specific character itself.\n\nisLeaf() method:\n\nboolean isLeaf(): This is a handy little helper. It returns true if the node has no left or right children (meaning it’s a leaf), and false otherwise.","type":"content","url":"/xhuffmancode#id-1-the-node-class-the-building-blocks-of-our-tree","position":15},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"2. The HuffmanCode Class: The Brains of the Operation","lvl2":"Code Explanation"},"type":"lvl3","url":"/xhuffmancode#id-2-the-huffmancode-class-the-brains-of-the-operation","position":16},{"hierarchy":{"lvl1":"Huffman Code","lvl3":"2. The HuffmanCode Class: The Brains of the Operation","lvl2":"Code Explanation"},"content":"Javaclass HuffmanCode {\n\n    private Node root; // This will store the very top node (the root) of our Huffman tree\n    private Map<Character, String> huffmanCode; // This will store the generated codes (e.g., 'A' -> \"01\")\n\n    // Constructor (currently empty, could be used for setup if needed)\n    public HuffmanCode()\n    {\n        \n    }\n\n    // Main method to orchestrate the Huffman encoding process\n    public void runHuffaman(String text)\n    {\n        // Step 1: Count character frequencies\n        Map<Character, Integer> freqMap = buildFrequencyMap(text);\n\n        // Step 2: Build the Huffman Tree using these frequencies\n        this.root = buildTree(freqMap);\n\n        // Step 3: Generate the codes (like \"0\" or \"101\") for each character from the tree\n        this.huffmanCode = new HashMap<>(); // Initialize the map to store codes\n        buildCodes(root, \"\", huffmanCode);  // Start building codes from the root\n    }\n\nThe HuffmanCode class contains all the logic to take a piece of text, build the tree, generate the codes, and then encode or decode text.\n\nprivate Node root;: This variable will eventually hold the single Node that is at the very top of our completed Huffman tree. It’s our entry point into the tree.\n\nprivate Map<Character, String> huffmanCode;: A Map is like a dictionary. This one will store each character from our text as a “key” and its corresponding Huffman code (a string of '0’s and '1’s) as its “value”. For example, {'A': \"0\", 'B': \"100\", ...}.\n\nLet’s look at its key methods:\n\npublic void runHuffaman(String text):\n\nThis is like the main manager for the Huffman process.\n\nIt first calls buildFrequencyMap(text) to count how many times each character appears in the input text.\n\nThen, it calls buildTree(freqMap) using those frequencies to construct the actual Huffman tree. The result (the root of the tree) is stored in this.root.\n\nFinally, it initializes this.huffmanCode as a new empty map and calls buildCodes(root, \"\", huffmanCode) to traverse the tree and fill up the huffmanCode map with the binary codes for each character.\n\nprivate Map<Character, Integer> buildFrequencyMap(String text):\n\nJava    private Map<Character, Integer> buildFrequencyMap(String text)\n    {\n        Map<Character, Integer> freqMap = new HashMap<>(); // Create an empty dictionary\n        for (char ch : text.toCharArray()) { // Loop through each character in the input text\n            // Get the current count of 'ch', or 0 if not seen yet, then add 1\n            freqMap.put(ch, freqMap.getOrDefault(ch, 0) + 1);\n        }\n        return freqMap; // Return the map with all character counts\n    }\n\nThis method does exactly what we described as the first step of the Huffman algorithm:\n\nIt creates an empty HashMap called freqMap.\n\nIt then loops through every single character (ch) in the input text.\n\nFor each character, it updates its count in freqMap. The getOrDefault(ch, 0) part is clever: it tries to get the current count of ch. If ch hasn’t been seen before, it defaults to 0, and then 1 is added.\n\nIt returns this populated freqMap. If text was “ABCA”, freqMap would look like {'A': 2, 'B': 1, 'C': 1}.\n\nprivate Node buildTree(Map<Character, Integer> freqMap):\n\nJava    private Node buildTree(Map<Character, Integer> freqMap)\n    {\n        // Create a priority queue. Nodes with lower frequency have higher priority.\n        PriorityQueue<Node> pq = new PriorityQueue<>(Comparator.comparingInt(n -> n.freq));\n\n        // Create a leaf node for each character and add it to the priority queue.\n        for (Map.Entry<Character, Integer> entry : freqMap.entrySet()) {\n            pq.add(new Node(entry.getKey(), entry.getValue()));\n        }\n\n        // Loop as long as there is more than one node in the queue\n        while (pq.size() > 1) {\n            // Remove the two nodes with the smallest frequency\n            Node left = pq.poll();  // Smallest\n            Node right = pq.poll(); // Second smallest\n\n            // Create a new internal node with these two nodes as children\n            // and frequency equal to the sum of the two nodes' frequencies.\n            // Add the new node to the priority queue.\n            pq.add(new Node(left.freq + right.freq, left, right));\n        }\n\n        // The remaining node is the root of the Huffman Tree\n        return pq.poll(); \n    }\n\nThis is where the Huffman tree is actually built, following the “greedy” approach:\n\nPriorityQueue<Node> pq = new PriorityQueue<>(Comparator.comparingInt(n -> n.freq));: A PriorityQueue is a special kind of list where items are automatically kept in a certain order based on their “priority.” Here, we’re telling it to prioritize Node objects based on their freq attribute – specifically, nodes with lower frequencies will be considered higher priority (meaning they come out first).\n\nfor (Map.Entry<Character, Integer> entry : freqMap.entrySet()) { ... }: It loops through our freqMap. For each character and its frequency, it creates a new leaf Node (using the first Node constructor) and adds it to the pq. So now, pq is full of leaf nodes, ordered by their frequency.\n\nwhile (pq.size() > 1) { ... }\n\nThis loop is the heart of the tree construction. It keeps running as long as there’s more than one node in thepq\n\n.\n\nNode left = pq.poll(); and Node right = pq.poll();: It takes out the two nodes with the lowest frequencies from the pq. (Remember, lowest frequency = highest priority).\n\npq.add(new Node(left.freq + right.freq, left, right));\n\nIt creates a\n\nnew internal Node\n\n.\n\nIts frequency is the sum of the frequencies of left and right.\n\nleft becomes its left child, and right becomes its right child.\n\nThis new internal node is then added back into the pq. It will find its correct place in the priority order based on its new (combined) frequency.\n\nreturn pq.poll();: When the loop finishes, there’s only one node left in the pq. This single node is the root of the entire Huffman Tree.\n\nprivate void buildCodes(Node node, String code, Map<Character, String> map):\n\nJava    private void buildCodes(Node node, String code, Map<Character, String> map)\n    {\n        if (node == null) { // Base case: if we've gone past a leaf\n            return;\n        }\n\n        // If this is a leaf node, we've found a character!\n        // Store the character and its accumulated code in our map.\n        if (node.isLeaf()) {\n            map.put(node.ch, code);\n        }\n\n        // Recursively call for the left child, appending \"0\" to the code\n        buildCodes(node.left, code + \"0\", map);\n        // Recursively call for the right child, appending \"1\" to the code\n        buildCodes(node.right, code + \"1\", map);\n    }\n\nThis method figures out the '0’s and '1’s for each character. It’s a recursive method, meaning it calls itself to solve smaller parts of the problem.\n\nif (node == null) { return; }: This is a safety check or a “base case” for the recursion. If we try to go to a child that doesn’t exist, we just stop that path.\n\nif (node.isLeaf()) { map.put(node.ch, code); }: If the current node we’re looking at is a leaf node (it has a character!), we’ve found the end of a path from the root. The code string that we’ve built up by travelling down the tree is the Huffman code for node.ch. So, we store this pair in our map (which is huffmanCode from the runHuffman method).\n\nbuildCodes(node.left, code + \"0\", map);: This is the recursive step. It calls buildCodes again, but this time for the left child of the current node. Crucially, it appends a \"0\" to the code string because we’re taking a left branch.\n\nbuildCodes(node.right, code + \"1\", map);: Similarly, it calls buildCodes for the right child, appending a \"1\" to the code string for taking a right branch.\n\nImagine starting at the root with an empty code string (\"\"). If you go left, the code becomes “0”. If you go left again, it’s “00”. If you then reach a leaf for character ‘X’, ‘X’ gets the code “00”. The method backtracks and explores all paths.\n\npublic String encode(String text):\n\nJava    public String encode(String text)\n    {\n        StringBuilder encoded = new StringBuilder();\n        for (char ch : text.toCharArray()) { // Loop through each character of the input text\n            encoded.append(huffmanCode.get(ch)); // Look up its Huffman code and add it\n        }\n        return encoded.toString(); // Return the full string of 0s and 1s\n    }\n\nOnce runHuffman has been called (so the huffmanCode map is filled), this method takes the original text and converts it into the compressed string of 0s and 1s.\n\nIt iterates through each character (ch) of the input text.\n\nFor each ch, it looks up its corresponding Huffman code in the huffmanCode map (e.g., if ch is ‘A’, it might get “0”).\n\nIt appends this code to a StringBuilder (which is an efficient way to build strings).\n\nFinally, it returns the complete encoded string.\n\npublic String decode(String encodedText):\n\nJava    public String decode(String encodedText)\n    {\n        StringBuilder decoded = new StringBuilder();\n        Node current = root; // Start at the root of our Huffman tree\n        for (char bit : encodedText.toCharArray()) { // Loop through each '0' or '1' in the encoded text\n            // If the bit is '0', move to the left child. Otherwise, move to the right child.\n            current = (bit == '0') ? current.left : current.right;\n\n            // If we've reached a leaf node, we've decoded a character!\n            if (current.isLeaf()) {\n                decoded.append(current.ch); // Add the character to our result\n                current = root;             // Go back to the root for the next character\n            }\n        }\n        return decoded.toString(); // Return the fully decoded text\n    }\n\nThis method takes a compressed string of 0s and 1s (encodedText) and converts it back to the original text.\n\nIt starts with current pointing to the root of our Huffman tree.\n\nIt reads the encodedText   one bit  (‘0’ or ‘1’) at a time.\n\nIf the bit is ‘0’, it moves current to its left child.\n\nIf the bit is ‘1’, it moves current to its right child.\n\nif (current.isLeaf()) { ... }\n\nAfter moving, it checks ifcurrent\n\nis now a leaf node.\n\nIf it is, it means we’ve successfully traced a complete Huffman code. The character at this leaf (current.ch) is appended to our decoded result.\n\nImportantly, current is then reset back to root to start searching for the next character from the current position in the encodedText.\n\nIt returns the fully decoded string.\n\npublic Map<Character, String> getHuffmanCodes():\n\nJava    public Map<Character, String> getHuffmanCodes()\n    {\n        return this.huffmanCode; // Simply returns the map of characters to their codes\n    }\n\nThis is a simple “getter” method. It just returns the huffmanCode map that was generated, in case you want to inspect the codes outside of this class.\n\npublic String stringToBinary(String text):\n\nJava    public String stringToBinary(String text)\n    {\n        String newString = \"\";\n        StringBuilder sb;\n\n        for (int i = 0; i < text.length(); i++) {\n            String myBinary = \"\";\n            int asciVal = Integer.valueOf(text.charAt(i)); // Get ASCII value of character\n\n            // Convert ASCII value to its binary representation\n            while (asciVal > 0) {\n                myBinary = myBinary + (asciVal % 2 == 1 ? \"1\" : \"0\");\n                asciVal /= 2;\n            }\n\n            // The above loop generates binary in reverse, so reverse it\n            sb = new StringBuilder(myBinary).reverse();\n            newString += sb + \"\"; // Append to the result\n        }\n        return newString;\n    }\n}\n\nThis method is a bit different from the core Huffman logic. It appears to be a utility function to convert a given string into its standard fixed-length binary representation (likely 7 or 8-bit ASCII, padded implicitly).\n\nIt iterates through each character of the input text.\n\nint asciVal = Integer.valueOf(text.charAt(i)); gets the numerical ASCII value of the character (e.g., ‘A’ is 65).\n\nThe while (asciVal > 0) loop converts this decimal ASCII value into a binary string. It does this by repeatedly taking the number modulo 2 (to get the last bit) and then dividing by 2.\n\nsb = new StringBuilder(myBinary).reverse(); is needed because the loop builds the binary string in reverse order.\n\nIt concatenates these binary representations for all characters.\n\nImportant Note on stringToBinary: This method is not producing Huffman codes. Huffman codes are variable-length and based on frequency. stringToBinary produces fixed-length codes (like standard ASCII-to-binary). It might be included in this class for comparison purposes – to show how much space Huffman coding saves compared to a standard binary representation of text. For example, you could encode “AAAAA” using Huffman (might be “00000”) and then using stringToBinary (might be “0100000101000001010000010100000101000001”) to see the difference.\n\nSo, the main parts for the Huffman algorithm itself are runHuffman (and the methods it calls: buildFrequencyMap, buildTree, buildCodes), encode, and decode. The Node class is the essential data structure it uses.\n\nHopefully, this breaks down the code in a way that makes sense! The key is to see how these different code pieces work together to implement the steps of the Huffman algorithm we discussed earlier.","type":"content","url":"/xhuffmancode#id-2-the-huffmancode-class-the-brains-of-the-operation","position":17},{"hierarchy":{"lvl1":"JAVA Techniques"},"type":"lvl1","url":"/xjavatechniques","position":0},{"hierarchy":{"lvl1":"JAVA Techniques"},"content":"These are techniques specific to JAVA.","type":"content","url":"/xjavatechniques","position":1},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap"},"type":"lvl1","url":"/xjavahashmaptreemaplinkedhashmap","position":0},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap"},"content":"","type":"content","url":"/xjavahashmaptreemaplinkedhashmap","position":1},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap","lvl2":"1. HashMap"},"type":"lvl2","url":"/xjavahashmaptreemaplinkedhashmap#id-1-hashmap","position":2},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap","lvl2":"1. HashMap"},"content":"Characteristics:\n\nUnordered collection (no guarantees on order).\n\nFastest performance for basic operations (get, put) with O(1) average complexity.\n\nAllows null as key/value.\n\nExample:import java.util.HashMap;\nimport java.util.Map;\n\npublic class HashMapExample {\n    public static void main(String[] args) {\n        Map<String, Integer> map = new HashMap<>();\n\n        map.put(\"apple\", 3);\n        map.put(\"banana\", 2);\n        map.put(\"orange\", 5);\n\n        System.out.println(\"Value of apple: \" + map.get(\"apple\"));\n\n        System.out.println(\"Iterating HashMap:\");\n        for (String key : map.keySet()) {\n            System.out.println(\"Key: \" + key + \", Value: \" + map.get(key));\n        }\n    }\n}\n\nBest Uses:\n\nWhen you need fast lookup and insertion.\n\nOrder doesn’t matter.","type":"content","url":"/xjavahashmaptreemaplinkedhashmap#id-1-hashmap","position":3},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap","lvl2":"2. TreeMap"},"type":"lvl2","url":"/xjavahashmaptreemaplinkedhashmap#id-2-treemap","position":4},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap","lvl2":"2. TreeMap"},"content":"Characteristics:\n\nSorted according to natural ordering or a specified comparator.\n\nO(log n) complexity for put, get, remove operations.\n\nCannot contain null keys (but can have null values).\n\nExample:import java.util.Map;\nimport java.util.TreeMap;\n\npublic class TreeMapExample {\n    public static void main(String[] args) {\n        Map<String, Integer> map = new TreeMap<>();\n\n        map.put(\"apple\", 3);\n        map.put(\"banana\", 2);\n        map.put(\"orange\", 5);\n\n        System.out.println(\"Value of banana: \" + map.get(\"banana\"));\n\n        System.out.println(\"Iterating TreeMap (sorted):\");\n        for (String key : map.keySet()) {\n            System.out.println(\"Key: \" + key + \", Value: \" + map.get(key));\n        }\n    }\n}\n\nBest Uses:\n\nMaintaining sorted order (such as alphabetical order).\n\nRange queries (subMap(), headMap(), tailMap()).","type":"content","url":"/xjavahashmaptreemaplinkedhashmap#id-2-treemap","position":5},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap","lvl2":"3. LinkedHashMap"},"type":"lvl2","url":"/xjavahashmaptreemaplinkedhashmap#id-3-linkedhashmap","position":6},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap","lvl2":"3. LinkedHashMap"},"content":"Characteristics:\n\nMaintains insertion order.\n\nSlightly slower than HashMap, with O(1) average complexity.\n\nAllows null key/value.\n\nExample:import java.util.LinkedHashMap;\nimport java.util.Map;\n\npublic class LinkedHashMapExample {\n    public static void main(String[] args) {\n        Map<String, Integer> map = new LinkedHashMap<>();\n\n        map.put(\"apple\", 3);\n        map.put(\"banana\", 2);\n        map.put(\"orange\", 5);\n\n        System.out.println(\"Value of orange: \" + map.get(\"orange\"));\n\n        System.out.println(\"Iterating LinkedHashMap (insertion order):\");\n        for (String key : map.keySet()) {\n            System.out.println(\"Key: \" + key + \", Value: \" + map.get(key));\n        }\n    }\n}\n\nBest Uses:\n\nCaching implementations, where insertion/access order is important.\n\nPreserving the order of inserted keys (e.g., configurations, ordered tasks).","type":"content","url":"/xjavahashmaptreemaplinkedhashmap#id-3-linkedhashmap","position":7},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap","lvl2":"Summary (Quick Reference):"},"type":"lvl2","url":"/xjavahashmaptreemaplinkedhashmap#summary-quick-reference","position":8},{"hierarchy":{"lvl1":"Examples of Java’s HashMap, TreeMap, and LinkedHashMap","lvl2":"Summary (Quick Reference):"},"content":"Feature\n\nHashMap\n\nTreeMap\n\nLinkedHashMap\n\nOrder\n\nNo order guarantee\n\nSorted\n\nInsertion order\n\nPerformance (get, put)\n\nO(1) avg.\n\nO(log n)\n\nO(1) avg.\n\nNull Keys Allowed\n\nYes\n\nNo\n\nYes\n\nReferences:\n\nOracle Documentation – HashMap\n\nOracle Documentation – TreeMap\n\nOracle Documentation – LinkedHashMap","type":"content","url":"/xjavahashmaptreemaplinkedhashmap#summary-quick-reference","position":9},{"hierarchy":{"lvl1":"Programming To The Interface, Not The Implementation\""},"type":"lvl1","url":"/xprogrammingtotheinterfacemd","position":0},{"hierarchy":{"lvl1":"Programming To The Interface, Not The Implementation\""},"content":"“Programming to the interface, not the implementation,” including the definitions  of Interface and Abstract","type":"content","url":"/xprogrammingtotheinterfacemd","position":1},{"hierarchy":{"lvl1":"Programming To The Interface, Not The Implementation\"","lvl2":"Background Information"},"type":"lvl2","url":"/xprogrammingtotheinterfacemd#background-information","position":2},{"hierarchy":{"lvl1":"Programming To The Interface, Not The Implementation\"","lvl2":"Background Information"},"content":"1. Definitions\n\nAbstract Class:\n\nAn abstract class is a class declared with the abstract keyword.\n\nIt cannot be instantiated directly using new.\n\nIt can contain both abstract methods (methods without implementation) and concrete methods (methods with implementation).\n\n\n\nIt1 can also have instance variables (state) and constructors, just like a regular class.\n\nA (concrete) class extends an abstract class and must provide implementations for any inherited abstract methods.\n\nAbstract classes are often used as a base class for a group of related subclasses, providing some common implementation details or state while leaving other parts for the subclasses to define. They represent an “is-a” relationship with some shared structure or partial implementation.\n\nInterface:\n\nIn Java, an interface is a reference type that acts as a contract or a blueprint for classes.\n\nIt defines a set of abstract methods (methods without implementations, prior to Java 8) and/or constants (static final fields).\n\nSince Java 8, interfaces can also contain default methods (methods with an implementation that implementing classes inherit) and static methods. Since Java 9, they can also include private methods.\n\nA class implements an interface, promising to provide concrete implementations for all the abstract methods declared in that interface (unless the class itself is abstract).\n\nInterfaces cannot be instantiated directly using new.\n\nTheir primary purpose is to define a common set of behaviors (a contract) that multiple, potentially unrelated classes can adhere to. They enable polymorphism and achieve abstraction.\n\nKey Difference Summary: Interfaces primarily define a contract (what methods must exist), focusing on what a class can do. Abstract classes can provide a partial implementation and common state, often serving as a structural base for related classes. A class can implement multiple interfaces but can only extend one class (abstract or concrete).","type":"content","url":"/xprogrammingtotheinterfacemd#background-information","position":3},{"hierarchy":{"lvl1":"Programming To The Interface, Not The Implementation\"","lvl2":"Programming to the Interface, Not the Implementation"},"type":"lvl2","url":"/xprogrammingtotheinterfacemd#programming-to-the-interface-not-the-implementation","position":4},{"hierarchy":{"lvl1":"Programming To The Interface, Not The Implementation\"","lvl2":"Programming to the Interface, Not the Implementation"},"content":"This is a fundamental design principle in object-oriented programming. It means:\n\nWhen you declare variables, write method parameters, or specify return types, you should use the most general type possible that provides the necessary functionality – usually an interface type – rather than a specific concrete class type.\n\n“Programming to the Interface”: Your code depends on the contract defined by the interface (e.g., Set, List, Map). It interacts with objects based only on the methods and behaviors guaranteed by that interface.\n\nJava// GOOD: Programming to the 'Set' interface\nSet<String> names = new HashSet<>();\nprocessSet(names);\n\npublic void processSet(Set<String> data) { // Accepts any kind of Set\n    // Code here only uses methods defined in the Set interface\n    if (data.contains(\"Alice\")) {\n         data.remove(\"Alice\");\n    }\n    // ...\n}\n\n“Not the Implementation”: You avoid tying your code directly to a specific concrete class (e.g., HashSet, ArrayList, HashMap) unless you absolutely need functionality unique to that specific class (which is rare for general use).\n\nJava// LESS FLEXIBLE: Programming to the 'HashSet' implementation\nHashSet<String> names = new HashSet<>();\nprocessSpecificSet(names);\n\npublic void processSpecificSet(HashSet<String> data) { // Only accepts HashSets\n   // Code might potentially use HashSet-specific methods (if any existed beyond Set)\n   // or implicitly rely on HashSet's behavior (like lack of order).\n   // ...\n}\n\nWhy follow this principle?\n\nFlexibility/Maintainability: Your code becomes much easier to change. If you decide you need a different implementation later (e.g., you need sorted elements), you only change the object creation part (new ...()), not the rest of the code that uses the object via its interface.\n\nLoose Coupling: Components of your system depend on abstract contracts rather than concrete details of other components. This reduces dependencies and makes the system more modular. Changes in one part are less likely to break others.\n\nTestability: It’s easier to substitute mock objects (for testing) that implement the same interface.\n\nAbstraction: It hides unnecessary implementation details, making the code cleaner and focusing on the essential behavior.","type":"content","url":"/xprogrammingtotheinterfacemd#programming-to-the-interface-not-the-implementation","position":5},{"hierarchy":{"lvl1":"Serialization"},"type":"lvl1","url":"/xserializable","position":0},{"hierarchy":{"lvl1":"Serialization"},"content":"","type":"content","url":"/xserializable","position":1},{"hierarchy":{"lvl1":"Serialization","lvl2":"Definition of Serialization"},"type":"lvl2","url":"/xserializable#definition-of-serialization","position":2},{"hierarchy":{"lvl1":"Serialization","lvl2":"Definition of Serialization"},"content":"Serialization is the process of converting an object into a format that can be stored or transmitted and later reconstructed. This allows objects to be saved to a file, sent over a network, or stored in a database in a way that they can be reconstructed later.","type":"content","url":"/xserializable#definition-of-serialization","position":3},{"hierarchy":{"lvl1":"Serialization","lvl2":"Uses of Serialization"},"type":"lvl2","url":"/xserializable#uses-of-serialization","position":4},{"hierarchy":{"lvl1":"Serialization","lvl2":"Uses of Serialization"},"content":"Persistence – Storing objects in a file or database for later retrieval.\n\nCommunication – Transmitting objects over a network (e.g., in distributed applications).\n\nCaching – Storing objects in memory to speed up future access.\n\nDeep Copying – Cloning objects by serializing and deserializing them.\n\nInteroperability – Sharing data between different programming languages or systems.","type":"content","url":"/xserializable#uses-of-serialization","position":5},{"hierarchy":{"lvl1":"Serialization","lvl2":"Example in Java"},"type":"lvl2","url":"/xserializable#example-in-java","position":6},{"hierarchy":{"lvl1":"Serialization","lvl2":"Example in Java"},"content":"In Java, serialization is implemented using the Serializable interface.import java.io.*;\n\n// Class that implements Serializable\nclass Person implements Serializable {\n    private static final long serialVersionUID = 1L;  // Ensure versioning compatibility\n    String name;\n    int age;\n\n    // Constructor\n    public Person(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    // Method to display object data\n    public void display() {\n        System.out.println(\"Name: \" + name + \", Age: \" + age);\n    }\n}\n\npublic class SerializationExample {\n    public static void main(String[] args) {\n        Person person = new Person(\"John\", 30);\n\n        // Serialize the object\n        try (FileOutputStream fileOut = new FileOutputStream(\"person.ser\");\n             ObjectOutputStream out = new ObjectOutputStream(fileOut)) {\n            out.writeObject(person);\n            System.out.println(\"Object serialized successfully.\");\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n\n        // Deserialize the object\n        try (FileInputStream fileIn = new FileInputStream(\"person.ser\");\n             ObjectInputStream in = new ObjectInputStream(fileIn)) {\n            Person deserializedPerson = (Person) in.readObject();\n            System.out.println(\"Object deserialized successfully.\");\n            deserializedPerson.display();\n        } catch (IOException | ClassNotFoundException e) {\n            e.printStackTrace();\n        }\n    }\n}\n\nExplanation:\n\nThe Person class implements Serializable.\n\nObjectOutputStream writes the object to a file (person.ser).\n\nObjectInputStream reads the object back and restores it.","type":"content","url":"/xserializable#example-in-java","position":7},{"hierarchy":{"lvl1":"Serialization","lvl2":"Equivalent Example in Python"},"type":"lvl2","url":"/xserializable#equivalent-example-in-python","position":8},{"hierarchy":{"lvl1":"Serialization","lvl2":"Equivalent Example in Python"},"content":"In Python, pickle is commonly used for serialization.import pickle\n\n# Class definition\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def display(self):\n        print(f\"Name: {self.name}, Age: {self.age}\")\n\n# Serialize object\nperson = Person(\"John\", 30)\nwith open(\"person.pkl\", \"wb\") as file:\n    pickle.dump(person, file)\n    print(\"Object serialized successfully.\")\n\n# Deserialize object\nwith open(\"person.pkl\", \"rb\") as file:\n    deserialized_person = pickle.load(file)\n    print(\"Object deserialized successfully.\")\n    deserialized_person.display()\n\nKey Differences:\n\npickle.dump() serializes the object.\n\npickle.load() deserializes the object.","type":"content","url":"/xserializable#equivalent-example-in-python","position":9},{"hierarchy":{"lvl1":"Serialization","lvl2":"Equivalent Example in C#"},"type":"lvl2","url":"/xserializable#equivalent-example-in-c","position":10},{"hierarchy":{"lvl1":"Serialization","lvl2":"Equivalent Example in C#"},"content":"In C#, System.Runtime.Serialization and System.Xml.Serialization are used.using System;\nusing System.IO;\nusing System.Runtime.Serialization;\nusing System.Runtime.Serialization.Formatters.Binary;\n\n[Serializable]\nclass Person\n{\n    public string Name { get; set; }\n    public int Age { get; set; }\n\n    public Person(string name, int age)\n    {\n        Name = name;\n        Age = age;\n    }\n\n    public void Display()\n    {\n        Console.WriteLine($\"Name: {Name}, Age: {Age}\");\n    }\n}\n\nclass SerializationExample\n{\n    static void Main()\n    {\n        Person person = new Person(\"John\", 30);\n        string filePath = \"person.dat\";\n\n        // Serialize object\n        IFormatter formatter = new BinaryFormatter();\n        using (Stream stream = new FileStream(filePath, FileMode.Create, FileAccess.Write, FileShare.None))\n        {\n            formatter.Serialize(stream, person);\n            Console.WriteLine(\"Object serialized successfully.\");\n        }\n\n        // Deserialize object\n        using (Stream stream = new FileStream(filePath, FileMode.Open, FileAccess.Read, FileShare.Read))\n        {\n            Person deserializedPerson = (Person)formatter.Deserialize(stream);\n            Console.WriteLine(\"Object deserialized successfully.\");\n            deserializedPerson.Display();\n        }\n    }\n}\n\nKey Differences:\n\nUses [Serializable] attribute.\n\nBinaryFormatter is used for serialization and deserialization.\n\nFileStream handles writing and reading from a file.","type":"content","url":"/xserializable#equivalent-example-in-c","position":11},{"hierarchy":{"lvl1":"Serialization","lvl2":"Summary"},"type":"lvl2","url":"/xserializable#summary","position":12},{"hierarchy":{"lvl1":"Serialization","lvl2":"Summary"},"content":"Java: Uses Serializable interface and ObjectOutputStream/ObjectInputStream.\n\nPython: Uses pickle.dump() and pickle.load().\n\nC#: Uses [Serializable] attribute and BinaryFormatter.\n\nEach language has different serialization approaches but achieves the same goal—converting objects into a storable/transmittable format and reconstructing them later.","type":"content","url":"/xserializable#summary","position":13},{"hierarchy":{"lvl1":"Skip List"},"type":"lvl1","url":"/xskiplist","position":0},{"hierarchy":{"lvl1":"Skip List"},"content":"","type":"content","url":"/xskiplist","position":1},{"hierarchy":{"lvl1":"Skip List","lvl2":"Introduction"},"type":"lvl2","url":"/xskiplist#introduction","position":2},{"hierarchy":{"lvl1":"Skip List","lvl2":"Introduction"},"content":"Skip lists are a powerful data structure that offer efficient search and insertion operations on sorted data. They achieve this by combining the simplicity of linked lists with the efficiency of jump searches. Here’s a deeper dive into their inner workings:\n\nStructure:\n\nLevels: A skip list is made up of multiple levels, with Level 0 being the bottommost level and acting as a standard sorted linked list. Higher levels contain fewer elements and serve as shortcuts to navigate the data faster.\n\nNodes:\n\nEach element in the skip list is stored in a node. A node typically contains the element’s value and pointers:\n\nForward Pointers: These point to the next element in the same level, maintaining the sorted order within each level.\n\nShortcut Pointers (Optional): These pointers “jump” over some elements in the level below, allowing for faster traversal during search and insertion.\n\nRandom Height Assignment:\n\nA crucial aspect of skip lists is the random height assigned to each element. This randomness is what gives them their probabilistic nature.\n\nA coin-flipping approach (or any other random number generation) is used to determine the height. Higher levels have fewer elements because the chance of a successful coin flip (reaching a higher level) decreases with each level.\n\nSearching in a Skip List:\n\nStart at the highest level (Level 3 in the 4-level example).\n\nCompare the search value with the current element’s value.\n\nIf the search value is less, move to the previous element using the forward pointer in the current level.\n\nIf the search value is greater and there’s a shortcut pointer available, use it to jump several elements ahead in the level below (Level 2).\n\nRepeat steps 2-4 until you either find the element or reach the end of the level.\n\nIf you haven’t found it yet, move down to Level 1 and repeat the process (compare, move, jump using shortcuts if available).\n\nFinally, search the bottom level (Level 0) using the standard linked list traversal.\n\nBenefits:\n\nAverage Search Time (O(log n)): Due to the shortcut pointers, searching a skip list on average takes logarithmic time (O(log n)), where n is the number of elements. This is significantly faster than a linear search (O(n)) in a standard linked list.\n\nEfficient Insertions: Similar to searching, insertions also benefit from the layered structure. By efficiently navigating through the levels, the element can be inserted in its correct sorted position.\n\nSimpler than Balanced Trees: Compared to balanced search trees (e.g., AVL trees), skip lists are easier to implement and have lower memory overhead.\n\nDrawbacks:\n\nProbabilistic: The random height assignment makes skip lists probabilistic. While the average performance is excellent, there’s a small chance of the worst-case scenario (O(n)) happening in search or insertion.\n\nSpace Overhead: The shortcut pointers add some extra space compared to a regular linked list.\n\nOverall, skip lists offer a compelling balance between simplicity and efficiency for maintaining sorted data. They are a powerful alternative to balanced search trees in situations where the slight possibility of a worst-case scenario is acceptable.","type":"content","url":"/xskiplist#introduction","position":3},{"hierarchy":{"lvl1":"Skip List","lvl2":"Skiplist Diagram"},"type":"lvl2","url":"/xskiplist#skiplist-diagram","position":4},{"hierarchy":{"lvl1":"Skip List","lvl2":"Skiplist Diagram"},"content":"Here’s a diagram of a skip list with 4 levels:         Level 3  ->  80  ->  ...\n                     ^\n                     |\n        Level 2  ->  40  ->  60  ->  ...\n                     ^         ^         ^\n                     |         |         |\n        Level 1  ->  20  ->  30  ->  50  ->  ...\n                     ^         ^         ^         ^\n                     |         |         |         |  \nLevel 0 (Bottom) ->  5  ->  10  ->  15  ->  25  ->  35\n\nExplanation:\n\nThis diagram shows a skip list with four levels (Level 0, Level 1, Level 2, Level 3).\n\nSimilar to the previous diagram, Level 0 is the bottommost sorted linked list.\n\nElements have values and pointers. Solid arrows show pointers to the next element in the same level. Dashed arrows represent shortcut pointers that jump over elements in the lower level.\n\nIn this example:\n\nElements 5, 10, 15, 25, and 35 only appear in Level 0.\n\nElements 20, 30, and 50 have a level of 1 (one shortcut pointer).\n\nElements 40 and 60 have a level of 2 (two shortcut pointers).\n\nElement 80 has the highest level (3) with three shortcut pointers, skipping all elements in the lower levels.","type":"content","url":"/xskiplist#skiplist-diagram","position":5},{"hierarchy":{"lvl1":"Skip List","lvl2":"Lecture code explaination"},"type":"lvl2","url":"/xskiplist#lecture-code-explaination","position":6},{"hierarchy":{"lvl1":"Skip List","lvl2":"Lecture code explaination"},"content":"Skip Lists are a probabilistic alternative to traditional sorted linked lists. They achieve faster search times by utilizing a linked list structure with multiple layers (levels).\n\nHere’s a breakdown of the code:","type":"content","url":"/xskiplist#lecture-code-explaination","position":7},{"hierarchy":{"lvl1":"Skip List","lvl3":"Classes:","lvl2":"Lecture code explaination"},"type":"lvl3","url":"/xskiplist#classes","position":8},{"hierarchy":{"lvl1":"Skip List","lvl3":"Classes:","lvl2":"Lecture code explaination"},"content":"Node: This class represents a single node in the SkipList. It has two properties:\n\nkey: An integer value representing the data stored in the node.\n\nforward: An array of pointers to other nodes. The length of this array determines the level of the node in the SkipList.\n\nSkipList: This class implements the SkipList data structure. It has several properties and methods:\n\nmaxLevel: An integer specifying the maximum level allowed in the SkipList.\n\nP: A double value between 0 and 1 representing the probability of adding a new level when inserting a node.\n\nlevel: An integer representing the current highest level in the SkipList.\n\nhead: A pointer to the head node of the SkipList. This node has a special key value (usually -1) and forward pointers for all possible levels.","type":"content","url":"/xskiplist#classes","position":9},{"hierarchy":{"lvl1":"Skip List","lvl3":"Methods:","lvl2":"Lecture code explaination"},"type":"lvl3","url":"/xskiplist#methods","position":10},{"hierarchy":{"lvl1":"Skip List","lvl3":"Methods:","lvl2":"Lecture code explaination"},"content":"","type":"content","url":"/xskiplist#methods","position":11},{"hierarchy":{"lvl1":"Skip List","lvl4":"Helper Methods","lvl3":"Methods:","lvl2":"Lecture code explaination"},"type":"lvl4","url":"/xskiplist#helper-methods","position":12},{"hierarchy":{"lvl1":"Skip List","lvl4":"Helper Methods","lvl3":"Methods:","lvl2":"Lecture code explaination"},"content":"randomLevel(): This function generates a random integer value between 1 and maxLevel that determines the level of a new node being inserted. It uses the P value to simulate a coin toss. With a higher P, there’s a greater chance of getting a higher level.\n\ncreateNode(int key, int level): This function creates a new Node object with the specified key and level.","type":"content","url":"/xskiplist#helper-methods","position":13},{"hierarchy":{"lvl1":"Skip List","lvl3":"Insert Element","lvl2":"Lecture code explaination"},"type":"lvl3","url":"/xskiplist#insert-element","position":14},{"hierarchy":{"lvl1":"Skip List","lvl3":"Insert Element","lvl2":"Lecture code explaination"},"content":"insertElement(int key): This function inserts a new element with the provided key into the SkipList. Here’s a simplified explanation of the process:\n\nThe provided function insertElement(int key) inserts a new element with the specified key into the SkipList data structure. Here’s a breakdown of how it works:\n\n1. Initialization:\n\nNode current = head;: This line sets a pointer current to the head node of the SkipList. This will be used to traverse the list during insertion.\n\nNode update[] = new Node[maxLevel + 1];: This line creates an array of Node pointers named update. This array will hold references to nodes at each level that will be used to update the forward pointers during insertion.\n\n2. Traversing Levels and Finding Insertion Point:\n\nfor (int i = level; i >= 0; i--)  : This loop iterates through each level of the SkipList, starting from the highest level (level ) down to level 0.\n\nwhile (current.forward[i] != null && current.forward[i].key < key): This inner loop iterates within a specific level, moving the current pointer forward until it reaches the end of the level (null) or finds a node with a key greater than the key being inserted. This ensures we find the last node before the insertion point for the new element.\n\nupdate[i] = current;: After finding the appropriate position in the current level, the update array at index i is assigned the value of the current pointer. This essentially stores references to nodes at each level that will be used to link the new node into the SkipList.\n\n3. Checking for Existing Key:\n\ncurrent = current.forward[0]: This line moves the current pointer to the node pointed to by the head node’s forward pointer at level 0 (the bottommost level). This effectively checks if a node with the same key already exists in the list.\n\nif (current == null || current.key != key): This condition checks if the current pointer is null (meaning the key is not present) or if the key of the current node (if found) doesn’t match the key being inserted. This indicates that we need to insert a new node.\n\n4. Determining Random Level for New Node:\n\nint rlevel = randomLevel();: This line calls the randomLevel() function (assumed to be implemented elsewhere) to generate a random level for the new node. The randomLevel() function likely uses a probability P to determine the level with a higher chance of getting a higher level for the new node.\n\n5. Updating Head Pointers if Needed:\n\nif (rlevel > level)  : This condition checks if the randomly generated level (rlevel ) for the new node is higher than the current highest level (level ) in the SkipList.\n\nfor (int i = (level + 1); i < (rlevel + 1); i++)  : This loop iterates from the current highest level (level+ 1) up to the randomly generated level (rlevel ).\n\nupdate[i] = head;: Inside the loop, each element of the update array for these new levels is assigned the head node. This essentially updates the head node’s forward pointers for these higher levels to point to the new node being inserted. This creates a new “tower” in the SkipList if the random level is higher.\n\nlevel = rlevel;: This line updates the level variable to reflect the new highest level in the SkipList after potentially adding new head pointers.\n\n6. Creating the New Node:\n\nNode n = createNode(key, rlevel);: This line calls the createNode(key, rlevel) function (assumed to be implemented elsewhere) to create a new Node object with the specified key and the randomly generated level (rlevel). This function likely allocates memory and sets the initial forward pointers of the new node to null.\n\n7. Updating Forward Pointers for Insertion:\n\nfor (int i = 0; i <= rlevel; i++)  : This loop iterates through all levels, including the new ones if applicable (up to rlevel).\n\nn.forward[i] = update[i].forward[i];: This line updates the forward pointer of the new node (n) at level i to point to the node currently stored in the update array at the same level i. This essentially connects the new node to the previous nodes at each level.\n\nupdate[i].forward[i] = n;: This line updates the forward pointer of the node stored in the update array at level i","type":"content","url":"/xskiplist#insert-element","position":15},{"hierarchy":{"lvl1":"Skip List","lvl3":"Search Element","lvl2":"Lecture code explaination"},"type":"lvl3","url":"/xskiplist#search-element","position":16},{"hierarchy":{"lvl1":"Skip List","lvl3":"Search Element","lvl2":"Lecture code explaination"},"content":"searchElement(int key): This function searches for an element with the provided key in the SkipList. It follows a similar process as insertElement to traverse down each level until it finds the key or reaches the end of the list. It then prints whether the key was found or not.\n\nThe provided function searchElement(int key) searches for a node with the specified key in the SkipList data structure. Here’s a breakdown of how it works:\n\n1. Initialization:\n\nNode current = head;: This line sets a pointer current to the head node of the SkipList. This will be used to traverse the list during the search.\n\nSystem.out.println(\"\\n---------------------\\n\");: This line prints a line separator.\n\n2. Traversing Levels:\n\nfor (int i = level; i >= 0; i--): This loop iterates through each level of the SkipList, starting from the highest level (level) down to level 0.\n\n3. Searching Within Each Level:\n\nwhile (current.forward[i] != null && current.forward[i].key < key): This loop iterates within a specific level, moving the current pointer forward until it reaches the end of the level (null) or finds a node with a key greater than or equal to the key being searched for. This ensures we find the last node before (or the node itself) that has a key less than the target key.\n\n4. Search Result:\n\nif (current.forward[0] == null)  : This condition checks if the loop in step 3 completed without finding a node with a key greater than or equal to the target key  at level 0 (the bottommost level). This essentially means the target key is not present in the SkipList.\n\nSystem.out.println(\"Not Found\"); return;: If the key is not found, the function prints a message indicating “Not Found” and exits by returning from the function.\n\n5. Checking the Found Node (if any):\n\ncurrent = current.forward[0]: This line assumes we didn’t exit in the previous step (i.e., the key might have been found). Here, the current pointer is moved to the node pointed to by the head node’s forward pointer at level 0. This effectively moves to the first node in the list (remember, level 0 represents the bottommost level with all actual data).\n\nif (current.key == key)  : This condition checks if the key of the current node (potentially the found node)  matches the target key .\n\nSystem.out.println(\"Found key: \" + key);: If the keys match, the function prints a message indicating \"Found key: \" followed by the actual key value.\n\nelse : If the keys don’t match (i.e., we moved to a node with a higher key but not the exact target key), it implies the target key is not present in the list.\n\nSystem.out.println(\"Not Found\");: The function prints a message indicating “Not Found”.\n\nOverall, the searchElement function efficiently searches for a node with a specific key in the SkipList by utilizing the multi-level structure. It traverses down each level, stopping at the last node before the target key (or the node itself if the key exists). Finally, it checks if the key matches and prints the appropriate message.","type":"content","url":"/xskiplist#search-element","position":17},{"hierarchy":{"lvl1":"Skip List","lvl3":"Delete Element","lvl2":"Lecture code explaination"},"type":"lvl3","url":"/xskiplist#delete-element","position":18},{"hierarchy":{"lvl1":"Skip List","lvl3":"Delete Element","lvl2":"Lecture code explaination"},"content":"deleteElement(int key): This function searches for a node with the provided key and removes it from the SkipList. It adjusts the forward pointers of the surrounding nodes to skip over the deleted node. It also checks if the highest level can be reduced after a deletion.\n\nThe provided function deleteElement(int key) removes a node with the specified key from the SkipList data structure. Here’s a breakdown of how it works:\n\n1. Debugging Message (Commented Out):\n\nJava// Print a message indicating the key to be deleted (for debugging purposes)\nSystem.out.println(\"\\n\" + key + \" is to be deleted\\n\");\n\nThis line is commented out but serves a debugging purpose. It would print a message indicating the key being deleted.\n\n2. Initialization:\n\nNode current = head;: This line sets a pointer current to the head node of the SkipList. This will be used to traverse the list during deletion.\n\n3. Traversing Levels:\n\nfor (int i = level; i >= 0; i--): This loop iterates through each level of the SkipList, starting from the highest level (level) down to level 0.\n\n4. Searching Within Each Level:\n\nwhile (current.forward[i] != null && current.forward[i].key <= key): This loop iterates within a specific level, moving the current pointer forward until it reaches the end of the level (null) or finds a node with a key greater than the key being deleted. This ensures we find the node before or the node itself that has the key we want to delete.\n\n5. Deletion Logic:\n\nif (current.forward[i].key == key)  : This condition checks if the current node’s forward pointer at the current level points to the node with the  key  to be deleted.\n\nSystem.out.println(\"delete found\");: This line (for debugging) prints a message indicating the deletion target is found.\n\ncurrent.forward[i] = current.forward[i].forward[i]: This is the core deletion step. It updates the forward pointer of the current node at the current level to skip over the node being deleted. It essentially points to the node that comes after the deleted node in that level.\n\nif (current.key == -1 && current.forward[i] == null) :  This condition checks if the deletion happened at level 0 (i.e., the head node) and the head node’s forward pointer became null after the deletion. This means the list is now empty.\n\nlevel--;: If the list is empty, the level is reduced to reflect that there are no elements anymore.\n\nSystem.out.println(\"level deleted\");: This line (for debugging) prints a message indicating the level has been reduced.\n\n6. Moving to the Next Node (if not deleted):\n\nelse  : If the key  is not found at the current level (i.e., the loop condition current.forward[i].key <= key is not met), the else block executes.\n\ncurrent = current.forward[i]: This line simply moves the current pointer to the next node in the current level, continuing the search for the target key.\n\nOverall, the deleteElement function efficiently removes a node with the specified key from the SkipList by adjusting the forward pointers of surrounding nodes to skip over the deleted node. It also handles the case where the deletion empties the list, reducing the highest level (effectively making the list empty).\n\ndisplayList(): This function prints the contents of the SkipList. It iterates through each level, starting from the highest, and prints the keys of the nodes in that level.\n\nOverall, Skip Lists provide a good balance between insertion, search, and deletion operations. They are well-suited for scenarios where search operations are frequent.","type":"content","url":"/xskiplist#delete-element","position":19},{"hierarchy":{"lvl1":"Skip List","lvl2":"Lecture Code"},"type":"lvl2","url":"/xskiplist#lecture-code","position":20},{"hierarchy":{"lvl1":"Skip List","lvl2":"Lecture Code"},"content":"/*\nProject: \tSkiplist\nProgrammer:\tJames Goudy\n */\npackage skiplists_rev24;\n\nclass Node {\n\n    // A single node in the SkipList\n    public int key;\n    public Node[] forward;\n\n    public Node(int key, int level) {\n        // Initializes a new Node with a key and an array of forward pointers\n        this.key = key;\n        forward = new Node[level + 1];\n\n        for (int c = 0; c < level + 1; c++) {\n            forward[c] = null;\n        }\n    }\n}\n\nclass SkipList {\n\n    // A SkipList data structure\n    private int maxLevel;\n    private double P;\n    private int level = 0;\n    private Node head;\n\n    public SkipList(int maxLevel, double P) {\n        // Constructor for SkipList, initializes head node with special key\n        this.maxLevel = maxLevel;\n        this.P = P;\n        level = 0;\n        head = new Node(-1, maxLevel);\n    }\n\n    int randomLevel() {\n        // Generates a random level for a new node\n        double r = Math.random();\n        int lvl = 0;\n        while (r < P && lvl < maxLevel) {\n            lvl++;\n            r = Math.random();\n        }\n        return lvl;\n    }\n\n    static Node createNode(int key, int level) {\n        // Creates a new node with a key and specified level\n        Node n = new Node(key, level);\n        return n;\n    }\n\n    public void insertElement(int key) {\n        // Inserts a new element with the provided key into the SkipList\n        Node current = head;\n        Node update[] = new Node[maxLevel + 1];\n\n        for (int i = level; i >= 0; i--) {\n            // Traverse each level, find the last node before the key\n            while (current.forward[i] != null \n                    && current.forward[i].key < key) {\n                current = current.forward[i];\n            }\n            update[i] = current;\n        }\n\n        current = current.forward[0];\n\n        if (current == null || current.key != key) {\n            // If key not found, insert a new node\n            int rlevel = randomLevel();\n\n            if (rlevel > level) {\n                // If random level is higher than current level, \n                // update head pointers\n                for (int i = (level + 1); i < (rlevel + 1); i++) {\n                    update[i] = head;\n                }\n                level = rlevel;\n            }\n\n            Node n = createNode(key, rlevel);\n\n            for (int i = 0; i <= rlevel; i++) {\n                // Update forward pointers of new node \n                // and previous nodes at each level\n                n.forward[i] = update[i].forward[i];\n                update[i].forward[i] = n;\n            }\n            System.out.println(\"Successfully Inserted key \" + key + \"\\n\");\n        }\n    }\n\n    void searchElement(int key) {\n        // Searches for an element with the provided key in the SkipList\n        Node current = head;\n        System.out.println(\"\\n---------------------\\n\");\n        for (int i = level; i >= 0; i--) {\n            // Traverse each level, find the last node before the key\n            while (current.forward[i] != null \n                    && current.forward[i].key < key) {\n                current = current.forward[i];\n            }\n        }\n\n        if (current.forward[0] == null) {\n            // Key not found\n            System.out.println(\"Not Found\");\n            return;\n        }\n\n        current = current.forward[0];\n\n        if (current.key == key) {\n            // Key found\n            System.out.println(\"Found key: \" + key);\n        } else {\n            // Key not found\n            System.out.println(\"Not Found\");\n        }\n    }\n\n    //---------------------------------------\n    void deleteElement(int key) {\n        // Print a message indicating the key \n        // to be deleted (for debugging purposes)\n        System.out.println(\"\\n\" + key + \" is to be deleted\\n\");\n\n        Node current = head;\n\n        // Traverse down each level of the SkipList\n        for (int i = level; i >= 0; i--) {\n            // Search for the node with the key or \n            // the last node before the key at the current level\n            while (current.forward[i] != null \n                    && current.forward[i].key <= key) {\n                // If the key is found in the current level\n                if (current.forward[i].key == key) {\n                    System.out.println(\"delete found\");\n\n                    // Update the forward pointer \n                    // of the current node to skip the deleted node\n                    current.forward[i] = current.forward[i].forward[i];\n\n                    // If the head node's forward pointer \n                    // becomes null after deletion \n                    // and the current level is 0, \n                    // it means the list is empty, \n                    // so reduce the level\n                    if (current.key == -1 && current.forward[i] == null) {\n                        level--;\n                        System.out.println(\"level deleted\");\n                    }\n                } else {\n                    // If the key is not found at the current level, \n                    // move to the next node\n                    current = current.forward[i];\n                }\n            }\n        }\n    }\n\n    void displayList() {\n        // Prints the contents of the SkipList\n        System.out.println(\"\\n*****Skip List*****\\n\");\n        for (int i = 0; i <= level; i++) {\n            Node node = head.forward[i];\n            System.out.print(\"Level \" + i + \": \");\n            // Traverse each level and print the keys of the nodes\n            while (node != null) {\n                System.out.print(node.key + \" \");\n                node = node.forward[i];\n            }\n            System.out.println(\"\");\n        }\n    }\n}\n\npublic class Skiplists_rev24 {\n\n    /**\n     * @param args the command line arguments\n     */\n    public static void main(String[] args) {\n        // create SkipList object with MAXLVL and P > 0 and P < 1 \n        int MAXLVL = 4;\n\n        // the higer the probability number,\n        // the greaterchance of more levels.\n        double prob = .75;\n\n        SkipList lst = new SkipList(MAXLVL, prob);\n\n        //lst.insertElement(35);\n        lst.insertElement(3);\n        lst.insertElement(6);\n        lst.insertElement(7);\n        lst.insertElement(9);\n        lst.insertElement(12);\n        lst.insertElement(19);\n\n        lst.insertElement(17);\n\n        lst.insertElement(26);\n        lst.insertElement(21);\n        lst.insertElement(25);\n        lst.displayList();\n\n        lst.searchElement(19);\n        lst.searchElement(25);\n        lst.searchElement(9);\n        lst.searchElement(5);\n        lst.searchElement(55);\n\n        lst.deleteElement(25);\n        lst.displayList();\n\n        lst.deleteElement(7);\n        lst.displayList();\n\n        lst.deleteElement(3);\n        lst.displayList();\n\n        lst.deleteElement(17);\n        lst.displayList();\n\n        System.out.println(\"\\nbye\\n\");\n    }\n\n}\n\n","type":"content","url":"/xskiplist#lecture-code","position":21},{"hierarchy":{"lvl1":"Skip List","lvl3":"Output","lvl2":"Lecture Code"},"type":"lvl3","url":"/xskiplist#output","position":22},{"hierarchy":{"lvl1":"Skip List","lvl3":"Output","lvl2":"Lecture Code"},"content":"Note: Output will be different for the levels each time due to the randomness factorSuccessfully Inserted key 3\n\nSuccessfully Inserted key 6\n\nSuccessfully Inserted key 7\n\nSuccessfully Inserted key 9\n\nSuccessfully Inserted key 12\n\nSuccessfully Inserted key 19\n\nSuccessfully Inserted key 17\n\nSuccessfully Inserted key 26\n\nSuccessfully Inserted key 21\n\nSuccessfully Inserted key 25\n\n\n*****Skip List*****\n\nLevel 0: 3 6 7 9 12 17 19 21 25 26 \nLevel 1: 3 6 7 9 12 17 19 21 25 26 \nLevel 2: 3 6 7 9 17 19 25 26 \nLevel 3: 3 6 9 17 19 25 \nLevel 4: 3 6 9 17 19 \n\n---------------------\n\nFound key: 19\n\n---------------------\n\nFound key: 25\n\n---------------------\n\nFound key: 9\n\n---------------------\n\nNot Found\n\n---------------------\n\nNot Found\n\n25 is to be deleted\n\ndelete found\ndelete found\ndelete found\ndelete found\n\n*****Skip List*****\n\nLevel 0: 3 6 7 9 12 17 19 21 26 \nLevel 1: 3 6 7 9 12 17 19 21 26 \nLevel 2: 3 6 7 9 17 19 26 \nLevel 3: 3 6 9 17 19 \nLevel 4: 3 6 9 17 19 \n\n7 is to be deleted\n\ndelete found\ndelete found\ndelete found\n\n*****Skip List*****\n\nLevel 0: 3 6 9 12 17 19 21 26 \nLevel 1: 3 6 9 12 17 19 21 26 \nLevel 2: 3 6 9 17 19 26 \nLevel 3: 3 6 9 17 19 \nLevel 4: 3 6 9 17 19 \n\n3 is to be deleted\n\ndelete found\ndelete found\ndelete found\ndelete found\ndelete found\n\n*****Skip List*****\n\nLevel 0: 6 9 12 17 19 21 26 \nLevel 1: 6 9 12 17 19 21 26 \nLevel 2: 6 9 17 19 26 \nLevel 3: 6 9 17 19 \nLevel 4: 6 9 17 19 \n\n17 is to be deleted\n\ndelete found\ndelete found\ndelete found\ndelete found\ndelete found\n\n*****Skip List*****\n\nLevel 0: 6 9 12 19 21 26 \nLevel 1: 6 9 12 19 21 26 \nLevel 2: 6 9 19 26 \nLevel 3: 6 9 19 \nLevel 4: 6 9 19 \n\nbye\n","type":"content","url":"/xskiplist#output","position":23},{"hierarchy":{"lvl1":"Terms and Concepts"},"type":"lvl1","url":"/xterms","position":0},{"hierarchy":{"lvl1":"Terms and Concepts"},"content":"","type":"content","url":"/xterms","position":1},{"hierarchy":{"lvl1":"Iterator"},"type":"lvl1","url":"/xterms-iterator","position":0},{"hierarchy":{"lvl1":"Iterator"},"content":"In Java, an iterator is an interface that allows you to traverse elements in a collection one at a time. It provides a standardized way to loop through various collections like ArrayList, HashSet, and more, regardless of their underlying implementation.\n\nHere are some key points about iterators in Java:\n\nFunctionality:\n\nTraversing Collections: Iterators act like a cursor that points to the current element in a collection. You can use the hasNext() method to check if there are more elements remaining, and next() to retrieve the next element in the iteration process.\n\nModification: Unlike the older Enumeration interface, iterators allow you to remove elements from the collection you’re iterating over using the remove() method. This maintains a safe and well-defined way to modify the collection during iteration.\n\nBenefits of Using Iterators:\n\nUniversality:  Since most collection classes in Java implement the Iterator interface, you can use the same looping pattern to iterate through different collection types with consistent behavior.\n\nSafe Removal: The remove() method allows for safe modification of the collection during iteration. This prevents issues like concurrent modification exceptions that can occur with other looping mechanisms.\n\nEfficiency:  Iterators can be efficient, especially when dealing with large collections, as they retrieve elements on demand.\n\nUsing an Iterator:\n\nImport the Interface: You’ll typically need to import the java.util.Iterator interface at the beginning of your code.\n\nGet an Iterator: Most collection classes provide an iterator() method that returns an iterator object specific to that collection.\n\nLooping:  Use a while loop to iterate through the collection. Inside the loop, call hasNext() to check for elements, and next() to access the current element.\n\nOptional Removal: If needed, you can call remove() to remove the element you just accessed using next(). However, keep in mind that removing elements while iterating might have specific restrictions depending on the collection type.\n\nBy understanding iterators, you can effectively process and manipulate elements within various collections in your Java programs.","type":"content","url":"/xterms-iterator","position":1},{"hierarchy":{"lvl1":"Iterator","lvl2":"Example Code"},"type":"lvl2","url":"/xterms-iterator#example-code","position":2},{"hierarchy":{"lvl1":"Iterator","lvl2":"Example Code"},"content":"import java.util.ArrayList;\nimport java.util.Iterator;\n\npublic class IteratorExample {\n\n  public static void main(String[] args) {\n    // Create an ArrayList of names\n    ArrayList<String> names = new ArrayList<String>();\n    names.add(\"Alice\");\n    names.add(\"Bob\");\n    names.add(\"Charlie\");\n\n    // Get an iterator for the ArrayList\n    Iterator<String> it = names.iterator();\n\n    // Loop through the elements using hasNext() and next()\n    System.out.println(\"Names in the ArrayList:\");\n    while (it.hasNext()) {\n      String name = it.next();\n      System.out.println(name);\n    }\n  }\n}\n\n    ","type":"content","url":"/xterms-iterator#example-code","position":3},{"hierarchy":{"lvl1":"Iterator","lvl2":"Iterator vs For statement"},"type":"lvl2","url":"/xterms-iterator#iterator-vs-for-statement","position":4},{"hierarchy":{"lvl1":"Iterator","lvl2":"Iterator vs For statement"},"content":"Both iterators and for statements are used for looping through collections in Java, but they have some key differences:\n\nFocus:\n\nIterator:  An iterator is an object that provides a way to access elements in a collection one at a time. It offers a more general-purpose approach to traversing various data structures.\n\nFor statement: A for statement is a syntactic construct specifically designed for looping through collections. It offers a concise and readable way to iterate, especially for simple forward iteration.\n\nFunctionality:\n\nIterator:  Provides methods like hasNext() and next() for element access and checking. It also offers optional removal of elements with remove().\n\nFor statement (for-each loop):  This type of for statement is specifically designed for iterating over collections. It automatically retrieves the next element and assigns it to a temporary variable within the loop. It doesn’t provide direct access to the current element’s index or removal functionality.\n\nUse Cases:\n\nIterator:  Use iterators when you need more control over the iteration process, such as removing elements during iteration or working with custom data structures that don’t have built-in for loop support.\n\nFor statement (for-each loop):  Use for-each loops for simple forward iteration through collections where you only need to access the elements themselves.  They are generally more concise and readable for these scenarios.\n\nHere’s a table summarizing the key differences:\n\nFeature\n\nIterator\n\nFor Statement (for-each loop)\n\nType\n\nInterface\n\nSyntactic construct\n\nFocus\n\nTraversing elements one by one\n\nLooping through collections\n\nFunctionality\n\nhasNext(), next(), remove()\n\nAutomatic element access\n\nIndex access\n\nNo direct access\n\nNo access\n\nElement modification\n\nOptional with remove()\n\nNot possible\n\nUse cases\n\nMore control, custom data structures\n\nSimple forward iteration\n\nChoosing Between Iterator and For Statement:\n\nIn most cases, for simple iteration through collections, the for-each loop is preferred due to its conciseness and readability.\n\nIf you need more control over the iteration process, like removing elements or working with custom data structures, then iterators are the way to go.","type":"content","url":"/xterms-iterator#iterator-vs-for-statement","position":5},{"hierarchy":{"lvl1":"Radix - Number Bases"},"type":"lvl1","url":"/xterms-radix","position":0},{"hierarchy":{"lvl1":"Radix - Number Bases"},"content":"In the context of coding, radix (also sometimes called base) refers to the number of unique digits used to represent numbers in a positional numeral system. Here’s a breakdown:\n\nPositional Numeral System:\n\nThis is a system in which the value of a digit depends on its position within the number. The most common example is the decimal system used in everyday life, where we have 10 digits (0-9) and the position of a digit determines its value by powers of 10. For example, in the number 123, the “1” represents 1 x 10^2 (100), the “2” represents 2 x 10^1 (20), and the “3” represents 3 x 10^0 (3).\n\nRadix and Digits:\n\nThe radix of a system defines the number of unique digits used. So, the decimal system has a radix of 10 because it uses 10 digits. Other common systems include:\n\nBinary (base 2): Uses only 2 digits (0 and 1).\n\nOctal (base 8): Uses 8 digits (0-7).\n\nHexadecimal (base 16): Uses 16 digits (0-9, A-F).\n\nWhy Radix Matters in Coding:\n\nUnderstanding radix is crucial in several coding aspects:\n\nConverting between different numeral systems: Programmers often need to convert between different bases, for example, from decimal to binary (common in computer hardware) or vice versa. Knowing the radix is essential for performing these conversions accurately.\n\nData representation: Numbers in memory are often stored in binary format using a specific number of bits. Understanding radix allows programmers to interpret and manipulate these binary representations.\n\nError checking: Some error checking techniques rely on calculating checksums or hash values based on specific radices. Understanding the radix used in these calculations is essential for interpreting the results.\n\nCommunication protocols: Sometimes, data is exchanged between systems using different radices (e.g., ASCII uses base-10 for characters). Knowing the radices involved is crucial for proper data transmission and interpretation.\n\nIn summary, understanding radix is a fundamental concept in coding, as it forms the foundation for representing, manipulating, and interpreting numerical data in various contexts.\n\nFor example:\n\nIn the decimal system (the most common system), the radix is ten, as it uses the ten digits from 0 through 9.\n\nIn hexadecimal (base-16), the radix is sixteen, allowing digits from 0 to 15 (where A represents 10, B represents 11, and so on).\n\nWhen you perform operations like parsing integers or converting numbers to strings, the radix determines how the numbers are interpreted or displayed\n\nFor instance:\n\nInteger.parseInt(\"11\", 16) interprets “11” as a base-16 number, resulting in 17 (1*16 + 1).\n\nInteger.toString(11, 16) converts the decimal value 11 to hexadecimal, resulting in B.","type":"content","url":"/xterms-radix","position":1},{"hierarchy":{"lvl1":"Serializable"},"type":"lvl1","url":"/xterms-serializable","position":0},{"hierarchy":{"lvl1":"Serializable"},"content":"“Serializable” refers to a crucial concept related to data storage and transmission. Let me break it down for you:\n\nSerialization:\n\nDefinition: Serialization is the process of converting a data structure or object into a sequence of bits. These bits can then be stored in a file, memory buffer, or transmitted across a network connection.\n\nPurpose: Serialization allows data to be saved persistently (e.g., onto a disk) or transmitted between different computer environments.\n\nUse Cases:\n\nSaving an object’s state to a file.\n\nSending data over a network.\n\nStoring data in a database.\n\nDeserialization:\n\nDefinition: Deserialization is the reverse process. It involves reading data from a serialized format (e.g., from a file) and reconstructing an object with the same state.\n\nPurpose: Deserialization allows us to recreate an object from its serialized form.\n\nExample: Imagine saving a complex data structure (like an intricate graph or a user’s session data) by serializing the root object. Later, you can deserialize it to restore the original object.","type":"content","url":"/xterms-serializable","position":1},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)"},"type":"lvl1","url":"/xunderstandingbfs-202504","position":0},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)"},"content":"","type":"content","url":"/xunderstandingbfs-202504","position":1},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)","lvl2":"What is BFS?"},"type":"lvl2","url":"/xunderstandingbfs-202504#what-is-bfs","position":2},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)","lvl2":"What is BFS?"},"content":"Imagine you’re exploring a maze. BFS is like exploring it level by level. You start at the entrance (the source node). First, you check all the paths directly connected to the entrance (one step away). Then, you explore all the paths that are two steps away from the entrance, then three steps away, and so on. You explore broadly before going deeper into any one path.\n\nIn technical terms, BFS is an algorithm for traversing or searching tree or graph data structures. It starts at a selected node (the source) and explores all of the neighbor nodes at the present depth or level  prior to moving on to the nodes at the next depth level. It uses a queue (First-In, First-Out) data structure to keep track of the next node to visit.","type":"content","url":"/xunderstandingbfs-202504#what-is-bfs","position":3},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)","lvl2":"Why Use BFS?"},"type":"lvl2","url":"/xunderstandingbfs-202504#why-use-bfs","position":4},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)","lvl2":"Why Use BFS?"},"content":"BFS is particularly useful for a few key tasks:\n\nFinding the Shortest Path: In graphs where all edges have the same “cost” or weight (like in the maze example, where each step is equal), BFS is guaranteed to find the shortest path between the starting node and any other reachable node in terms of the number of edges.\n\nLevel Order Traversal: It naturally visits nodes level by level, which can be useful in hierarchical structures.\n\nConnectivity Checking: You can use BFS to determine if a node is reachable from a starting node or to find all reachable nodes.","type":"content","url":"/xunderstandingbfs-202504#why-use-bfs","position":5},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)","lvl3":"Real-Life Examples","lvl2":"Why Use BFS?"},"type":"lvl3","url":"/xunderstandingbfs-202504#real-life-examples","position":6},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)","lvl3":"Real-Life Examples","lvl2":"Why Use BFS?"},"content":"BFS is used in many applications:\n\nSocial Networks: Finding friends-of-friends. If you want to see all people within ‘X’ connections of you, BFS is a natural fit. It explores your direct friends (level 1), then their friends (level 2), and so on.\n\nGPS Navigation: Finding the shortest route (in terms of number of turns or segments, not necessarily distance/time if roads have different speeds/lengths) between two points on a map.\n\nWeb Crawlers: Search engines use crawlers to discover web pages. A crawler might start at a seed page and use BFS to find all pages linked from it (level 1), then all pages linked from those pages (level 2), etc.\n\nNetwork Broadcasting: Sending a message to all nodes in a network efficiently.\n\nFinding Connected Components: Identifying groups of interconnected nodes in a graph.\n\n \n\n## Code Example","type":"content","url":"/xunderstandingbfs-202504#real-life-examples","position":7},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)","lvl3":"Code Analysis","lvl2":"Why Use BFS?"},"type":"lvl3","url":"/xunderstandingbfs-202504#code-analysis","position":8},{"hierarchy":{"lvl1":"Understanding Breadth-First Search (BFS)","lvl3":"Code Analysis","lvl2":"Why Use BFS?"},"content":"BFS Class: This class represents the graph itself.\n\nnumVertices: Stores the total number of nodes (vertices) in the graph.\n\nadjacencyList: This is the core data structure for storing the graph. It’s a List where each index corresponds to a vertex. The element at each index is a LinkedList<Integer> containing all the vertices directly connected to that vertex (its neighbors). This is called an adjacency list representation.\n\nBFS(int vertices) (Constructor): Initializes the graph with a specific number of vertices and creates empty adjacency lists for each.\n\naddEdge(int source, int destination): Adds a connection (an edge) between two vertices. Since it adds the destination to the source’s list and the source to the destination’s list, it creates an undirected edge (meaning the connection goes both ways).\n\nperformBFS(int startVertex) Method: This is where the BFS magic happens.\n\nvisited: A boolean array to keep track of which vertices have already been visited. This prevents infinite loops in graphs with cycles.\n\nqueue: A Queue (implemented using LinkedList) is used to store the vertices to be visited. BFS relies on the FIFO (First-In, First-Out) nature of a queue.\n\nInitialization: The startVertex is marked as visited and added to the queue.\n\nTraversal Loop (while (!queue.isEmpty())): The loop continues as long as there are nodes in the queue waiting to be processed.\n\ncurrentVertex = queue.poll(): Removes the next vertex from the front of the queue. This is the vertex currently being visited.\n\nSystem.out.print(currentVertex + \" \");: Prints the visited vertex.\n\nNeighbor Exploration (for (int neighbor : ...)): It iterates through all the neighbors of the currentVertex (obtained from the adjacencyList).\n\nif (!visited[neighbor]): Checks if the neighbor has already been visited.\n\nEnqueueing: If the neighbor hasn’t been visited, it’s marked as visited and added to the end of the queue (queue.offer(neighbor)). This ensures that nodes at the current level are fully explored before moving to the next level.\n\nBreadthFirst_Rev2504 Class (Main Program):\n\nmain(String[] args): The entry point of the program.\n\nCreates a BFS graph object with 11 vertices.\n\nCalls addEdge multiple times to define the connections in the graph, matching the diagram in the comments.\n\nCalls performBFS(0) to run BFS starting from vertex 0.\n\nCalls performBFS(6) to run BFS starting from vertex 6, demonstrating how the traversal changes based on the starting point.\n\nIn essence, the code sets up a graph using adjacency lists and then implements the BFS algorithm using a queue and a visited array to explore the graph level by level, printing the nodes in the order they are visited.\n\n \n\n```java /* BREADTH FIRST Developer: James Goudy */ package breadthfirst_rev2504a;\n\nimport java.util.LinkedList;\nimport java.util.Queue;\nimport java.util.List;\nimport java.util.ArrayList;\n\n// Class representing a graph using adjacency lists\nclass BFS {// Total number of vertices in the graph\nprivate int numVertices;\n\n// Adjacency list to store edges\nprivate List<LinkedList<Integer>> adjacencyList;\n\n// Constructor to initialize the graph\npublic BFS(int vertices) {\n    this.numVertices = vertices;\n    this.adjacencyList = new ArrayList<>(vertices);\n\n    // Initialize each adjacency list for every vertex\n    for (int i = 0; i < vertices; i++) {\n        this.adjacencyList.add(new LinkedList<>());\n    }\n}\n\n// Method to add an edge between two vertices\npublic void addEdge(int source, int destination) {\n\n    this.adjacencyList.get(source).add(destination);\n\n    // For an undirected graph\n    this.adjacencyList.get(destination).add(source);\n}\n\n// Method to perform Breadth-First Search starting from a given vertex (Iterative)\npublic void performBFS(int startVertex) {\n\n    // Track visited vertices\n    boolean[] visited = new boolean[numVertices];\n\n    // Queue to maintain BFS traversal order\n    Queue<Integer> queue = new LinkedList<>();\n\n    // Mark start vertex as visited\n    visited[startVertex] = true;\n\n    // Add start vertex to the queue\n    queue.offer(startVertex);\n\n    System.out.println(\"Breadth-First Search (Iterative) starting from vertex \"\n                                        + startVertex + \":\");\n\n    // Continue BFS traversal until queue becomes empty\n    while (!queue.isEmpty()) {\n\n        // Dequeue vertex from the queue\n        int currentVertex = queue.poll();\n\n        // Print the current vertex\n        System.out.print(currentVertex + \" \");\n\n        // Explore all adjacent vertices of the current vertex\n        for (int neighbor : this.adjacencyList.get(currentVertex)) {\n\n            // If neighbor is not visited yet\n            if (!visited[neighbor]) {\n\n                // Mark neighbor as visited\n                visited[neighbor] = true;\n\n                // Add neighbor to the queue\n                queue.offer(neighbor);\n            }\n        }\n    }\n\n    // Print newline after traversal completion\n    System.out.println();\n}\n\n// Method to perform Breadth-First Search starting from a given vertex (Recursive)\npublic void performBFSRecursive(int startVertex) {\n    boolean[] visited = new boolean[numVertices];\n    Queue<Integer> queue = new LinkedList<>();\n\n    System.out.println(\"Breadth-First Search (Recursive) starting from vertex \"\n                                        + startVertex + \":\");\n\n    visited[startVertex] = true;\n    queue.offer(startVertex);\n    recursiveBFS(queue, visited);\n    System.out.println();\n}\n\nprivate void recursiveBFS(Queue<Integer> queue, boolean[] visited) {\n    if (queue.isEmpty()) {\n        return;\n    }\n\n    int currentVertex = queue.poll();\n    System.out.print(currentVertex + \" \");\n\n    for (int neighbor : this.adjacencyList.get(currentVertex)) {\n        if (!visited[neighbor]) {\n            visited[neighbor] = true;\n            queue.offer(neighbor);\n        }\n    }\n    recursiveBFS(queue, visited);\n}\n\n}\n\npublic class BreadthFirst_Rev2504a {/**\n * @param args the command line arguments\n */\npublic static void main(String[] args)\n{\n    BFS graph = new BFS(11);\n\n    graph.addEdge(0, 1);\n    graph.addEdge(0, 2);\n    graph.addEdge(1, 3);\n    graph.addEdge(2, 4);\n    graph.addEdge(4, 5);\n\n    graph.addEdge(0, 6);\n    graph.addEdge(0, 7);\n    graph.addEdge(7, 8);\n    graph.addEdge(7, 9);\n\n    graph.addEdge(9, 10);\n\n    graph.performBFS(0);\n    graph.performBFSRecursive(0);\n\n    graph.performBFS(6);\n    graph.performBFSRecursive(6);\n}\n\n}\n\n/*\n\nGraph Map based on the addEdge calls:0\n\n/  /|/  / | 1  2  6  7\n|  |    / 3  4   8   9\n|       |\n5        10\n\nBreadth-First Search (Iterative) starting from vertex 0:\n0 1 2 6 7 3 4 8 9 5 10\nBreadth-First Search (Recursive) starting from vertex 0:\n0 1 2 6 7 3 4 8 9 5 10\nBreadth-First Search (Iterative) starting from vertex 6:\n6 0 1 2 7 3 4 8 9 5 10\nBreadth-First Search (Recursive) starting from vertex 6:\n6 0 1 2 7 3 4 8 9 5 10\n\n*/","type":"content","url":"/xunderstandingbfs-202504#code-analysis","position":9},{"hierarchy":{"lvl1":"Understanding Depth-First Search (DFS)"},"type":"lvl1","url":"/xunderstandingdfs-202504","position":0},{"hierarchy":{"lvl1":"Understanding Depth-First Search (DFS)"},"content":"What is DFS?\n\nImagine exploring the same maze as before, but this time, instead of checking all paths at the current level, you pick one path and go as deep as possible until you hit a dead end. Then, you backtrack to the last branching point and try another path from there. You prioritize going deep down a single branch before exploring other branches.\n\nIn technical terms, DFS is an algorithm for traversing or searching tree or graph data structures. It starts at a selected node (the source) and explores as far as possible along each branch before backtracking. It uses a stack (Last-In, First-Out) data structure or recursion to keep track of the next node to visit.\n\nWhy Use DFS?\n\nDFS is particularly useful for several key tasks:\n\nPath Finding: DFS can be used to find if a path exists between two nodes. It explores each path until it finds the target or exhausts all possibilities.\n\nDetecting Cycles: DFS can detect cycles in a graph. If you encounter a visited node that is still in the current recursion stack, it indicates a cycle.\n\nTopological Sorting: For directed acyclic graphs (DAGs), DFS can be used to perform a topological sort, which orders the nodes such that for every directed edge from node A to node B, node A comes before node B in the ordering.\n\nFinding Connected Components: Similar to BFS, DFS can be used to find all reachable nodes from a starting node and identify connected components in a graph.\n\nSolving Puzzles: Many puzzles that involve exploring possibilities, like Sudoku solvers or finding a path through a maze, can be effectively solved using DFS.\n\nReal-Life Examples\n\nDFS is used in various applications:\n\nBacktracking Algorithms: Many algorithms that involve trying out different possibilities and undoing choices if they don’t lead to a solution use DFS principles.\n\nCompiler Design: DFS can be used in compilers for tasks like syntax analysis and semantic analysis.\n\nFile System Traversal: When you explore folders and subfolders on your computer, many operating systems use a form of DFS.\n\nNetwork Analysis: Identifying dependencies or hierarchical structures in a network.\n\n \n\nCode Example/*\nDEPTH FIRST\nDeveloper: James Goudy (Modified)\n */\npackage depthfirst_rev2504;\n\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Stack;\n\n// Class representing a graph using adjacency lists\nclass DFS {\n\n    // Total number of vertices in the graph\n    private int numVertices;\n\n    // Adjacency list to store edges\n    private List<LinkedList<Integer>> adjacencyList;\n\n    // Constructor to initialize the graph\n    public DFS(int vertices) {\n        this.numVertices = vertices;\n        this.adjacencyList = new ArrayList<>(vertices);\n\n        // Initialize each adjacency list for every vertex\n        for (int i = 0; i < vertices; i++) {\n            this.adjacencyList.add(new LinkedList<>());\n        }\n    }\n\n    // Method to add an edge between two vertices\n    public void addEdge(int source, int destination) {\n\n        this.adjacencyList.get(source).add(destination);\n\n        // For an undirected graph\n        this.adjacencyList.get(destination).add(source);\n    }\n\n    // Method to perform Depth-First Search starting from a given vertex (Iterative)\n    public void performDFSIterative(int startVertex) {\n        boolean[] visited = new boolean[numVertices];\n        Stack<Integer> stack = new Stack<>();\n\n        visited[startVertex] = true;\n        stack.push(startVertex);\n\n        System.out.println(\"Depth-First Search (Iterative) starting from vertex \"\n                + startVertex + \":\");\n\n        while (!stack.isEmpty()) {\n            int currentVertex = stack.pop();\n            System.out.print(currentVertex + \" \");\n\n            for (int neighbor : this.adjacencyList.get(currentVertex)) {\n                if (!visited[neighbor]) {\n                    visited[neighbor] = true;\n                    stack.push(neighbor);\n                }\n            }\n        }\n        System.out.println();\n    }\n\n    // Method to perform Depth-First Search starting from a given vertex (Recursive)\n    public void performDFSRecursive(int startVertex) {\n        boolean[] visited = new boolean[numVertices];\n        System.out.println(\"Depth-First Search (Recursive) starting from vertex \"\n                + startVertex + \":\");\n        performDFSRecursiveUtil(startVertex, visited);\n        System.out.println();\n    }\n\n    private void performDFSRecursiveUtil(int vertex, boolean[] visited) {\n        visited[vertex] = true;\n        System.out.print(vertex + \" \");\n\n        for (int neighbor : this.adjacencyList.get(vertex)) {\n            if (!visited[neighbor]) {\n                performDFSRecursiveUtil(neighbor, visited);\n            }\n        }\n    }\n}\n\npublic class DepthFirst_Rev2504 {\n\n    /**\n     * @param args the command line arguments\n     */\n    public static void main(String[] args) {\n        DFS graph = new DFS(11);\n\n        graph.addEdge(0, 1);\n        graph.addEdge(0, 2);\n        graph.addEdge(1, 3);\n        graph.addEdge(2, 4);\n        graph.addEdge(4, 5);\n\n        graph.addEdge(0, 6);\n        graph.addEdge(0, 7);\n        graph.addEdge(7, 8);\n        graph.addEdge(7, 9);\n\n        graph.addEdge(9, 10);\n\n        graph.performDFSIterative(0);\n        graph.performDFSRecursive(0);\n\n        graph.performDFSIterative(6);\n        graph.performDFSRecursive(6);\n    }\n\n}\n\n/*\n * Graph Map based on the addEdge calls:\n *\n           0\n       /  /| \\\n      /  / |  \\\n     1  2  6   7\n     |  |     / \\\n     3  4    8   9\n        |        |\n        5        10\n\nDepth-First Search (Iterative) starting from vertex 0:\n0 7 9 10 8 6 2 4 5 1 3\nDepth-First Search (Recursive) starting from vertex 0:\n0 1 3 2 4 5 7 8 9 10 6\nDepth-First Search (Iterative) starting from vertex 6:\n6 0 7 9 10 8 2 4 5 1 3\nDepth-First Search (Recursive) starting from vertex 6:\n6 0 1 3 2 4 5 7 8 9 10\n*/\n\nCode Analysis\n\nDFS Class: This class represents the graph itself, similar to the BFS class.\n\nnumVertices: Stores the total number of vertices in the graph.\n\nadjacencyList: The adjacency list representation of the graph.\n\nDFS(int vertices) (Constructor): Initializes the graph with a specified number of vertices and creates empty adjacency lists.\n\naddEdge(int source, int destination): Adds an undirected edge between two vertices.\n\nperformDFSIterative(int startVertex) Method:\n\nThis method implements the iterative DFS algorithm.\n\nvisited: A boolean array to keep track of visited vertices.\n\nstack: A Stack (LIFO - Last-In, First-Out) is used to store vertices to be visited. DFS relies on the LIFO nature of a stack to explore deeper first.\n\nInitialization: The startVertex is marked as visited and pushed onto the stack.\n\nTraversal Loop (while (!stack.isEmpty())): The loop continues as long as there are nodes in the stack to process.\n\ncurrentVertex = stack.pop(): Removes the top vertex from the stack. This is the vertex currently being visited.\n\nSystem.out.print(currentVertex + \" \");: Prints the visited vertex.\n\nNeighbor Exploration (for (int neighbor : ...)): It iterates through all the neighbors of the currentVertex.\n\nif (!visited[neighbor]): Checks if the neighbor has already been visited.\n\nPushing to Stack: If the neighbor hasn’t been visited, it’s marked as visited and pushed onto the stack. This ensures that the algorithm explores the neighbors of the most recently added node first, going deeper into the graph.\n\nperformDFSRecursive(int startVertex) Method:\n\nThis method initiates the recursive DFS.\n\nIt creates a visited array and calls the helper method performDFSRecursiveUtil.\n\nperformDFSRecursiveUtil(int vertex, boolean[] visited) Method:\n\nThis is the recursive helper function.\n\nIt marks the current vertex as visited and prints it.\n\nIt then iterates through the neighbors of the current vertex.\n\nFor each unvisited neighbor, it recursively calls performDFSRecursiveUtil on that neighbor, effectively exploring deeper down that path.\n\nDepthFirst_Rev2504 Class (Main Program):\n\nmain(String[] args): The entry point of the program.\n\nCreates a DFS graph object with 11 vertices.\n\nCalls addEdge multiple times to define the same graph connections as in the BFS example.\n\nCalls performDFSIterative(0) and performDFSRecursive(0) to run both iterative and recursive DFS starting from vertex 0.\n\nCalls performDFSIterative(6) and performDFSRecursive(6) to run both iterative and recursive DFS starting from vertex 6.\n\nOutput\n\nThe output shows the order in which the nodes are visited using both the iterative and recursive approaches of DFS, starting from different vertices. Notice how the traversal goes deep along one path before backtracking and exploring other paths, which is characteristic of Depth-First Search. The iterative and recursive approaches may result in slightly different traversal orders depending on the order in which neighbors are added to the stack or processed in the adjacency list.","type":"content","url":"/xunderstandingdfs-202504","position":1}]}